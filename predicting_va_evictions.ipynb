{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspired/based on https://github.com/rayidghani/magicloops and https://github.com/dssg/MLforPublicPolicy/blob/master/labs/2019/lab6_feature_generation_sol.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pipeline_evictions as pipeline\n",
    "import ml_loop_evictions as loop\n",
    "\n",
    "import importlib\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(pipeline)\n",
    "\n",
    "datafile = \"data/tracts.csv\"\n",
    "\n",
    "#Read data, parsing year column to date type\n",
    "data = pd.read_csv(datafile, parse_dates=['year'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete rows that do not have eviction-rate. We do not want to impute this value\n",
    "\n",
    "data.dropna(subset=['eviction-rate'], inplace=True)\n",
    "data['eviction-rate'].isnull().values.any()\n",
    "data.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create outcome label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_eviction_rate(df, year,geoid):\n",
    "    \n",
    "  data_to_return = df.loc[(df['year'] == year) & (df['GEOID'] == geoid)]\n",
    "  \n",
    "  if(data_to_return.empty):\n",
    "    return 0\n",
    "  \n",
    "  return data_to_return['eviction-rate'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27889,)\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(pipeline)\n",
    "\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "#Obtain eviction-rate cutoff for the top 10%, for each year\n",
    "cutoff_10_percent={}\n",
    "for year in range(2000,2017):\n",
    "    year = pd.Timestamp(year,1,1)\n",
    "    cutoff_10_percent[year]=data.loc[data['year'] == year]['eviction-rate'].quantile(.9)\n",
    "    \n",
    "top_10_eviction_rate_in_any_next_3_years_column = np.zeros(len(data))\n",
    "print(top_10_eviction_rate_in_any_next_3_years_column.shape)\n",
    "\n",
    "\n",
    "for index, row in data.iterrows():\n",
    "  \n",
    "  #Because the outcome will come from eviction-rate in next 3 years and we have data till 2016,\n",
    "  #features data bust be from 2013 or before\n",
    "  \n",
    "  if(row['year']<=pd.Timestamp(2013,1,1)):    \n",
    "    \n",
    "    found_year_where_eviction_was_in_top_10_percent=0\n",
    "    \n",
    "    #Get eviction for the next 3 years\n",
    "    for i in range(1,4):\n",
    "      date_in_i_years = row['year'] + relativedelta(years=i)\n",
    "      eviction_rate_in_i_years = get_eviction_rate(data, date_in_i_years,row['GEOID'])\n",
    "    \n",
    "      top_10_eviction_rate_in_i_years = 1 if eviction_rate_in_i_years>= cutoff_10_percent[date_in_i_years] else 0\n",
    "      \n",
    "\n",
    "      \n",
    "      #If we found one year that meets requirement, we are done with looping\n",
    "      if(top_10_eviction_rate_in_i_years==1):\n",
    "        found_year_where_eviction_was_in_top_10_percent=1\n",
    "        break\n",
    "\n",
    "    top_10_eviction_rate_in_any_next_3_years_column[index]=found_year_where_eviction_was_in_top_10_percent\n",
    "\n",
    "data['top_10_percent_in_any_next_3_years'] = top_10_eviction_rate_in_any_next_3_years_column\n",
    "\n",
    "label ='top_10_percent_in_any_next_3_years'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Debugging. In case we want to add 1 column for each future year with top 10%\n",
    "\n",
    "      # eviction_rate_in_1_year = np.zeros(len(data))\n",
    "# cutoff_in_1_year = np.zeros(len(data))\n",
    "\n",
    "      \n",
    "#       if(top_10_eviction_rate_in_i_years==1):\n",
    "#         print(row['GEOID'])\n",
    "#         print(row['year'])\n",
    "#         print(date_in_i_years)\n",
    "#         print(eviction_rate_in_i_years)\n",
    "#         print(cutoff_10_percent[date_in_i_years])\n",
    "#         print(top_10_eviction_rate_in_i_years)     \n",
    "\n",
    "#       if(i==1):\n",
    "#         eviction_rate_in_1_year[index]=eviction_rate_in_i_years\n",
    "#         cutoff_in_1_year[index]=cutoff_10_percent[date_in_i_years]\n",
    "\n",
    "# data['eviction_rate_in_1_year']='eviction_rate_in_1_year'\n",
    "# data['cutoff_in_1_year']='eviction_rate_in_1_year'      \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create temporal train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(pipeline)\n",
    "\n",
    "#Create sets of train and test data, based on different split thresholds\n",
    "#The split thresholds corresponds to the starting date of the testing data\n",
    "\n",
    "#Splits according to https://docs.google.com/spreadsheets/d/1ipqsgThz7hdXXyyNpTuqa4J1inc088lop7lhFsAQ_r0/edit#gid=0\n",
    "split_thresholds = [pd.Timestamp(i,1,1) for i in range (2004, 2014)]\n",
    "\n",
    "#Indicating which is the column to be used for splitting training and test daata\n",
    "date_column='year'\n",
    "\n",
    "#Amount of data used for test set\n",
    "test_window = relativedelta(years=4)\n",
    "\n",
    "#Gap needed between training and test set\n",
    "prediction_horizon = relativedelta(years=3)\n",
    "\n",
    "#Generate train and test sets\n",
    "train_test_sets= pipeline.create_temp_validation_train_and_testing_sets(\n",
    "  data,\n",
    "  date_column,\n",
    "  label,\n",
    "  split_thresholds,\n",
    "  test_window,\n",
    "  prediction_horizon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GEOID\n",
      "year\n",
      "name\n",
      "parent-location\n",
      "population\n",
      "poverty-rate\n",
      "renter-occupied-households\n",
      "pct-renter-occupied\n",
      "median-gross-rent\n",
      "median-household-income\n",
      "median-property-value\n",
      "rent-burden\n",
      "pct-white\n",
      "pct-af-am\n",
      "pct-hispanic\n",
      "pct-am-ind\n",
      "pct-asian\n",
      "pct-nh-pi\n",
      "pct-multiple\n",
      "pct-other\n",
      "eviction-filings\n",
      "evictions\n",
      "eviction-rate\n",
      "eviction-filing-rate\n",
      "low-flag\n",
      "imputed\n",
      "subbed\n"
     ]
    }
   ],
   "source": [
    "for c in train_test_sets[5]['x_train'].columns:\n",
    "  print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "importlib.reload(pipeline)\n",
    "\n",
    "#Impute data on continuous columns for each training and test set\n",
    "\n",
    "#--->PENDING\n",
    "#In the meantime, imputing all float columns with mean\n",
    "  \n",
    "float_columns = [column for column in data.columns if data[column].dtype=='float']\n",
    "\n",
    "#Do not consider GEOID column nor top_10_percent_in_any_next_3_years\n",
    "float_columns.remove('name')\n",
    "float_columns.remove('top_10_percent_in_any_next_3_years')\n",
    "\n",
    "\n",
    "for train_test_set in train_test_sets:\n",
    "  train_data = train_test_set['x_train']\n",
    "  test_data = train_test_set['x_test']\n",
    "\n",
    "  #fill na values with mean\n",
    "  pipeline.impute_data(train_data, float_columns)\n",
    "  pipeline.impute_data(test_data, float_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Create features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import feature_generation as fg\n",
    "\n",
    "importlib.reload(pipeline)\n",
    "importlib.reload(fg)\n",
    "\n",
    "#We will have to generate features independently for each different train/test set\n",
    "for train_test_set in train_test_sets:\n",
    "\n",
    "  train_features = fg.create_features(train_test_set['x_train'])\n",
    "  test_features = fg.create_features(train_test_set['x_test']) \n",
    "  \n",
    "  #Alternative for just working with default features\n",
    "  #train_features, test_features = pipeline.create_features(train_test_set)\n",
    "  \n",
    "  #Replace raw data in train_test_set with features generated\n",
    "  train_test_set['x_train'] = train_features\n",
    "  train_test_set['x_test'] = test_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Clasifiers and parameters generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(pipeline)\n",
    "\n",
    "#We define the specific models we want to run\n",
    "models_to_run=['LR','DT','RF','KNN','NB','BA','AB','GB','ET']#,SVM'\n",
    "\n",
    "#Get all posible models and their different sets of parameters\n",
    "models, parameters_grid = pipeline.get_models_and_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loop over models and different training/test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1300"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(len(train_test_sets[0]['x_test']))\n",
    "# print(len(train_test_sets[0]['y_test']))\n",
    "train_test_sets[0]['y_test'].isnull().any()\n",
    "# df.isnull().values.any()\n",
    "\n",
    "# for column in train_test_sets[5]['x_test'].columns:\n",
    "#   print(column)\n",
    "  \n",
    "np.sum(len(train_test_sets[5]['x_test']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-12 07:57:27.536716: Running LR with params: {'C': 0.001, 'penalty': 'l1'} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-12 07:57:27.996724: Running LR with params: {'C': 0.001, 'penalty': 'l2'} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-12 07:57:28.413423: Running LR with params: {'C': 0.1, 'penalty': 'l1'} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-12 07:57:29.898325: Running LR with params: {'C': 0.1, 'penalty': 'l2'} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-12 07:57:30.278459: Running LR with params: {'C': 1, 'penalty': 'l1'} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-12 07:57:31.418492: Running LR with params: {'C': 1, 'penalty': 'l2'} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-12 07:57:31.814619: Running LR with params: {'C': 10, 'penalty': 'l1'} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-12 07:57:46.464250: Running LR with params: {'C': 10, 'penalty': 'l2'} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-12 07:57:46.841994: Running DT with params: {'criterion': 'gini', 'max_depth': 2, 'min_samples_split': 2} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-12 07:57:47.125050: Running DT with params: {'criterion': 'gini', 'max_depth': 2, 'min_samples_split': 5} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-12 07:57:47.404454: Running DT with params: {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 2} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-12 07:57:47.746466: Running DT with params: {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 5} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-12 07:57:48.027140: Running DT with params: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 2} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-12 07:57:48.307838: Running DT with params: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 5} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-12 07:57:48.593142: Running DT with params: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 2} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-12 07:57:48.885209: Running DT with params: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 5} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-12 07:57:49.173330: Running DT with params: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 2} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-12 07:57:49.466817: Running DT with params: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 5} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-12 07:57:49.763800: Running DT with params: {'criterion': 'entropy', 'max_depth': 2, 'min_samples_split': 2} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-12 07:57:50.047799: Running DT with params: {'criterion': 'entropy', 'max_depth': 2, 'min_samples_split': 5} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-12 07:57:50.333791: Running DT with params: {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 2} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-12 07:57:50.623737: Running DT with params: {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 5} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-12 07:57:50.919497: Running DT with params: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 2} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-12 07:57:51.234935: Running DT with params: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 5} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-12 07:57:51.598317: Running DT with params: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 2} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-12 07:57:51.893313: Running DT with params: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 5} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-12 07:57:52.194045: Running DT with params: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 2} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-12 07:57:52.490345: Running DT with params: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 5} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-12 07:57:52.791430: Running RF with params: {'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 2, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-12 07:57:53.297742: Running RF with params: {'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 2, 'n_estimators': 1000, 'n_jobs': -1} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-12 07:57:55.614460: Running RF with params: {'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-12 07:57:56.106517: Running RF with params: {'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 1000, 'n_jobs': -1} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-12 07:57:57.762236: Running RF with params: {'max_depth': 5, 'max_features': 'log2', 'min_samples_split': 2, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-12 07:57:58.265042: Running RF with params: {'max_depth': 5, 'max_features': 'log2', 'min_samples_split': 2, 'n_estimators': 1000, 'n_jobs': -1} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-12 07:58:00.585438: Running RF with params: {'max_depth': 5, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-12 07:58:01.076382: Running RF with params: {'max_depth': 5, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 1000, 'n_jobs': -1} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-12 07:58:03.425781: Running RF with params: {'max_depth': 50, 'max_features': 'sqrt', 'min_samples_split': 2, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-12 07:58:03.920573: Running RF with params: {'max_depth': 50, 'max_features': 'sqrt', 'min_samples_split': 2, 'n_estimators': 1000, 'n_jobs': -1} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-12 07:58:06.409942: Running RF with params: {'max_depth': 50, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-12 07:58:06.897984: Running RF with params: {'max_depth': 50, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 1000, 'n_jobs': -1} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-12 07:58:08.807221: Running RF with params: {'max_depth': 50, 'max_features': 'log2', 'min_samples_split': 2, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-12 07:58:09.301701: Running RF with params: {'max_depth': 50, 'max_features': 'log2', 'min_samples_split': 2, 'n_estimators': 1000, 'n_jobs': -1} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-12 07:58:12.200557: Running RF with params: {'max_depth': 50, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-12 07:58:12.667529: Running RF with params: {'max_depth': 50, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 1000, 'n_jobs': -1} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-12 07:58:14.260500: Running RF with params: {'max_depth': 100, 'max_features': 'sqrt', 'min_samples_split': 2, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-12 07:58:14.792773: Running RF with params: {'max_depth': 100, 'max_features': 'sqrt', 'min_samples_split': 2, 'n_estimators': 1000, 'n_jobs': -1} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-12 07:58:17.424539: Running RF with params: {'max_depth': 100, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-12 07:58:17.915733: Running RF with params: {'max_depth': 100, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 1000, 'n_jobs': -1} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-12 07:58:20.386844: Running RF with params: {'max_depth': 100, 'max_features': 'log2', 'min_samples_split': 2, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-12 07:58:20.848747: Running RF with params: {'max_depth': 100, 'max_features': 'log2', 'min_samples_split': 2, 'n_estimators': 1000, 'n_jobs': -1} on train/test set 2004-01-01 00:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-12 07:58:22.496319: Running RF with params: {'max_depth': 100, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-12 07:58:22.998748: Running RF with params: {'max_depth': 100, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 1000, 'n_jobs': -1} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-12 07:58:25.523544: Running KNN with params: {'algorithm': 'auto', 'n_neighbors': 3, 'weights': 'uniform'} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-12 07:58:25.815617: Running KNN with params: {'algorithm': 'auto', 'n_neighbors': 3, 'weights': 'distance'} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-12 07:58:26.098925: Running KNN with params: {'algorithm': 'auto', 'n_neighbors': 5, 'weights': 'uniform'} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-12 07:58:26.391583: Running KNN with params: {'algorithm': 'auto', 'n_neighbors': 5, 'weights': 'distance'} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-12 07:58:26.682363: Running KNN with params: {'algorithm': 'auto', 'n_neighbors': 10, 'weights': 'uniform'} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-12 07:58:26.991557: Running KNN with params: {'algorithm': 'auto', 'n_neighbors': 10, 'weights': 'distance'} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-12 07:58:27.330579: Running KNN with params: {'algorithm': 'auto', 'n_neighbors': 50, 'weights': 'uniform'} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-12 07:58:27.735556: Running KNN with params: {'algorithm': 'auto', 'n_neighbors': 50, 'weights': 'distance'} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-12 07:58:28.159205: Running KNN with params: {'algorithm': 'auto', 'n_neighbors': 100, 'weights': 'uniform'} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-12 07:58:28.613179: Running KNN with params: {'algorithm': 'auto', 'n_neighbors': 100, 'weights': 'distance'} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-12 07:58:29.092198: Running KNN with params: {'algorithm': 'ball_tree', 'n_neighbors': 3, 'weights': 'uniform'} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-12 07:58:29.546165: Running KNN with params: {'algorithm': 'ball_tree', 'n_neighbors': 3, 'weights': 'distance'} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-12 07:58:29.990339: Running KNN with params: {'algorithm': 'ball_tree', 'n_neighbors': 5, 'weights': 'uniform'} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-12 07:58:30.435982: Running KNN with params: {'algorithm': 'ball_tree', 'n_neighbors': 5, 'weights': 'distance'} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-12 07:58:30.888339: Running KNN with params: {'algorithm': 'ball_tree', 'n_neighbors': 10, 'weights': 'uniform'} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-12 07:58:31.343766: Running KNN with params: {'algorithm': 'ball_tree', 'n_neighbors': 10, 'weights': 'distance'} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-12 07:58:31.809010: Running KNN with params: {'algorithm': 'ball_tree', 'n_neighbors': 50, 'weights': 'uniform'} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-12 07:58:32.322807: Running KNN with params: {'algorithm': 'ball_tree', 'n_neighbors': 50, 'weights': 'distance'} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-12 07:58:32.870096: Running KNN with params: {'algorithm': 'ball_tree', 'n_neighbors': 100, 'weights': 'uniform'} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-12 07:58:33.434200: Running KNN with params: {'algorithm': 'ball_tree', 'n_neighbors': 100, 'weights': 'distance'} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-12 07:58:34.016595: Running NB with params: {} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-12 07:58:34.278033: Running BA with params: {'n_estimators': 10} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-12 07:58:35.266669: Running BA with params: {'n_estimators': 100} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-12 07:58:42.779245: Running AB with params: {'algorithm': 'SAMME', 'n_estimators': 10} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-12 07:58:43.194954: Running AB with params: {'algorithm': 'SAMME', 'n_estimators': 100} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-12 07:58:43.874653: Running AB with params: {'algorithm': 'SAMME.R', 'n_estimators': 10} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-12 07:58:44.178559: Running AB with params: {'algorithm': 'SAMME.R', 'n_estimators': 100} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-12 07:58:44.910375: Running GB with params: {'learning_rate': 0.001, 'n_estimators': 10, 'subsample': 0.1} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-12 07:58:45.197470: Running GB with params: {'learning_rate': 0.001, 'n_estimators': 10, 'subsample': 1.0} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-12 07:58:45.499425: Running GB with params: {'learning_rate': 0.001, 'n_estimators': 100, 'subsample': 0.1} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-12 07:58:45.984939: Running GB with params: {'learning_rate': 0.001, 'n_estimators': 100, 'subsample': 1.0} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-12 07:58:46.699747: Running GB with params: {'learning_rate': 0.1, 'n_estimators': 10, 'subsample': 0.1} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-12 07:58:46.991129: Running GB with params: {'learning_rate': 0.1, 'n_estimators': 10, 'subsample': 1.0} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-12 07:58:47.300098: Running GB with params: {'learning_rate': 0.1, 'n_estimators': 100, 'subsample': 0.1} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-12 07:58:47.766232: Running GB with params: {'learning_rate': 0.1, 'n_estimators': 100, 'subsample': 1.0} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-12 07:58:48.465258: Running ET with params: {'criterion': 'gini', 'max_depth': 2, 'n_estimators': 100} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-12 07:58:48.944801: Running ET with params: {'criterion': 'gini', 'max_depth': 2, 'n_estimators': 1000} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-12 07:58:51.327949: Running ET with params: {'criterion': 'gini', 'max_depth': 5, 'n_estimators': 100} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-12 07:58:51.808430: Running ET with params: {'criterion': 'gini', 'max_depth': 5, 'n_estimators': 1000} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-12 07:58:53.157427: Running ET with params: {'criterion': 'gini', 'max_depth': 50, 'n_estimators': 100} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-12 07:58:53.628329: Running ET with params: {'criterion': 'gini', 'max_depth': 50, 'n_estimators': 1000} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-12 07:58:56.301196: Running ET with params: {'criterion': 'entropy', 'max_depth': 2, 'n_estimators': 100} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-12 07:58:56.780812: Running ET with params: {'criterion': 'entropy', 'max_depth': 2, 'n_estimators': 1000} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-12 07:58:58.370171: Running ET with params: {'criterion': 'entropy', 'max_depth': 5, 'n_estimators': 100} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-12 07:58:58.862030: Running ET with params: {'criterion': 'entropy', 'max_depth': 5, 'n_estimators': 1000} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-12 07:59:00.209420: Running ET with params: {'criterion': 'entropy', 'max_depth': 50, 'n_estimators': 100} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-12 07:59:00.666726: Running ET with params: {'criterion': 'entropy', 'max_depth': 50, 'n_estimators': 1000} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-12 07:59:03.265901: Running LR with params: {'C': 0.001, 'penalty': 'l1'} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-12 07:59:04.519938: Running LR with params: {'C': 0.001, 'penalty': 'l2'} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-12 07:59:05.096544: Running LR with params: {'C': 0.1, 'penalty': 'l1'} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-12 07:59:10.284471: Running LR with params: {'C': 0.1, 'penalty': 'l2'} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-12 07:59:11.554423: Running LR with params: {'C': 1, 'penalty': 'l1'} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-12 07:59:18.464788: Running LR with params: {'C': 1, 'penalty': 'l2'} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-12 07:59:19.455326: Running LR with params: {'C': 10, 'penalty': 'l1'} on train/test set 2005-01-01 00:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-12 07:59:58.699532: Running LR with params: {'C': 10, 'penalty': 'l2'} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-12 07:59:59.166517: Running DT with params: {'criterion': 'gini', 'max_depth': 2, 'min_samples_split': 2} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-12 07:59:59.654427: Running DT with params: {'criterion': 'gini', 'max_depth': 2, 'min_samples_split': 5} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-12 07:59:59.989342: Running DT with params: {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 2} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-12 08:00:00.307023: Running DT with params: {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 5} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-12 08:00:00.603298: Running DT with params: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 2} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-12 08:00:00.923101: Running DT with params: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 5} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-12 08:00:01.239759: Running DT with params: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 2} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-12 08:00:01.555521: Running DT with params: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 5} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-12 08:00:01.870929: Running DT with params: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 2} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-12 08:00:02.187961: Running DT with params: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 5} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-12 08:00:02.499170: Running DT with params: {'criterion': 'entropy', 'max_depth': 2, 'min_samples_split': 2} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-12 08:00:02.771595: Running DT with params: {'criterion': 'entropy', 'max_depth': 2, 'min_samples_split': 5} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-12 08:00:03.039729: Running DT with params: {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 2} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-12 08:00:03.340282: Running DT with params: {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 5} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-12 08:00:03.640891: Running DT with params: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 2} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-12 08:00:03.966104: Running DT with params: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 5} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-12 08:00:04.290638: Running DT with params: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 2} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-12 08:00:04.610086: Running DT with params: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 5} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-12 08:00:04.938594: Running DT with params: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 2} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-12 08:00:05.264655: Running DT with params: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 5} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-12 08:00:05.593104: Running RF with params: {'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 2, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-12 08:00:06.193972: Running RF with params: {'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 2, 'n_estimators': 1000, 'n_jobs': -1} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-12 08:00:09.144264: Running RF with params: {'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-12 08:00:09.734927: Running RF with params: {'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 1000, 'n_jobs': -1} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-12 08:00:12.230756: Running RF with params: {'max_depth': 5, 'max_features': 'log2', 'min_samples_split': 2, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-12 08:00:12.707930: Running RF with params: {'max_depth': 5, 'max_features': 'log2', 'min_samples_split': 2, 'n_estimators': 1000, 'n_jobs': -1} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-12 08:00:17.486854: Running RF with params: {'max_depth': 5, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-12 08:00:18.708290: Running RF with params: {'max_depth': 5, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 1000, 'n_jobs': -1} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-12 08:00:24.681554: Running RF with params: {'max_depth': 50, 'max_features': 'sqrt', 'min_samples_split': 2, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-12 08:00:25.498502: Running RF with params: {'max_depth': 50, 'max_features': 'sqrt', 'min_samples_split': 2, 'n_estimators': 1000, 'n_jobs': -1} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-12 08:00:29.422697: Running RF with params: {'max_depth': 50, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-12 08:00:30.060075: Running RF with params: {'max_depth': 50, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 1000, 'n_jobs': -1} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-12 08:00:33.222388: Running RF with params: {'max_depth': 50, 'max_features': 'log2', 'min_samples_split': 2, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-12 08:00:33.930205: Running RF with params: {'max_depth': 50, 'max_features': 'log2', 'min_samples_split': 2, 'n_estimators': 1000, 'n_jobs': -1} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-12 08:00:36.289303: Running RF with params: {'max_depth': 50, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-12 08:00:37.118202: Running RF with params: {'max_depth': 50, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 1000, 'n_jobs': -1} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-12 08:00:39.805234: Running RF with params: {'max_depth': 100, 'max_features': 'sqrt', 'min_samples_split': 2, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-12 08:00:40.418572: Running RF with params: {'max_depth': 100, 'max_features': 'sqrt', 'min_samples_split': 2, 'n_estimators': 1000, 'n_jobs': -1} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-12 08:00:44.286438: Running RF with params: {'max_depth': 100, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-12 08:00:44.894188: Running RF with params: {'max_depth': 100, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 1000, 'n_jobs': -1} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-12 08:00:48.206154: Running RF with params: {'max_depth': 100, 'max_features': 'log2', 'min_samples_split': 2, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-12 08:00:48.923436: Running RF with params: {'max_depth': 100, 'max_features': 'log2', 'min_samples_split': 2, 'n_estimators': 1000, 'n_jobs': -1} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-12 08:00:51.350897: Running RF with params: {'max_depth': 100, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-12 08:00:51.971438: Running RF with params: {'max_depth': 100, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 1000, 'n_jobs': -1} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-12 08:00:55.292142: Running KNN with params: {'algorithm': 'auto', 'n_neighbors': 3, 'weights': 'uniform'} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-12 08:00:55.593410: Running KNN with params: {'algorithm': 'auto', 'n_neighbors': 3, 'weights': 'distance'} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-12 08:00:55.878273: Running KNN with params: {'algorithm': 'auto', 'n_neighbors': 5, 'weights': 'uniform'} on train/test set 2005-01-01 00:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-12 08:00:56.179258: Running KNN with params: {'algorithm': 'auto', 'n_neighbors': 5, 'weights': 'distance'} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-12 08:00:56.470736: Running KNN with params: {'algorithm': 'auto', 'n_neighbors': 10, 'weights': 'uniform'} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-12 08:00:56.781706: Running KNN with params: {'algorithm': 'auto', 'n_neighbors': 10, 'weights': 'distance'} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-12 08:00:57.077527: Running KNN with params: {'algorithm': 'auto', 'n_neighbors': 50, 'weights': 'uniform'} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-12 08:00:57.457480: Running KNN with params: {'algorithm': 'auto', 'n_neighbors': 50, 'weights': 'distance'} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-12 08:00:57.885628: Running KNN with params: {'algorithm': 'auto', 'n_neighbors': 100, 'weights': 'uniform'} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-12 08:00:58.342874: Running KNN with params: {'algorithm': 'auto', 'n_neighbors': 100, 'weights': 'distance'} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-12 08:00:58.850739: Running KNN with params: {'algorithm': 'ball_tree', 'n_neighbors': 3, 'weights': 'uniform'} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-12 08:00:59.286121: Running KNN with params: {'algorithm': 'ball_tree', 'n_neighbors': 3, 'weights': 'distance'} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-12 08:00:59.685869: Running KNN with params: {'algorithm': 'ball_tree', 'n_neighbors': 5, 'weights': 'uniform'} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-12 08:01:00.111081: Running KNN with params: {'algorithm': 'ball_tree', 'n_neighbors': 5, 'weights': 'distance'} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-12 08:01:00.511397: Running KNN with params: {'algorithm': 'ball_tree', 'n_neighbors': 10, 'weights': 'uniform'} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-12 08:01:00.919146: Running KNN with params: {'algorithm': 'ball_tree', 'n_neighbors': 10, 'weights': 'distance'} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-12 08:01:01.319712: Running KNN with params: {'algorithm': 'ball_tree', 'n_neighbors': 50, 'weights': 'uniform'} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-12 08:01:01.797343: Running KNN with params: {'algorithm': 'ball_tree', 'n_neighbors': 50, 'weights': 'distance'} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-12 08:01:02.294797: Running KNN with params: {'algorithm': 'ball_tree', 'n_neighbors': 100, 'weights': 'uniform'} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-12 08:01:02.838859: Running KNN with params: {'algorithm': 'ball_tree', 'n_neighbors': 100, 'weights': 'distance'} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-12 08:01:03.393141: Running NB with params: {} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-12 08:01:03.962689: Running BA with params: {'n_estimators': 10} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-12 08:01:05.059954: Running BA with params: {'n_estimators': 100} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-12 08:01:14.073610: Running AB with params: {'algorithm': 'SAMME', 'n_estimators': 10} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-12 08:01:14.386564: Running AB with params: {'algorithm': 'SAMME', 'n_estimators': 100} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-12 08:01:15.391495: Running AB with params: {'algorithm': 'SAMME.R', 'n_estimators': 10} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-12 08:01:15.710631: Running AB with params: {'algorithm': 'SAMME.R', 'n_estimators': 100} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-12 08:01:16.787006: Running GB with params: {'learning_rate': 0.001, 'n_estimators': 10, 'subsample': 0.1} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-12 08:01:17.103087: Running GB with params: {'learning_rate': 0.001, 'n_estimators': 10, 'subsample': 1.0} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-12 08:01:17.443515: Running GB with params: {'learning_rate': 0.001, 'n_estimators': 100, 'subsample': 0.1} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-12 08:01:18.114601: Running GB with params: {'learning_rate': 0.001, 'n_estimators': 100, 'subsample': 1.0} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-12 08:01:19.203930: Running GB with params: {'learning_rate': 0.1, 'n_estimators': 10, 'subsample': 0.1} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-12 08:01:19.554608: Running GB with params: {'learning_rate': 0.1, 'n_estimators': 10, 'subsample': 1.0} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-12 08:01:19.897921: Running GB with params: {'learning_rate': 0.1, 'n_estimators': 100, 'subsample': 0.1} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-12 08:01:20.540784: Running GB with params: {'learning_rate': 0.1, 'n_estimators': 100, 'subsample': 1.0} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-12 08:01:21.553666: Running ET with params: {'criterion': 'gini', 'max_depth': 2, 'n_estimators': 100} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-12 08:01:22.040886: Running ET with params: {'criterion': 'gini', 'max_depth': 2, 'n_estimators': 1000} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-12 08:01:23.515442: Running ET with params: {'criterion': 'gini', 'max_depth': 5, 'n_estimators': 100} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-12 08:01:24.010737: Running ET with params: {'criterion': 'gini', 'max_depth': 5, 'n_estimators': 1000} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-12 08:01:25.674521: Running ET with params: {'criterion': 'gini', 'max_depth': 50, 'n_estimators': 100} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-12 08:01:26.497224: Running ET with params: {'criterion': 'gini', 'max_depth': 50, 'n_estimators': 1000} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-12 08:01:28.632508: Running ET with params: {'criterion': 'entropy', 'max_depth': 2, 'n_estimators': 100} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-12 08:01:29.147139: Running ET with params: {'criterion': 'entropy', 'max_depth': 2, 'n_estimators': 1000} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-12 08:01:31.190148: Running ET with params: {'criterion': 'entropy', 'max_depth': 5, 'n_estimators': 100} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-12 08:01:31.678304: Running ET with params: {'criterion': 'entropy', 'max_depth': 5, 'n_estimators': 1000} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-12 08:01:33.240160: Running ET with params: {'criterion': 'entropy', 'max_depth': 50, 'n_estimators': 100} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-12 08:01:33.848769: Running ET with params: {'criterion': 'entropy', 'max_depth': 50, 'n_estimators': 1000} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-12 08:01:36.273367: Running LR with params: {'C': 0.001, 'penalty': 'l1'} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-12 08:01:38.857106: Running LR with params: {'C': 0.001, 'penalty': 'l2'} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-12 08:01:39.418913: Running LR with params: {'C': 0.1, 'penalty': 'l1'} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-12 08:01:44.804826: Running LR with params: {'C': 0.1, 'penalty': 'l2'} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-12 08:01:45.463581: Running LR with params: {'C': 1, 'penalty': 'l1'} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-12 08:01:51.655429: Running LR with params: {'C': 1, 'penalty': 'l2'} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-12 08:01:52.209858: Running LR with params: {'C': 10, 'penalty': 'l1'} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-12 08:02:46.244736: Running LR with params: {'C': 10, 'penalty': 'l2'} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-12 08:02:46.782764: Running DT with params: {'criterion': 'gini', 'max_depth': 2, 'min_samples_split': 2} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-12 08:02:47.065580: Running DT with params: {'criterion': 'gini', 'max_depth': 2, 'min_samples_split': 5} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-12 08:02:47.329714: Running DT with params: {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 2} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-12 08:02:47.627719: Running DT with params: {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 5} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-12 08:02:47.951054: Running DT with params: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 2} on train/test set 2006-01-01 00:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-12 08:02:48.291064: Running DT with params: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 5} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-12 08:02:48.610112: Running DT with params: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 2} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-12 08:02:48.945173: Running DT with params: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 5} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-12 08:02:49.267638: Running DT with params: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 2} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-12 08:02:49.600960: Running DT with params: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 5} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-12 08:02:49.932597: Running DT with params: {'criterion': 'entropy', 'max_depth': 2, 'min_samples_split': 2} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-12 08:02:50.206273: Running DT with params: {'criterion': 'entropy', 'max_depth': 2, 'min_samples_split': 5} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-12 08:02:50.472159: Running DT with params: {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 2} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-12 08:02:50.782062: Running DT with params: {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 5} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-12 08:02:51.491070: Running DT with params: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 2} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-12 08:02:51.803020: Running DT with params: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 5} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-12 08:02:52.111447: Running DT with params: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 2} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-12 08:02:52.454243: Running DT with params: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 5} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-12 08:02:52.793840: Running DT with params: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 2} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-12 08:02:53.138674: Running DT with params: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 5} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-12 08:02:53.473789: Running RF with params: {'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 2, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-12 08:02:54.098345: Running RF with params: {'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 2, 'n_estimators': 1000, 'n_jobs': -1} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-12 08:02:57.236644: Running RF with params: {'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-12 08:02:57.920966: Running RF with params: {'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 1000, 'n_jobs': -1} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-12 08:03:00.559459: Running RF with params: {'max_depth': 5, 'max_features': 'log2', 'min_samples_split': 2, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-12 08:03:01.272758: Running RF with params: {'max_depth': 5, 'max_features': 'log2', 'min_samples_split': 2, 'n_estimators': 1000, 'n_jobs': -1} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-12 08:03:04.266988: Running RF with params: {'max_depth': 5, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-12 08:03:04.867455: Running RF with params: {'max_depth': 5, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 1000, 'n_jobs': -1} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-12 08:03:06.956431: Running RF with params: {'max_depth': 50, 'max_features': 'sqrt', 'min_samples_split': 2, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-12 08:03:07.687199: Running RF with params: {'max_depth': 50, 'max_features': 'sqrt', 'min_samples_split': 2, 'n_estimators': 1000, 'n_jobs': -1} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-12 08:03:11.619824: Running RF with params: {'max_depth': 50, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-12 08:03:12.380687: Running RF with params: {'max_depth': 50, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 1000, 'n_jobs': -1} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-12 08:03:16.671439: Running RF with params: {'max_depth': 50, 'max_features': 'log2', 'min_samples_split': 2, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-12 08:03:17.388027: Running RF with params: {'max_depth': 50, 'max_features': 'log2', 'min_samples_split': 2, 'n_estimators': 1000, 'n_jobs': -1} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-12 08:03:20.926757: Running RF with params: {'max_depth': 50, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-12 08:03:21.782068: Running RF with params: {'max_depth': 50, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 1000, 'n_jobs': -1} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-12 08:03:24.666153: Running RF with params: {'max_depth': 100, 'max_features': 'sqrt', 'min_samples_split': 2, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-12 08:03:25.402584: Running RF with params: {'max_depth': 100, 'max_features': 'sqrt', 'min_samples_split': 2, 'n_estimators': 1000, 'n_jobs': -1} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-12 08:03:30.217667: Running RF with params: {'max_depth': 100, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-12 08:03:30.970669: Running RF with params: {'max_depth': 100, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 1000, 'n_jobs': -1} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-12 08:03:34.674378: Running RF with params: {'max_depth': 100, 'max_features': 'log2', 'min_samples_split': 2, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-12 08:03:35.487961: Running RF with params: {'max_depth': 100, 'max_features': 'log2', 'min_samples_split': 2, 'n_estimators': 1000, 'n_jobs': -1} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-12 08:03:39.310605: Running RF with params: {'max_depth': 100, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-12 08:03:39.931016: Running RF with params: {'max_depth': 100, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 1000, 'n_jobs': -1} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-12 08:03:43.317711: Running KNN with params: {'algorithm': 'auto', 'n_neighbors': 3, 'weights': 'uniform'} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-12 08:03:43.626977: Running KNN with params: {'algorithm': 'auto', 'n_neighbors': 3, 'weights': 'distance'} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-12 08:03:43.924867: Running KNN with params: {'algorithm': 'auto', 'n_neighbors': 5, 'weights': 'uniform'} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-12 08:03:44.236846: Running KNN with params: {'algorithm': 'auto', 'n_neighbors': 5, 'weights': 'distance'} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-12 08:03:44.543009: Running KNN with params: {'algorithm': 'auto', 'n_neighbors': 10, 'weights': 'uniform'} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-12 08:03:44.895434: Running KNN with params: {'algorithm': 'auto', 'n_neighbors': 10, 'weights': 'distance'} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-12 08:03:45.257675: Running KNN with params: {'algorithm': 'auto', 'n_neighbors': 50, 'weights': 'uniform'} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-12 08:03:45.674687: Running KNN with params: {'algorithm': 'auto', 'n_neighbors': 50, 'weights': 'distance'} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-12 08:03:46.123565: Running KNN with params: {'algorithm': 'auto', 'n_neighbors': 100, 'weights': 'uniform'} on train/test set 2006-01-01 00:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-12 08:03:46.622186: Running KNN with params: {'algorithm': 'auto', 'n_neighbors': 100, 'weights': 'distance'} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-12 08:03:47.131810: Running KNN with params: {'algorithm': 'ball_tree', 'n_neighbors': 3, 'weights': 'uniform'} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-12 08:03:47.532071: Running KNN with params: {'algorithm': 'ball_tree', 'n_neighbors': 3, 'weights': 'distance'} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-12 08:03:47.937102: Running KNN with params: {'algorithm': 'ball_tree', 'n_neighbors': 5, 'weights': 'uniform'} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-12 08:03:48.351010: Running KNN with params: {'algorithm': 'ball_tree', 'n_neighbors': 5, 'weights': 'distance'} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-12 08:03:48.754446: Running KNN with params: {'algorithm': 'ball_tree', 'n_neighbors': 10, 'weights': 'uniform'} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-12 08:03:49.187748: Running KNN with params: {'algorithm': 'ball_tree', 'n_neighbors': 10, 'weights': 'distance'} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-12 08:03:49.619138: Running KNN with params: {'algorithm': 'ball_tree', 'n_neighbors': 50, 'weights': 'uniform'} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-12 08:03:50.138137: Running KNN with params: {'algorithm': 'ball_tree', 'n_neighbors': 50, 'weights': 'distance'} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-12 08:03:50.669626: Running KNN with params: {'algorithm': 'ball_tree', 'n_neighbors': 100, 'weights': 'uniform'} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-12 08:03:51.265410: Running KNN with params: {'algorithm': 'ball_tree', 'n_neighbors': 100, 'weights': 'distance'} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-12 08:03:51.867788: Running NB with params: {} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-12 08:03:52.143560: Running BA with params: {'n_estimators': 10} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-12 08:03:53.710381: Running BA with params: {'n_estimators': 100} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-12 08:04:05.262337: Running AB with params: {'algorithm': 'SAMME', 'n_estimators': 10} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-12 08:04:05.636789: Running AB with params: {'algorithm': 'SAMME', 'n_estimators': 100} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-12 08:04:07.013709: Running AB with params: {'algorithm': 'SAMME.R', 'n_estimators': 10} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-12 08:04:07.886678: Running AB with params: {'algorithm': 'SAMME.R', 'n_estimators': 100} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-12 08:04:09.219861: Running GB with params: {'learning_rate': 0.001, 'n_estimators': 10, 'subsample': 0.1} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-12 08:04:09.570716: Running GB with params: {'learning_rate': 0.001, 'n_estimators': 10, 'subsample': 1.0} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-12 08:04:09.976481: Running GB with params: {'learning_rate': 0.001, 'n_estimators': 100, 'subsample': 0.1} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-12 08:04:10.878153: Running GB with params: {'learning_rate': 0.001, 'n_estimators': 100, 'subsample': 1.0} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-12 08:04:12.322145: Running GB with params: {'learning_rate': 0.1, 'n_estimators': 10, 'subsample': 0.1} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-12 08:04:12.674286: Running GB with params: {'learning_rate': 0.1, 'n_estimators': 10, 'subsample': 1.0} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-12 08:04:13.095695: Running GB with params: {'learning_rate': 0.1, 'n_estimators': 100, 'subsample': 0.1} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-12 08:04:13.979478: Running GB with params: {'learning_rate': 0.1, 'n_estimators': 100, 'subsample': 1.0} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-12 08:04:15.365474: Running ET with params: {'criterion': 'gini', 'max_depth': 2, 'n_estimators': 100} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-12 08:04:15.878745: Running ET with params: {'criterion': 'gini', 'max_depth': 2, 'n_estimators': 1000} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-12 08:04:17.568472: Running ET with params: {'criterion': 'gini', 'max_depth': 5, 'n_estimators': 100} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-12 08:04:18.054739: Running ET with params: {'criterion': 'gini', 'max_depth': 5, 'n_estimators': 1000} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-12 08:04:20.449423: Running ET with params: {'criterion': 'gini', 'max_depth': 50, 'n_estimators': 100} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-12 08:04:21.185979: Running ET with params: {'criterion': 'gini', 'max_depth': 50, 'n_estimators': 1000} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-12 08:04:24.220043: Running ET with params: {'criterion': 'entropy', 'max_depth': 2, 'n_estimators': 100} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-12 08:04:24.685567: Running ET with params: {'criterion': 'entropy', 'max_depth': 2, 'n_estimators': 1000} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-12 08:04:27.370850: Running ET with params: {'criterion': 'entropy', 'max_depth': 5, 'n_estimators': 100} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-12 08:04:27.845081: Running ET with params: {'criterion': 'entropy', 'max_depth': 5, 'n_estimators': 1000} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-12 08:04:29.512969: Running ET with params: {'criterion': 'entropy', 'max_depth': 50, 'n_estimators': 100} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-12 08:04:30.147931: Running ET with params: {'criterion': 'entropy', 'max_depth': 50, 'n_estimators': 1000} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-12 08:04:33.170360: Running LR with params: {'C': 0.001, 'penalty': 'l1'} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-12 08:04:35.856370: Running LR with params: {'C': 0.001, 'penalty': 'l2'} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-12 08:04:36.711477: Running LR with params: {'C': 0.1, 'penalty': 'l1'} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-12 08:05:04.766021: Running LR with params: {'C': 0.1, 'penalty': 'l2'} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-12 08:05:05.753594: Running LR with params: {'C': 1, 'penalty': 'l1'} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-12 08:05:33.982023: Running LR with params: {'C': 1, 'penalty': 'l2'} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-12 08:05:34.690696: Running LR with params: {'C': 10, 'penalty': 'l1'} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-12 08:06:49.631509: Running LR with params: {'C': 10, 'penalty': 'l2'} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-12 08:06:50.336458: Running DT with params: {'criterion': 'gini', 'max_depth': 2, 'min_samples_split': 2} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-12 08:06:50.624112: Running DT with params: {'criterion': 'gini', 'max_depth': 2, 'min_samples_split': 5} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-12 08:06:50.920159: Running DT with params: {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 2} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-12 08:06:51.261549: Running DT with params: {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 5} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-12 08:06:51.600116: Running DT with params: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 2} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-12 08:06:52.005651: Running DT with params: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 5} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-12 08:06:52.400461: Running DT with params: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 2} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-12 08:06:52.819607: Running DT with params: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 5} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-12 08:06:53.230091: Running DT with params: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 2} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-12 08:06:53.641608: Running DT with params: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 5} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-12 08:06:54.059960: Running DT with params: {'criterion': 'entropy', 'max_depth': 2, 'min_samples_split': 2} on train/test set 2007-01-01 00:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-12 08:06:54.347056: Running DT with params: {'criterion': 'entropy', 'max_depth': 2, 'min_samples_split': 5} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-12 08:06:54.641247: Running DT with params: {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 2} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-12 08:06:54.982122: Running DT with params: {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 5} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-12 08:06:55.314932: Running DT with params: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 2} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-12 08:06:55.684458: Running DT with params: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 5} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-12 08:06:56.055590: Running DT with params: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 2} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-12 08:06:56.437622: Running DT with params: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 5} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-12 08:06:56.824085: Running DT with params: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 2} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-12 08:06:57.211907: Running DT with params: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 5} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-12 08:06:57.595306: Running RF with params: {'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 2, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-12 08:06:58.420335: Running RF with params: {'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 2, 'n_estimators': 1000, 'n_jobs': -1} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-12 08:07:01.579472: Running RF with params: {'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-12 08:07:02.384708: Running RF with params: {'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 1000, 'n_jobs': -1} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-12 08:07:05.550438: Running RF with params: {'max_depth': 5, 'max_features': 'log2', 'min_samples_split': 2, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-12 08:07:06.135626: Running RF with params: {'max_depth': 5, 'max_features': 'log2', 'min_samples_split': 2, 'n_estimators': 1000, 'n_jobs': -1} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-12 08:07:09.310850: Running RF with params: {'max_depth': 5, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-12 08:07:09.885682: Running RF with params: {'max_depth': 5, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 1000, 'n_jobs': -1} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-12 08:07:13.252698: Running RF with params: {'max_depth': 50, 'max_features': 'sqrt', 'min_samples_split': 2, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-12 08:07:14.085931: Running RF with params: {'max_depth': 50, 'max_features': 'sqrt', 'min_samples_split': 2, 'n_estimators': 1000, 'n_jobs': -1} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-12 08:07:19.198896: Running RF with params: {'max_depth': 50, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-12 08:07:20.240645: Running RF with params: {'max_depth': 50, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 1000, 'n_jobs': -1} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-12 08:07:26.344578: Running RF with params: {'max_depth': 50, 'max_features': 'log2', 'min_samples_split': 2, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-12 08:07:27.059714: Running RF with params: {'max_depth': 50, 'max_features': 'log2', 'min_samples_split': 2, 'n_estimators': 1000, 'n_jobs': -1} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-12 08:07:31.340069: Running RF with params: {'max_depth': 50, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-12 08:07:32.057040: Running RF with params: {'max_depth': 50, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 1000, 'n_jobs': -1} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-12 08:07:36.199660: Running RF with params: {'max_depth': 100, 'max_features': 'sqrt', 'min_samples_split': 2, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-12 08:07:37.111373: Running RF with params: {'max_depth': 100, 'max_features': 'sqrt', 'min_samples_split': 2, 'n_estimators': 1000, 'n_jobs': -1} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-12 08:07:42.475045: Running RF with params: {'max_depth': 100, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-12 08:07:43.985762: Running RF with params: {'max_depth': 100, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 1000, 'n_jobs': -1} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-12 08:07:49.240742: Running RF with params: {'max_depth': 100, 'max_features': 'log2', 'min_samples_split': 2, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-12 08:07:50.008505: Running RF with params: {'max_depth': 100, 'max_features': 'log2', 'min_samples_split': 2, 'n_estimators': 1000, 'n_jobs': -1} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-12 08:07:53.848652: Running RF with params: {'max_depth': 100, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-12 08:07:54.660611: Running RF with params: {'max_depth': 100, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 1000, 'n_jobs': -1} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-12 08:07:58.403869: Running KNN with params: {'algorithm': 'auto', 'n_neighbors': 3, 'weights': 'uniform'} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-12 08:07:58.733909: Running KNN with params: {'algorithm': 'auto', 'n_neighbors': 3, 'weights': 'distance'} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-12 08:07:59.070598: Running KNN with params: {'algorithm': 'auto', 'n_neighbors': 5, 'weights': 'uniform'} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-12 08:07:59.440111: Running KNN with params: {'algorithm': 'auto', 'n_neighbors': 5, 'weights': 'distance'} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-12 08:07:59.815855: Running KNN with params: {'algorithm': 'auto', 'n_neighbors': 10, 'weights': 'uniform'} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-12 08:08:00.204939: Running KNN with params: {'algorithm': 'auto', 'n_neighbors': 10, 'weights': 'distance'} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-12 08:08:00.585827: Running KNN with params: {'algorithm': 'auto', 'n_neighbors': 50, 'weights': 'uniform'} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-12 08:08:01.032704: Running KNN with params: {'algorithm': 'auto', 'n_neighbors': 50, 'weights': 'distance'} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-12 08:08:01.492198: Running KNN with params: {'algorithm': 'auto', 'n_neighbors': 100, 'weights': 'uniform'} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-12 08:08:01.988669: Running KNN with params: {'algorithm': 'auto', 'n_neighbors': 100, 'weights': 'distance'} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-12 08:08:02.487212: Running KNN with params: {'algorithm': 'ball_tree', 'n_neighbors': 3, 'weights': 'uniform'} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-12 08:08:03.039465: Running KNN with params: {'algorithm': 'ball_tree', 'n_neighbors': 3, 'weights': 'distance'} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-12 08:08:03.569396: Running KNN with params: {'algorithm': 'ball_tree', 'n_neighbors': 5, 'weights': 'uniform'} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-12 08:08:04.120697: Running KNN with params: {'algorithm': 'ball_tree', 'n_neighbors': 5, 'weights': 'distance'} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-12 08:08:04.668437: Running KNN with params: {'algorithm': 'ball_tree', 'n_neighbors': 10, 'weights': 'uniform'} on train/test set 2007-01-01 00:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-12 08:08:05.247924: Running KNN with params: {'algorithm': 'ball_tree', 'n_neighbors': 10, 'weights': 'distance'} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-12 08:08:05.822764: Running KNN with params: {'algorithm': 'ball_tree', 'n_neighbors': 50, 'weights': 'uniform'} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-12 08:08:06.568941: Running KNN with params: {'algorithm': 'ball_tree', 'n_neighbors': 50, 'weights': 'distance'} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-12 08:08:07.321446: Running KNN with params: {'algorithm': 'ball_tree', 'n_neighbors': 100, 'weights': 'uniform'} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-12 08:08:08.134949: Running KNN with params: {'algorithm': 'ball_tree', 'n_neighbors': 100, 'weights': 'distance'} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-12 08:08:08.944483: Running NB with params: {} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-12 08:08:09.223887: Running BA with params: {'n_estimators': 10} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-12 08:08:10.977070: Running BA with params: {'n_estimators': 100} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-12 08:08:24.900213: Running AB with params: {'algorithm': 'SAMME', 'n_estimators': 10} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-12 08:08:25.293759: Running AB with params: {'algorithm': 'SAMME', 'n_estimators': 100} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-12 08:08:26.982199: Running AB with params: {'algorithm': 'SAMME.R', 'n_estimators': 10} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-12 08:08:27.378249: Running AB with params: {'algorithm': 'SAMME.R', 'n_estimators': 100} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-12 08:08:29.129506: Running GB with params: {'learning_rate': 0.001, 'n_estimators': 10, 'subsample': 0.1} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-12 08:08:29.482732: Running GB with params: {'learning_rate': 0.001, 'n_estimators': 10, 'subsample': 1.0} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-12 08:08:29.924126: Running GB with params: {'learning_rate': 0.001, 'n_estimators': 100, 'subsample': 0.1} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-12 08:08:31.072408: Running GB with params: {'learning_rate': 0.001, 'n_estimators': 100, 'subsample': 1.0} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-12 08:08:32.971692: Running GB with params: {'learning_rate': 0.1, 'n_estimators': 10, 'subsample': 0.1} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-12 08:08:33.328642: Running GB with params: {'learning_rate': 0.1, 'n_estimators': 10, 'subsample': 1.0} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-12 08:08:33.767616: Running GB with params: {'learning_rate': 0.1, 'n_estimators': 100, 'subsample': 0.1} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-12 08:08:34.856545: Running GB with params: {'learning_rate': 0.1, 'n_estimators': 100, 'subsample': 1.0} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-12 08:08:36.630458: Running ET with params: {'criterion': 'gini', 'max_depth': 2, 'n_estimators': 100} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-12 08:08:37.106653: Running ET with params: {'criterion': 'gini', 'max_depth': 2, 'n_estimators': 1000} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-12 08:08:39.286677: Running ET with params: {'criterion': 'gini', 'max_depth': 5, 'n_estimators': 100} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-12 08:08:39.729447: Running ET with params: {'criterion': 'gini', 'max_depth': 5, 'n_estimators': 1000} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-12 08:08:42.253861: Running ET with params: {'criterion': 'gini', 'max_depth': 50, 'n_estimators': 100} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-12 08:08:42.999022: Running ET with params: {'criterion': 'gini', 'max_depth': 50, 'n_estimators': 1000} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-12 08:08:47.263096: Running ET with params: {'criterion': 'entropy', 'max_depth': 2, 'n_estimators': 100} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-12 08:08:47.713663: Running ET with params: {'criterion': 'entropy', 'max_depth': 2, 'n_estimators': 1000} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-12 08:08:49.028611: Running ET with params: {'criterion': 'entropy', 'max_depth': 5, 'n_estimators': 100} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-12 08:08:49.593393: Running ET with params: {'criterion': 'entropy', 'max_depth': 5, 'n_estimators': 1000} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-12 08:08:52.355420: Running ET with params: {'criterion': 'entropy', 'max_depth': 50, 'n_estimators': 100} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-12 08:08:53.061320: Running ET with params: {'criterion': 'entropy', 'max_depth': 50, 'n_estimators': 1000} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-12 08:08:57.175654: Running LR with params: {'C': 0.001, 'penalty': 'l1'} on train/test set 2008-01-01 00:00:00\n",
      "2019-06-12 08:09:09.081764: Running LR with params: {'C': 0.001, 'penalty': 'l2'} on train/test set 2008-01-01 00:00:00\n",
      "2019-06-12 08:09:10.258627: Running LR with params: {'C': 0.1, 'penalty': 'l1'} on train/test set 2008-01-01 00:00:00\n",
      "2019-06-12 08:09:14.856636: Running LR with params: {'C': 0.1, 'penalty': 'l2'} on train/test set 2008-01-01 00:00:00\n",
      "2019-06-12 08:09:15.750033: Running LR with params: {'C': 1, 'penalty': 'l1'} on train/test set 2008-01-01 00:00:00\n",
      "2019-06-12 08:09:19.673083: Running LR with params: {'C': 1, 'penalty': 'l2'} on train/test set 2008-01-01 00:00:00\n",
      "2019-06-12 08:09:20.575842: Running LR with params: {'C': 10, 'penalty': 'l1'} on train/test set 2008-01-01 00:00:00\n",
      "2019-06-12 08:10:52.736858: Running LR with params: {'C': 10, 'penalty': 'l2'} on train/test set 2008-01-01 00:00:00\n",
      "2019-06-12 08:10:53.551654: Running DT with params: {'criterion': 'gini', 'max_depth': 2, 'min_samples_split': 2} on train/test set 2008-01-01 00:00:00\n",
      "2019-06-12 08:10:53.832764: Running DT with params: {'criterion': 'gini', 'max_depth': 2, 'min_samples_split': 5} on train/test set 2008-01-01 00:00:00\n",
      "2019-06-12 08:10:54.099278: Running DT with params: {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 2} on train/test set 2008-01-01 00:00:00\n",
      "2019-06-12 08:10:54.427874: Running DT with params: {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 5} on train/test set 2008-01-01 00:00:00\n",
      "2019-06-12 08:10:54.743399: Running DT with params: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 2} on train/test set 2008-01-01 00:00:00\n",
      "2019-06-12 08:10:55.126117: Running DT with params: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 5} on train/test set 2008-01-01 00:00:00\n",
      "2019-06-12 08:10:55.523168: Running DT with params: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 2} on train/test set 2008-01-01 00:00:00\n",
      "2019-06-12 08:10:55.936611: Running DT with params: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 5} on train/test set 2008-01-01 00:00:00\n",
      "2019-06-12 08:10:56.373586: Running DT with params: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 2} on train/test set 2008-01-01 00:00:00\n",
      "2019-06-12 08:10:56.794077: Running DT with params: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 5} on train/test set 2008-01-01 00:00:00\n",
      "2019-06-12 08:10:57.201312: Running DT with params: {'criterion': 'entropy', 'max_depth': 2, 'min_samples_split': 2} on train/test set 2008-01-01 00:00:00\n",
      "2019-06-12 08:10:57.486911: Running DT with params: {'criterion': 'entropy', 'max_depth': 2, 'min_samples_split': 5} on train/test set 2008-01-01 00:00:00\n",
      "2019-06-12 08:10:57.762153: Running DT with params: {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 2} on train/test set 2008-01-01 00:00:00\n",
      "2019-06-12 08:10:58.089768: Running DT with params: {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 5} on train/test set 2008-01-01 00:00:00\n",
      "2019-06-12 08:10:58.436103: Running DT with params: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 2} on train/test set 2008-01-01 00:00:00\n",
      "2019-06-12 08:10:58.826876: Running DT with params: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 5} on train/test set 2008-01-01 00:00:00\n",
      "2019-06-12 08:10:59.213875: Running DT with params: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 2} on train/test set 2008-01-01 00:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-12 08:10:59.629907: Running DT with params: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 5} on train/test set 2008-01-01 00:00:00\n",
      "2019-06-12 08:11:00.033094: Running DT with params: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 2} on train/test set 2008-01-01 00:00:00\n",
      "2019-06-12 08:11:00.453225: Running DT with params: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 5} on train/test set 2008-01-01 00:00:00\n",
      "2019-06-12 08:11:00.856599: Running RF with params: {'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 2, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2008-01-01 00:00:00\n",
      "2019-06-12 08:11:01.616826: Running RF with params: {'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 2, 'n_estimators': 1000, 'n_jobs': -1} on train/test set 2008-01-01 00:00:00\n",
      "2019-06-12 08:11:05.391118: Running RF with params: {'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2008-01-01 00:00:00\n",
      "2019-06-12 08:11:06.112445: Running RF with params: {'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 1000, 'n_jobs': -1} on train/test set 2008-01-01 00:00:00\n",
      "2019-06-12 08:11:10.489368: Running RF with params: {'max_depth': 5, 'max_features': 'log2', 'min_samples_split': 2, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2008-01-01 00:00:00\n",
      "2019-06-12 08:11:11.190128: Running RF with params: {'max_depth': 5, 'max_features': 'log2', 'min_samples_split': 2, 'n_estimators': 1000, 'n_jobs': -1} on train/test set 2008-01-01 00:00:00\n",
      "2019-06-12 08:11:14.609989: Running RF with params: {'max_depth': 5, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2008-01-01 00:00:00\n",
      "2019-06-12 08:11:15.207326: Running RF with params: {'max_depth': 5, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 1000, 'n_jobs': -1} on train/test set 2008-01-01 00:00:00\n",
      "2019-06-12 08:11:18.097126: Running RF with params: {'max_depth': 50, 'max_features': 'sqrt', 'min_samples_split': 2, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2008-01-01 00:00:00\n",
      "2019-06-12 08:11:19.123336: Running RF with params: {'max_depth': 50, 'max_features': 'sqrt', 'min_samples_split': 2, 'n_estimators': 1000, 'n_jobs': -1} on train/test set 2008-01-01 00:00:00\n",
      "2019-06-12 08:11:26.358268: Running RF with params: {'max_depth': 50, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2008-01-01 00:00:00\n",
      "2019-06-12 08:11:27.315578: Running RF with params: {'max_depth': 50, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 1000, 'n_jobs': -1} on train/test set 2008-01-01 00:00:00\n",
      "2019-06-12 08:11:33.488875: Running RF with params: {'max_depth': 50, 'max_features': 'log2', 'min_samples_split': 2, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2008-01-01 00:00:00\n",
      "2019-06-12 08:11:34.328485: Running RF with params: {'max_depth': 50, 'max_features': 'log2', 'min_samples_split': 2, 'n_estimators': 1000, 'n_jobs': -1} on train/test set 2008-01-01 00:00:00\n",
      "2019-06-12 08:11:39.057249: Running RF with params: {'max_depth': 50, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2008-01-01 00:00:00\n",
      "2019-06-12 08:11:39.899826: Running RF with params: {'max_depth': 50, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 1000, 'n_jobs': -1} on train/test set 2008-01-01 00:00:00\n",
      "2019-06-12 08:11:44.445567: Running RF with params: {'max_depth': 100, 'max_features': 'sqrt', 'min_samples_split': 2, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2008-01-01 00:00:00\n",
      "2019-06-12 08:11:45.364591: Running RF with params: {'max_depth': 100, 'max_features': 'sqrt', 'min_samples_split': 2, 'n_estimators': 1000, 'n_jobs': -1} on train/test set 2008-01-01 00:00:00\n",
      "2019-06-12 08:11:51.764140: Running RF with params: {'max_depth': 100, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2008-01-01 00:00:00\n",
      "2019-06-12 08:11:52.715560: Running RF with params: {'max_depth': 100, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 1000, 'n_jobs': -1} on train/test set 2008-01-01 00:00:00\n",
      "2019-06-12 08:11:59.431092: Running RF with params: {'max_depth': 100, 'max_features': 'log2', 'min_samples_split': 2, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2008-01-01 00:00:00\n",
      "2019-06-12 08:12:00.279183: Running RF with params: {'max_depth': 100, 'max_features': 'log2', 'min_samples_split': 2, 'n_estimators': 1000, 'n_jobs': -1} on train/test set 2008-01-01 00:00:00\n",
      "2019-06-12 08:12:05.353474: Running RF with params: {'max_depth': 100, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2008-01-01 00:00:00\n",
      "2019-06-12 08:12:06.060738: Running RF with params: {'max_depth': 100, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 1000, 'n_jobs': -1} on train/test set 2008-01-01 00:00:00\n",
      "2019-06-12 08:12:11.252998: Running KNN with params: {'algorithm': 'auto', 'n_neighbors': 3, 'weights': 'uniform'} on train/test set 2008-01-01 00:00:00\n",
      "2019-06-12 08:12:11.585069: Running KNN with params: {'algorithm': 'auto', 'n_neighbors': 3, 'weights': 'distance'} on train/test set 2008-01-01 00:00:00\n",
      "2019-06-12 08:12:11.919786: Running KNN with params: {'algorithm': 'auto', 'n_neighbors': 5, 'weights': 'uniform'} on train/test set 2008-01-01 00:00:00\n",
      "2019-06-12 08:12:12.255058: Running KNN with params: {'algorithm': 'auto', 'n_neighbors': 5, 'weights': 'distance'} on train/test set 2008-01-01 00:00:00\n",
      "2019-06-12 08:12:12.584666: Running KNN with params: {'algorithm': 'auto', 'n_neighbors': 10, 'weights': 'uniform'} on train/test set 2008-01-01 00:00:00\n",
      "2019-06-12 08:12:12.928063: Running KNN with params: {'algorithm': 'auto', 'n_neighbors': 10, 'weights': 'distance'} on train/test set 2008-01-01 00:00:00\n",
      "2019-06-12 08:12:13.288433: Running KNN with params: {'algorithm': 'auto', 'n_neighbors': 50, 'weights': 'uniform'} on train/test set 2008-01-01 00:00:00\n",
      "2019-06-12 08:12:13.724272: Running KNN with params: {'algorithm': 'auto', 'n_neighbors': 50, 'weights': 'distance'} on train/test set 2008-01-01 00:00:00\n",
      "2019-06-12 08:12:14.187856: Running KNN with params: {'algorithm': 'auto', 'n_neighbors': 100, 'weights': 'uniform'} on train/test set 2008-01-01 00:00:00\n",
      "2019-06-12 08:12:14.723472: Running KNN with params: {'algorithm': 'auto', 'n_neighbors': 100, 'weights': 'distance'} on train/test set 2008-01-01 00:00:00\n",
      "2019-06-12 08:12:15.259648: Running KNN with params: {'algorithm': 'ball_tree', 'n_neighbors': 3, 'weights': 'uniform'} on train/test set 2008-01-01 00:00:00\n",
      "2019-06-12 08:12:15.781865: Running KNN with params: {'algorithm': 'ball_tree', 'n_neighbors': 3, 'weights': 'distance'} on train/test set 2008-01-01 00:00:00\n",
      "2019-06-12 08:12:16.304334: Running KNN with params: {'algorithm': 'ball_tree', 'n_neighbors': 5, 'weights': 'uniform'} on train/test set 2008-01-01 00:00:00\n",
      "2019-06-12 08:12:16.821846: Running KNN with params: {'algorithm': 'ball_tree', 'n_neighbors': 5, 'weights': 'distance'} on train/test set 2008-01-01 00:00:00\n",
      "2019-06-12 08:12:17.354384: Running KNN with params: {'algorithm': 'ball_tree', 'n_neighbors': 10, 'weights': 'uniform'} on train/test set 2008-01-01 00:00:00\n",
      "2019-06-12 08:12:17.907711: Running KNN with params: {'algorithm': 'ball_tree', 'n_neighbors': 10, 'weights': 'distance'} on train/test set 2008-01-01 00:00:00\n",
      "2019-06-12 08:12:18.476148: Running KNN with params: {'algorithm': 'ball_tree', 'n_neighbors': 50, 'weights': 'uniform'} on train/test set 2008-01-01 00:00:00\n",
      "2019-06-12 08:12:19.179889: Running KNN with params: {'algorithm': 'ball_tree', 'n_neighbors': 50, 'weights': 'distance'} on train/test set 2008-01-01 00:00:00\n",
      "2019-06-12 08:12:19.926744: Running KNN with params: {'algorithm': 'ball_tree', 'n_neighbors': 100, 'weights': 'uniform'} on train/test set 2008-01-01 00:00:00\n",
      "2019-06-12 08:12:20.779857: Running KNN with params: {'algorithm': 'ball_tree', 'n_neighbors': 100, 'weights': 'distance'} on train/test set 2008-01-01 00:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-12 08:12:21.629425: Running NB with params: {} on train/test set 2008-01-01 00:00:00\n",
      "2019-06-12 08:12:21.904828: Running BA with params: {'n_estimators': 10} on train/test set 2008-01-01 00:00:00\n",
      "2019-06-12 08:12:23.701358: Running BA with params: {'n_estimators': 100} on train/test set 2008-01-01 00:00:00\n",
      "2019-06-12 08:12:38.635124: Running AB with params: {'algorithm': 'SAMME', 'n_estimators': 10} on train/test set 2008-01-01 00:00:00\n",
      "2019-06-12 08:12:39.051056: Running AB with params: {'algorithm': 'SAMME', 'n_estimators': 100} on train/test set 2008-01-01 00:00:00\n",
      "2019-06-12 08:12:41.086487: Running AB with params: {'algorithm': 'SAMME.R', 'n_estimators': 10} on train/test set 2008-01-01 00:00:00\n",
      "2019-06-12 08:12:41.511205: Running AB with params: {'algorithm': 'SAMME.R', 'n_estimators': 100} on train/test set 2008-01-01 00:00:00\n",
      "2019-06-12 08:12:43.597593: Running GB with params: {'learning_rate': 0.001, 'n_estimators': 10, 'subsample': 0.1} on train/test set 2008-01-01 00:00:00\n",
      "2019-06-12 08:12:43.977515: Running GB with params: {'learning_rate': 0.001, 'n_estimators': 10, 'subsample': 1.0} on train/test set 2008-01-01 00:00:00\n",
      "2019-06-12 08:12:44.448814: Running GB with params: {'learning_rate': 0.001, 'n_estimators': 100, 'subsample': 0.1} on train/test set 2008-01-01 00:00:00\n",
      "2019-06-12 08:12:45.832366: Running GB with params: {'learning_rate': 0.001, 'n_estimators': 100, 'subsample': 1.0} on train/test set 2008-01-01 00:00:00\n",
      "2019-06-12 08:12:48.148801: Running GB with params: {'learning_rate': 0.1, 'n_estimators': 10, 'subsample': 0.1} on train/test set 2008-01-01 00:00:00\n",
      "2019-06-12 08:12:48.533691: Running GB with params: {'learning_rate': 0.1, 'n_estimators': 10, 'subsample': 1.0} on train/test set 2008-01-01 00:00:00\n",
      "2019-06-12 08:12:49.006310: Running GB with params: {'learning_rate': 0.1, 'n_estimators': 100, 'subsample': 0.1} on train/test set 2008-01-01 00:00:00\n",
      "2019-06-12 08:12:50.352705: Running GB with params: {'learning_rate': 0.1, 'n_estimators': 100, 'subsample': 1.0} on train/test set 2008-01-01 00:00:00\n",
      "2019-06-12 08:12:52.502574: Running ET with params: {'criterion': 'gini', 'max_depth': 2, 'n_estimators': 100} on train/test set 2008-01-01 00:00:00\n",
      "2019-06-12 08:12:52.964815: Running ET with params: {'criterion': 'gini', 'max_depth': 2, 'n_estimators': 1000} on train/test set 2008-01-01 00:00:00\n",
      "2019-06-12 08:12:55.339714: Running ET with params: {'criterion': 'gini', 'max_depth': 5, 'n_estimators': 100} on train/test set 2008-01-01 00:00:00\n",
      "2019-06-12 08:12:55.914258: Running ET with params: {'criterion': 'gini', 'max_depth': 5, 'n_estimators': 1000} on train/test set 2008-01-01 00:00:00\n",
      "2019-06-12 08:12:58.612990: Running ET with params: {'criterion': 'gini', 'max_depth': 50, 'n_estimators': 100} on train/test set 2008-01-01 00:00:00\n",
      "2019-06-12 08:12:59.345711: Running ET with params: {'criterion': 'gini', 'max_depth': 50, 'n_estimators': 1000} on train/test set 2008-01-01 00:00:00\n",
      "2019-06-12 08:13:03.590955: Running ET with params: {'criterion': 'entropy', 'max_depth': 2, 'n_estimators': 100} on train/test set 2008-01-01 00:00:00\n",
      "2019-06-12 08:13:04.047074: Running ET with params: {'criterion': 'entropy', 'max_depth': 2, 'n_estimators': 1000} on train/test set 2008-01-01 00:00:00\n",
      "2019-06-12 08:13:06.287958: Running ET with params: {'criterion': 'entropy', 'max_depth': 5, 'n_estimators': 100} on train/test set 2008-01-01 00:00:00\n",
      "2019-06-12 08:13:06.873644: Running ET with params: {'criterion': 'entropy', 'max_depth': 5, 'n_estimators': 1000} on train/test set 2008-01-01 00:00:00\n",
      "2019-06-12 08:13:09.474517: Running ET with params: {'criterion': 'entropy', 'max_depth': 50, 'n_estimators': 100} on train/test set 2008-01-01 00:00:00\n",
      "2019-06-12 08:13:10.196586: Running ET with params: {'criterion': 'entropy', 'max_depth': 50, 'n_estimators': 1000} on train/test set 2008-01-01 00:00:00\n",
      "2019-06-12 08:13:14.881203: Running LR with params: {'C': 0.001, 'penalty': 'l1'} on train/test set 2009-01-01 00:00:00\n",
      "2019-06-12 08:13:18.580566: Running LR with params: {'C': 0.001, 'penalty': 'l2'} on train/test set 2009-01-01 00:00:00\n",
      "2019-06-12 08:13:19.601566: Running LR with params: {'C': 0.1, 'penalty': 'l1'} on train/test set 2009-01-01 00:00:00\n",
      "2019-06-12 08:13:25.232327: Running LR with params: {'C': 0.1, 'penalty': 'l2'} on train/test set 2009-01-01 00:00:00\n",
      "2019-06-12 08:13:26.219670: Running LR with params: {'C': 1, 'penalty': 'l1'} on train/test set 2009-01-01 00:00:00\n",
      "2019-06-12 08:13:34.444155: Running LR with params: {'C': 1, 'penalty': 'l2'} on train/test set 2009-01-01 00:00:00\n",
      "2019-06-12 08:13:35.404339: Running LR with params: {'C': 10, 'penalty': 'l1'} on train/test set 2009-01-01 00:00:00\n",
      "2019-06-12 08:16:00.188806: Running LR with params: {'C': 10, 'penalty': 'l2'} on train/test set 2009-01-01 00:00:00\n",
      "2019-06-12 08:16:02.251557: Running DT with params: {'criterion': 'gini', 'max_depth': 2, 'min_samples_split': 2} on train/test set 2009-01-01 00:00:00\n",
      "2019-06-12 08:16:02.794694: Running DT with params: {'criterion': 'gini', 'max_depth': 2, 'min_samples_split': 5} on train/test set 2009-01-01 00:00:00\n",
      "2019-06-12 08:16:03.250368: Running DT with params: {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 2} on train/test set 2009-01-01 00:00:00\n",
      "2019-06-12 08:16:03.785100: Running DT with params: {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 5} on train/test set 2009-01-01 00:00:00\n",
      "2019-06-12 08:16:04.263418: Running DT with params: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 2} on train/test set 2009-01-01 00:00:00\n",
      "2019-06-12 08:16:05.342344: Running DT with params: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 5} on train/test set 2009-01-01 00:00:00\n",
      "2019-06-12 08:16:06.388279: Running DT with params: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 2} on train/test set 2009-01-01 00:00:00\n",
      "2019-06-12 08:16:07.044288: Running DT with params: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 5} on train/test set 2009-01-01 00:00:00\n",
      "2019-06-12 08:16:07.592057: Running DT with params: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 2} on train/test set 2009-01-01 00:00:00\n",
      "2019-06-12 08:16:08.130845: Running DT with params: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 5} on train/test set 2009-01-01 00:00:00\n",
      "2019-06-12 08:16:08.678811: Running DT with params: {'criterion': 'entropy', 'max_depth': 2, 'min_samples_split': 2} on train/test set 2009-01-01 00:00:00\n",
      "2019-06-12 08:16:09.069475: Running DT with params: {'criterion': 'entropy', 'max_depth': 2, 'min_samples_split': 5} on train/test set 2009-01-01 00:00:00\n",
      "2019-06-12 08:16:09.628476: Running DT with params: {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 2} on train/test set 2009-01-01 00:00:00\n",
      "2019-06-12 08:16:10.328388: Running DT with params: {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 5} on train/test set 2009-01-01 00:00:00\n",
      "2019-06-12 08:16:10.866342: Running DT with params: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 2} on train/test set 2009-01-01 00:00:00\n",
      "2019-06-12 08:16:11.368725: Running DT with params: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 5} on train/test set 2009-01-01 00:00:00\n",
      "2019-06-12 08:16:12.038994: Running DT with params: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 2} on train/test set 2009-01-01 00:00:00\n",
      "2019-06-12 08:16:13.262721: Running DT with params: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 5} on train/test set 2009-01-01 00:00:00\n",
      "2019-06-12 08:16:13.871340: Running DT with params: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 2} on train/test set 2009-01-01 00:00:00\n",
      "2019-06-12 08:16:14.701534: Running DT with params: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 5} on train/test set 2009-01-01 00:00:00\n",
      "2019-06-12 08:16:15.823651: Running RF with params: {'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 2, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2009-01-01 00:00:00\n",
      "2019-06-12 08:16:16.934071: Running RF with params: {'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 2, 'n_estimators': 1000, 'n_jobs': -1} on train/test set 2009-01-01 00:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-12 08:16:22.653695: Running RF with params: {'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2009-01-01 00:00:00\n",
      "2019-06-12 08:16:23.501414: Running RF with params: {'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 1000, 'n_jobs': -1} on train/test set 2009-01-01 00:00:00\n",
      "2019-06-12 08:16:28.551446: Running RF with params: {'max_depth': 5, 'max_features': 'log2', 'min_samples_split': 2, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2009-01-01 00:00:00\n",
      "2019-06-12 08:16:29.527074: Running RF with params: {'max_depth': 5, 'max_features': 'log2', 'min_samples_split': 2, 'n_estimators': 1000, 'n_jobs': -1} on train/test set 2009-01-01 00:00:00\n",
      "2019-06-12 08:16:33.880710: Running RF with params: {'max_depth': 5, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2009-01-01 00:00:00\n",
      "2019-06-12 08:16:35.159346: Running RF with params: {'max_depth': 5, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 1000, 'n_jobs': -1} on train/test set 2009-01-01 00:00:00\n",
      "2019-06-12 08:16:43.862327: Running RF with params: {'max_depth': 50, 'max_features': 'sqrt', 'min_samples_split': 2, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2009-01-01 00:00:00\n",
      "2019-06-12 08:16:46.838772: Running RF with params: {'max_depth': 50, 'max_features': 'sqrt', 'min_samples_split': 2, 'n_estimators': 1000, 'n_jobs': -1} on train/test set 2009-01-01 00:00:00\n",
      "2019-06-12 08:16:59.213440: Running RF with params: {'max_depth': 50, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2009-01-01 00:00:00\n",
      "2019-06-12 08:17:00.726574: Running RF with params: {'max_depth': 50, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 1000, 'n_jobs': -1} on train/test set 2009-01-01 00:00:00\n",
      "2019-06-12 08:17:14.105041: Running RF with params: {'max_depth': 50, 'max_features': 'log2', 'min_samples_split': 2, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2009-01-01 00:00:00\n",
      "2019-06-12 08:17:16.259831: Running RF with params: {'max_depth': 50, 'max_features': 'log2', 'min_samples_split': 2, 'n_estimators': 1000, 'n_jobs': -1} on train/test set 2009-01-01 00:00:00\n",
      "2019-06-12 08:17:24.072905: Running RF with params: {'max_depth': 50, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2009-01-01 00:00:00\n",
      "2019-06-12 08:17:25.073587: Running RF with params: {'max_depth': 50, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 1000, 'n_jobs': -1} on train/test set 2009-01-01 00:00:00\n",
      "2019-06-12 08:17:31.371212: Running RF with params: {'max_depth': 100, 'max_features': 'sqrt', 'min_samples_split': 2, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2009-01-01 00:00:00\n",
      "2019-06-12 08:17:33.046568: Running RF with params: {'max_depth': 100, 'max_features': 'sqrt', 'min_samples_split': 2, 'n_estimators': 1000, 'n_jobs': -1} on train/test set 2009-01-01 00:00:00\n",
      "2019-06-12 08:17:44.516690: Running RF with params: {'max_depth': 100, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2009-01-01 00:00:00\n",
      "2019-06-12 08:17:45.886553: Running RF with params: {'max_depth': 100, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 1000, 'n_jobs': -1} on train/test set 2009-01-01 00:00:00\n",
      "2019-06-12 08:17:55.471576: Running RF with params: {'max_depth': 100, 'max_features': 'log2', 'min_samples_split': 2, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2009-01-01 00:00:00\n",
      "2019-06-12 08:17:56.635250: Running RF with params: {'max_depth': 100, 'max_features': 'log2', 'min_samples_split': 2, 'n_estimators': 1000, 'n_jobs': -1} on train/test set 2009-01-01 00:00:00\n",
      "2019-06-12 08:18:03.397609: Running RF with params: {'max_depth': 100, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2009-01-01 00:00:00\n",
      "2019-06-12 08:18:04.517975: Running RF with params: {'max_depth': 100, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 1000, 'n_jobs': -1} on train/test set 2009-01-01 00:00:00\n",
      "2019-06-12 08:18:11.153074: Running KNN with params: {'algorithm': 'auto', 'n_neighbors': 3, 'weights': 'uniform'} on train/test set 2009-01-01 00:00:00\n",
      "2019-06-12 08:18:11.529074: Running KNN with params: {'algorithm': 'auto', 'n_neighbors': 3, 'weights': 'distance'} on train/test set 2009-01-01 00:00:00\n",
      "2019-06-12 08:18:12.466863: Running KNN with params: {'algorithm': 'auto', 'n_neighbors': 5, 'weights': 'uniform'} on train/test set 2009-01-01 00:00:00\n",
      "2019-06-12 08:18:12.970877: Running KNN with params: {'algorithm': 'auto', 'n_neighbors': 5, 'weights': 'distance'} on train/test set 2009-01-01 00:00:00\n",
      "2019-06-12 08:18:13.422223: Running KNN with params: {'algorithm': 'auto', 'n_neighbors': 10, 'weights': 'uniform'} on train/test set 2009-01-01 00:00:00\n",
      "2019-06-12 08:18:13.891445: Running KNN with params: {'algorithm': 'auto', 'n_neighbors': 10, 'weights': 'distance'} on train/test set 2009-01-01 00:00:00\n",
      "2019-06-12 08:18:14.405991: Running KNN with params: {'algorithm': 'auto', 'n_neighbors': 50, 'weights': 'uniform'} on train/test set 2009-01-01 00:00:00\n",
      "2019-06-12 08:18:15.053336: Running KNN with params: {'algorithm': 'auto', 'n_neighbors': 50, 'weights': 'distance'} on train/test set 2009-01-01 00:00:00\n",
      "2019-06-12 08:18:15.665018: Running KNN with params: {'algorithm': 'auto', 'n_neighbors': 100, 'weights': 'uniform'} on train/test set 2009-01-01 00:00:00\n",
      "2019-06-12 08:18:16.425472: Running KNN with params: {'algorithm': 'auto', 'n_neighbors': 100, 'weights': 'distance'} on train/test set 2009-01-01 00:00:00\n",
      "2019-06-12 08:18:17.153073: Running KNN with params: {'algorithm': 'ball_tree', 'n_neighbors': 3, 'weights': 'uniform'} on train/test set 2009-01-01 00:00:00\n",
      "2019-06-12 08:18:17.958472: Running KNN with params: {'algorithm': 'ball_tree', 'n_neighbors': 3, 'weights': 'distance'} on train/test set 2009-01-01 00:00:00\n",
      "2019-06-12 08:18:18.910267: Running KNN with params: {'algorithm': 'ball_tree', 'n_neighbors': 5, 'weights': 'uniform'} on train/test set 2009-01-01 00:00:00\n",
      "2019-06-12 08:18:19.813481: Running KNN with params: {'algorithm': 'ball_tree', 'n_neighbors': 5, 'weights': 'distance'} on train/test set 2009-01-01 00:00:00\n",
      "2019-06-12 08:18:20.617684: Running KNN with params: {'algorithm': 'ball_tree', 'n_neighbors': 10, 'weights': 'uniform'} on train/test set 2009-01-01 00:00:00\n",
      "2019-06-12 08:18:21.503328: Running KNN with params: {'algorithm': 'ball_tree', 'n_neighbors': 10, 'weights': 'distance'} on train/test set 2009-01-01 00:00:00\n",
      "2019-06-12 08:18:22.319039: Running KNN with params: {'algorithm': 'ball_tree', 'n_neighbors': 50, 'weights': 'uniform'} on train/test set 2009-01-01 00:00:00\n",
      "2019-06-12 08:18:23.282323: Running KNN with params: {'algorithm': 'ball_tree', 'n_neighbors': 50, 'weights': 'distance'} on train/test set 2009-01-01 00:00:00\n",
      "2019-06-12 08:18:24.686689: Running KNN with params: {'algorithm': 'ball_tree', 'n_neighbors': 100, 'weights': 'uniform'} on train/test set 2009-01-01 00:00:00\n",
      "2019-06-12 08:18:25.916350: Running KNN with params: {'algorithm': 'ball_tree', 'n_neighbors': 100, 'weights': 'distance'} on train/test set 2009-01-01 00:00:00\n",
      "2019-06-12 08:18:27.279365: Running NB with params: {} on train/test set 2009-01-01 00:00:00\n",
      "2019-06-12 08:18:27.668257: Running BA with params: {'n_estimators': 10} on train/test set 2009-01-01 00:00:00\n",
      "2019-06-12 08:18:30.145707: Running BA with params: {'n_estimators': 100} on train/test set 2009-01-01 00:00:00\n",
      "2019-06-12 08:18:52.319085: Running AB with params: {'algorithm': 'SAMME', 'n_estimators': 10} on train/test set 2009-01-01 00:00:00\n",
      "2019-06-12 08:18:52.818112: Running AB with params: {'algorithm': 'SAMME', 'n_estimators': 100} on train/test set 2009-01-01 00:00:00\n",
      "2019-06-12 08:18:55.923671: Running AB with params: {'algorithm': 'SAMME.R', 'n_estimators': 10} on train/test set 2009-01-01 00:00:00\n",
      "2019-06-12 08:18:56.446888: Running AB with params: {'algorithm': 'SAMME.R', 'n_estimators': 100} on train/test set 2009-01-01 00:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-12 08:18:59.978646: Running GB with params: {'learning_rate': 0.001, 'n_estimators': 10, 'subsample': 0.1} on train/test set 2009-01-01 00:00:00\n",
      "2019-06-12 08:19:00.892779: Running GB with params: {'learning_rate': 0.001, 'n_estimators': 10, 'subsample': 1.0} on train/test set 2009-01-01 00:00:00\n",
      "2019-06-12 08:19:02.524329: Running GB with params: {'learning_rate': 0.001, 'n_estimators': 100, 'subsample': 0.1} on train/test set 2009-01-01 00:00:00\n",
      "2019-06-12 08:19:05.664000: Running GB with params: {'learning_rate': 0.001, 'n_estimators': 100, 'subsample': 1.0} on train/test set 2009-01-01 00:00:00\n",
      "2019-06-12 08:19:09.396831: Running GB with params: {'learning_rate': 0.1, 'n_estimators': 10, 'subsample': 0.1} on train/test set 2009-01-01 00:00:00\n",
      "2019-06-12 08:19:09.852957: Running GB with params: {'learning_rate': 0.1, 'n_estimators': 10, 'subsample': 1.0} on train/test set 2009-01-01 00:00:00\n",
      "2019-06-12 08:19:10.559401: Running GB with params: {'learning_rate': 0.1, 'n_estimators': 100, 'subsample': 0.1} on train/test set 2009-01-01 00:00:00\n",
      "2019-06-12 08:19:12.179829: Running GB with params: {'learning_rate': 0.1, 'n_estimators': 100, 'subsample': 1.0} on train/test set 2009-01-01 00:00:00\n",
      "2019-06-12 08:19:15.376256: Running ET with params: {'criterion': 'gini', 'max_depth': 2, 'n_estimators': 100} on train/test set 2009-01-01 00:00:00\n",
      "2019-06-12 08:19:16.177941: Running ET with params: {'criterion': 'gini', 'max_depth': 2, 'n_estimators': 1000} on train/test set 2009-01-01 00:00:00\n",
      "2019-06-12 08:19:20.325867: Running ET with params: {'criterion': 'gini', 'max_depth': 5, 'n_estimators': 100} on train/test set 2009-01-01 00:00:00\n",
      "2019-06-12 08:19:21.411354: Running ET with params: {'criterion': 'gini', 'max_depth': 5, 'n_estimators': 1000} on train/test set 2009-01-01 00:00:00\n",
      "2019-06-12 08:19:24.894078: Running ET with params: {'criterion': 'gini', 'max_depth': 50, 'n_estimators': 100} on train/test set 2009-01-01 00:00:00\n",
      "2019-06-12 08:19:25.851969: Running ET with params: {'criterion': 'gini', 'max_depth': 50, 'n_estimators': 1000} on train/test set 2009-01-01 00:00:00\n",
      "2019-06-12 08:19:33.158982: Running ET with params: {'criterion': 'entropy', 'max_depth': 2, 'n_estimators': 100} on train/test set 2009-01-01 00:00:00\n",
      "2019-06-12 08:19:33.692566: Running ET with params: {'criterion': 'entropy', 'max_depth': 2, 'n_estimators': 1000} on train/test set 2009-01-01 00:00:00\n",
      "2019-06-12 08:19:35.810066: Running ET with params: {'criterion': 'entropy', 'max_depth': 5, 'n_estimators': 100} on train/test set 2009-01-01 00:00:00\n",
      "2019-06-12 08:19:36.402624: Running ET with params: {'criterion': 'entropy', 'max_depth': 5, 'n_estimators': 1000} on train/test set 2009-01-01 00:00:00\n",
      "2019-06-12 08:19:39.384724: Running ET with params: {'criterion': 'entropy', 'max_depth': 50, 'n_estimators': 100} on train/test set 2009-01-01 00:00:00\n",
      "2019-06-12 08:19:40.220412: Running ET with params: {'criterion': 'entropy', 'max_depth': 50, 'n_estimators': 1000} on train/test set 2009-01-01 00:00:00\n",
      "2019-06-12 08:19:46.191965: Running LR with params: {'C': 0.001, 'penalty': 'l1'} on train/test set 2010-01-01 00:00:00\n",
      "2019-06-12 08:19:51.482568: Running LR with params: {'C': 0.001, 'penalty': 'l2'} on train/test set 2010-01-01 00:00:00\n",
      "2019-06-12 08:19:52.601743: Running LR with params: {'C': 0.1, 'penalty': 'l1'} on train/test set 2010-01-01 00:00:00\n",
      "2019-06-12 08:20:00.711986: Running LR with params: {'C': 0.1, 'penalty': 'l2'} on train/test set 2010-01-01 00:00:00\n",
      "2019-06-12 08:20:01.892886: Running LR with params: {'C': 1, 'penalty': 'l1'} on train/test set 2010-01-01 00:00:00\n",
      "2019-06-12 08:20:11.835160: Running LR with params: {'C': 1, 'penalty': 'l2'} on train/test set 2010-01-01 00:00:00\n",
      "2019-06-12 08:20:12.911719: Running LR with params: {'C': 10, 'penalty': 'l1'} on train/test set 2010-01-01 00:00:00\n",
      "2019-06-12 08:22:34.275814: Running LR with params: {'C': 10, 'penalty': 'l2'} on train/test set 2010-01-01 00:00:00\n",
      "2019-06-12 08:22:35.544115: Running DT with params: {'criterion': 'gini', 'max_depth': 2, 'min_samples_split': 2} on train/test set 2010-01-01 00:00:00\n",
      "2019-06-12 08:22:35.872139: Running DT with params: {'criterion': 'gini', 'max_depth': 2, 'min_samples_split': 5} on train/test set 2010-01-01 00:00:00\n",
      "2019-06-12 08:22:36.189190: Running DT with params: {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 2} on train/test set 2010-01-01 00:00:00\n",
      "2019-06-12 08:22:36.575522: Running DT with params: {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 5} on train/test set 2010-01-01 00:00:00\n",
      "2019-06-12 08:22:36.962889: Running DT with params: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 2} on train/test set 2010-01-01 00:00:00\n",
      "2019-06-12 08:22:37.457188: Running DT with params: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 5} on train/test set 2010-01-01 00:00:00\n",
      "2019-06-12 08:22:37.950368: Running DT with params: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 2} on train/test set 2010-01-01 00:00:00\n",
      "2019-06-12 08:22:38.543152: Running DT with params: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 5} on train/test set 2010-01-01 00:00:00\n",
      "2019-06-12 08:22:39.142746: Running DT with params: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 2} on train/test set 2010-01-01 00:00:00\n",
      "2019-06-12 08:22:39.737821: Running DT with params: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 5} on train/test set 2010-01-01 00:00:00\n",
      "2019-06-12 08:22:40.330140: Running DT with params: {'criterion': 'entropy', 'max_depth': 2, 'min_samples_split': 2} on train/test set 2010-01-01 00:00:00\n",
      "2019-06-12 08:22:40.642108: Running DT with params: {'criterion': 'entropy', 'max_depth': 2, 'min_samples_split': 5} on train/test set 2010-01-01 00:00:00\n",
      "2019-06-12 08:22:40.966870: Running DT with params: {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 2} on train/test set 2010-01-01 00:00:00\n",
      "2019-06-12 08:22:41.391563: Running DT with params: {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 5} on train/test set 2010-01-01 00:00:00\n",
      "2019-06-12 08:22:41.809971: Running DT with params: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 2} on train/test set 2010-01-01 00:00:00\n",
      "2019-06-12 08:22:42.336819: Running DT with params: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 5} on train/test set 2010-01-01 00:00:00\n",
      "2019-06-12 08:22:42.857619: Running DT with params: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 2} on train/test set 2010-01-01 00:00:00\n",
      "2019-06-12 08:22:43.417055: Running DT with params: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 5} on train/test set 2010-01-01 00:00:00\n",
      "2019-06-12 08:22:43.975135: Running DT with params: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 2} on train/test set 2010-01-01 00:00:00\n",
      "2019-06-12 08:22:44.551485: Running DT with params: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 5} on train/test set 2010-01-01 00:00:00\n",
      "2019-06-12 08:22:45.118359: Running RF with params: {'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 2, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2010-01-01 00:00:00\n",
      "2019-06-12 08:22:46.172926: Running RF with params: {'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 2, 'n_estimators': 1000, 'n_jobs': -1} on train/test set 2010-01-01 00:00:00\n",
      "2019-06-12 08:22:52.279345: Running RF with params: {'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2010-01-01 00:00:00\n",
      "2019-06-12 08:22:53.135822: Running RF with params: {'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 1000, 'n_jobs': -1} on train/test set 2010-01-01 00:00:00\n",
      "2019-06-12 08:22:58.132100: Running RF with params: {'max_depth': 5, 'max_features': 'log2', 'min_samples_split': 2, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2010-01-01 00:00:00\n",
      "2019-06-12 08:22:59.055588: Running RF with params: {'max_depth': 5, 'max_features': 'log2', 'min_samples_split': 2, 'n_estimators': 1000, 'n_jobs': -1} on train/test set 2010-01-01 00:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-12 08:23:02.846502: Running RF with params: {'max_depth': 5, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2010-01-01 00:00:00\n",
      "2019-06-12 08:23:03.591666: Running RF with params: {'max_depth': 5, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 1000, 'n_jobs': -1} on train/test set 2010-01-01 00:00:00\n",
      "2019-06-12 08:23:07.399579: Running RF with params: {'max_depth': 50, 'max_features': 'sqrt', 'min_samples_split': 2, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2010-01-01 00:00:00\n",
      "2019-06-12 08:23:08.933452: Running RF with params: {'max_depth': 50, 'max_features': 'sqrt', 'min_samples_split': 2, 'n_estimators': 1000, 'n_jobs': -1} on train/test set 2010-01-01 00:00:00\n",
      "2019-06-12 08:23:19.348929: Running RF with params: {'max_depth': 50, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2010-01-01 00:00:00\n",
      "2019-06-12 08:23:20.837858: Running RF with params: {'max_depth': 50, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 1000, 'n_jobs': -1} on train/test set 2010-01-01 00:00:00\n",
      "2019-06-12 08:23:31.238071: Running RF with params: {'max_depth': 50, 'max_features': 'log2', 'min_samples_split': 2, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2010-01-01 00:00:00\n",
      "2019-06-12 08:23:32.141907: Running RF with params: {'max_depth': 50, 'max_features': 'log2', 'min_samples_split': 2, 'n_estimators': 1000, 'n_jobs': -1} on train/test set 2010-01-01 00:00:00\n",
      "2019-06-12 08:23:39.296033: Running RF with params: {'max_depth': 50, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2010-01-01 00:00:00\n",
      "2019-06-12 08:23:40.251822: Running RF with params: {'max_depth': 50, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 1000, 'n_jobs': -1} on train/test set 2010-01-01 00:00:00\n",
      "2019-06-12 08:23:47.358140: Running RF with params: {'max_depth': 100, 'max_features': 'sqrt', 'min_samples_split': 2, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2010-01-01 00:00:00\n",
      "2019-06-12 08:23:48.613508: Running RF with params: {'max_depth': 100, 'max_features': 'sqrt', 'min_samples_split': 2, 'n_estimators': 1000, 'n_jobs': -1} on train/test set 2010-01-01 00:00:00\n",
      "2019-06-12 08:23:59.337922: Running RF with params: {'max_depth': 100, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2010-01-01 00:00:00\n",
      "2019-06-12 08:24:00.475378: Running RF with params: {'max_depth': 100, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 1000, 'n_jobs': -1} on train/test set 2010-01-01 00:00:00\n",
      "2019-06-12 08:24:10.337551: Running RF with params: {'max_depth': 100, 'max_features': 'log2', 'min_samples_split': 2, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2010-01-01 00:00:00\n",
      "2019-06-12 08:24:11.381175: Running RF with params: {'max_depth': 100, 'max_features': 'log2', 'min_samples_split': 2, 'n_estimators': 1000, 'n_jobs': -1} on train/test set 2010-01-01 00:00:00\n",
      "2019-06-12 08:24:18.395085: Running RF with params: {'max_depth': 100, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2010-01-01 00:00:00\n",
      "2019-06-12 08:24:19.551498: Running RF with params: {'max_depth': 100, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 1000, 'n_jobs': -1} on train/test set 2010-01-01 00:00:00\n",
      "2019-06-12 08:24:26.141528: Running KNN with params: {'algorithm': 'auto', 'n_neighbors': 3, 'weights': 'uniform'} on train/test set 2010-01-01 00:00:00\n",
      "2019-06-12 08:24:26.575688: Running KNN with params: {'algorithm': 'auto', 'n_neighbors': 3, 'weights': 'distance'} on train/test set 2010-01-01 00:00:00\n",
      "2019-06-12 08:24:27.036047: Running KNN with params: {'algorithm': 'auto', 'n_neighbors': 5, 'weights': 'uniform'} on train/test set 2010-01-01 00:00:00\n",
      "2019-06-12 08:24:27.505396: Running KNN with params: {'algorithm': 'auto', 'n_neighbors': 5, 'weights': 'distance'} on train/test set 2010-01-01 00:00:00\n",
      "2019-06-12 08:24:27.986727: Running KNN with params: {'algorithm': 'auto', 'n_neighbors': 10, 'weights': 'uniform'} on train/test set 2010-01-01 00:00:00\n",
      "2019-06-12 08:24:28.472872: Running KNN with params: {'algorithm': 'auto', 'n_neighbors': 10, 'weights': 'distance'} on train/test set 2010-01-01 00:00:00\n",
      "2019-06-12 08:24:28.976062: Running KNN with params: {'algorithm': 'auto', 'n_neighbors': 50, 'weights': 'uniform'} on train/test set 2010-01-01 00:00:00\n",
      "2019-06-12 08:24:29.581681: Running KNN with params: {'algorithm': 'auto', 'n_neighbors': 50, 'weights': 'distance'} on train/test set 2010-01-01 00:00:00\n",
      "2019-06-12 08:24:31.471968: Running KNN with params: {'algorithm': 'auto', 'n_neighbors': 100, 'weights': 'uniform'} on train/test set 2010-01-01 00:00:00\n",
      "2019-06-12 08:24:32.072510: Running KNN with params: {'algorithm': 'auto', 'n_neighbors': 100, 'weights': 'distance'} on train/test set 2010-01-01 00:00:00\n",
      "2019-06-12 08:24:32.679099: Running KNN with params: {'algorithm': 'ball_tree', 'n_neighbors': 3, 'weights': 'uniform'} on train/test set 2010-01-01 00:00:00\n",
      "2019-06-12 08:24:33.434163: Running KNN with params: {'algorithm': 'ball_tree', 'n_neighbors': 3, 'weights': 'distance'} on train/test set 2010-01-01 00:00:00\n",
      "2019-06-12 08:24:34.220268: Running KNN with params: {'algorithm': 'ball_tree', 'n_neighbors': 5, 'weights': 'uniform'} on train/test set 2010-01-01 00:00:00\n",
      "2019-06-12 08:24:35.015992: Running KNN with params: {'algorithm': 'ball_tree', 'n_neighbors': 5, 'weights': 'distance'} on train/test set 2010-01-01 00:00:00\n",
      "2019-06-12 08:24:36.120042: Running KNN with params: {'algorithm': 'ball_tree', 'n_neighbors': 10, 'weights': 'uniform'} on train/test set 2010-01-01 00:00:00\n",
      "2019-06-12 08:24:37.443088: Running KNN with params: {'algorithm': 'ball_tree', 'n_neighbors': 10, 'weights': 'distance'} on train/test set 2010-01-01 00:00:00\n",
      "2019-06-12 08:24:38.785682: Running KNN with params: {'algorithm': 'ball_tree', 'n_neighbors': 50, 'weights': 'uniform'} on train/test set 2010-01-01 00:00:00\n",
      "2019-06-12 08:24:40.369546: Running KNN with params: {'algorithm': 'ball_tree', 'n_neighbors': 50, 'weights': 'distance'} on train/test set 2010-01-01 00:00:00\n",
      "2019-06-12 08:24:41.982871: Running KNN with params: {'algorithm': 'ball_tree', 'n_neighbors': 100, 'weights': 'uniform'} on train/test set 2010-01-01 00:00:00\n",
      "2019-06-12 08:24:43.747463: Running KNN with params: {'algorithm': 'ball_tree', 'n_neighbors': 100, 'weights': 'distance'} on train/test set 2010-01-01 00:00:00\n",
      "2019-06-12 08:24:45.451265: Running NB with params: {} on train/test set 2010-01-01 00:00:00\n",
      "2019-06-12 08:24:45.812644: Running BA with params: {'n_estimators': 10} on train/test set 2010-01-01 00:00:00\n",
      "2019-06-12 08:24:48.519134: Running BA with params: {'n_estimators': 100} on train/test set 2010-01-01 00:00:00\n",
      "2019-06-12 08:25:12.623527: Running AB with params: {'algorithm': 'SAMME', 'n_estimators': 10} on train/test set 2010-01-01 00:00:00\n",
      "2019-06-12 08:25:13.142149: Running AB with params: {'algorithm': 'SAMME', 'n_estimators': 100} on train/test set 2010-01-01 00:00:00\n",
      "2019-06-12 08:25:16.119138: Running AB with params: {'algorithm': 'SAMME.R', 'n_estimators': 10} on train/test set 2010-01-01 00:00:00\n",
      "2019-06-12 08:25:16.644428: Running AB with params: {'algorithm': 'SAMME.R', 'n_estimators': 100} on train/test set 2010-01-01 00:00:00\n",
      "2019-06-12 08:25:19.795941: Running GB with params: {'learning_rate': 0.001, 'n_estimators': 10, 'subsample': 0.1} on train/test set 2010-01-01 00:00:00\n",
      "2019-06-12 08:25:20.239731: Running GB with params: {'learning_rate': 0.001, 'n_estimators': 10, 'subsample': 1.0} on train/test set 2010-01-01 00:00:00\n",
      "2019-06-12 08:25:20.842196: Running GB with params: {'learning_rate': 0.001, 'n_estimators': 100, 'subsample': 0.1} on train/test set 2010-01-01 00:00:00\n",
      "2019-06-12 08:25:22.872436: Running GB with params: {'learning_rate': 0.001, 'n_estimators': 100, 'subsample': 1.0} on train/test set 2010-01-01 00:00:00\n",
      "2019-06-12 08:25:26.185036: Running GB with params: {'learning_rate': 0.1, 'n_estimators': 10, 'subsample': 0.1} on train/test set 2010-01-01 00:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-12 08:25:26.642013: Running GB with params: {'learning_rate': 0.1, 'n_estimators': 10, 'subsample': 1.0} on train/test set 2010-01-01 00:00:00\n",
      "2019-06-12 08:25:27.234239: Running GB with params: {'learning_rate': 0.1, 'n_estimators': 100, 'subsample': 0.1} on train/test set 2010-01-01 00:00:00\n",
      "2019-06-12 08:25:29.110605: Running GB with params: {'learning_rate': 0.1, 'n_estimators': 100, 'subsample': 1.0} on train/test set 2010-01-01 00:00:00\n",
      "2019-06-12 08:25:32.243633: Running ET with params: {'criterion': 'gini', 'max_depth': 2, 'n_estimators': 100} on train/test set 2010-01-01 00:00:00\n",
      "2019-06-12 08:25:32.720357: Running ET with params: {'criterion': 'gini', 'max_depth': 2, 'n_estimators': 1000} on train/test set 2010-01-01 00:00:00\n",
      "2019-06-12 08:25:34.695303: Running ET with params: {'criterion': 'gini', 'max_depth': 5, 'n_estimators': 100} on train/test set 2010-01-01 00:00:00\n",
      "2019-06-12 08:25:35.322089: Running ET with params: {'criterion': 'gini', 'max_depth': 5, 'n_estimators': 1000} on train/test set 2010-01-01 00:00:00\n",
      "2019-06-12 08:25:38.201727: Running ET with params: {'criterion': 'gini', 'max_depth': 50, 'n_estimators': 100} on train/test set 2010-01-01 00:00:00\n",
      "2019-06-12 08:25:39.155275: Running ET with params: {'criterion': 'gini', 'max_depth': 50, 'n_estimators': 1000} on train/test set 2010-01-01 00:00:00\n",
      "2019-06-12 08:25:45.643950: Running ET with params: {'criterion': 'entropy', 'max_depth': 2, 'n_estimators': 100} on train/test set 2010-01-01 00:00:00\n",
      "2019-06-12 08:25:46.105654: Running ET with params: {'criterion': 'entropy', 'max_depth': 2, 'n_estimators': 1000} on train/test set 2010-01-01 00:00:00\n",
      "2019-06-12 08:25:48.012976: Running ET with params: {'criterion': 'entropy', 'max_depth': 5, 'n_estimators': 100} on train/test set 2010-01-01 00:00:00\n",
      "2019-06-12 08:25:48.626998: Running ET with params: {'criterion': 'entropy', 'max_depth': 5, 'n_estimators': 1000} on train/test set 2010-01-01 00:00:00\n",
      "2019-06-12 08:25:52.320918: Running ET with params: {'criterion': 'entropy', 'max_depth': 50, 'n_estimators': 100} on train/test set 2010-01-01 00:00:00\n",
      "2019-06-12 08:25:53.275510: Running ET with params: {'criterion': 'entropy', 'max_depth': 50, 'n_estimators': 1000} on train/test set 2010-01-01 00:00:00\n",
      "2019-06-12 08:26:00.263760: Running LR with params: {'C': 0.001, 'penalty': 'l1'} on train/test set 2011-01-01 00:00:00\n",
      "2019-06-12 08:26:06.518791: Running LR with params: {'C': 0.001, 'penalty': 'l2'} on train/test set 2011-01-01 00:00:00\n",
      "2019-06-12 08:26:07.862040: Running LR with params: {'C': 0.1, 'penalty': 'l1'} on train/test set 2011-01-01 00:00:00\n",
      "2019-06-12 08:26:15.457264: Running LR with params: {'C': 0.1, 'penalty': 'l2'} on train/test set 2011-01-01 00:00:00\n",
      "2019-06-12 08:26:16.797578: Running LR with params: {'C': 1, 'penalty': 'l1'} on train/test set 2011-01-01 00:00:00\n",
      "2019-06-12 08:26:24.389076: Running LR with params: {'C': 1, 'penalty': 'l2'} on train/test set 2011-01-01 00:00:00\n",
      "2019-06-12 08:26:25.807356: Running LR with params: {'C': 10, 'penalty': 'l1'} on train/test set 2011-01-01 00:00:00\n",
      "2019-06-12 08:29:01.234178: Running LR with params: {'C': 10, 'penalty': 'l2'} on train/test set 2011-01-01 00:00:00\n",
      "2019-06-12 08:29:02.680663: Running DT with params: {'criterion': 'gini', 'max_depth': 2, 'min_samples_split': 2} on train/test set 2011-01-01 00:00:00\n",
      "2019-06-12 08:29:03.004797: Running DT with params: {'criterion': 'gini', 'max_depth': 2, 'min_samples_split': 5} on train/test set 2011-01-01 00:00:00\n",
      "2019-06-12 08:29:03.329397: Running DT with params: {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 2} on train/test set 2011-01-01 00:00:00\n",
      "2019-06-12 08:29:03.720163: Running DT with params: {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 5} on train/test set 2011-01-01 00:00:00\n",
      "2019-06-12 08:29:04.103107: Running DT with params: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 2} on train/test set 2011-01-01 00:00:00\n",
      "2019-06-12 08:29:04.618306: Running DT with params: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 5} on train/test set 2011-01-01 00:00:00\n",
      "2019-06-12 08:29:05.127219: Running DT with params: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 2} on train/test set 2011-01-01 00:00:00\n",
      "2019-06-12 08:29:05.744632: Running DT with params: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 5} on train/test set 2011-01-01 00:00:00\n",
      "2019-06-12 08:29:06.369877: Running DT with params: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 2} on train/test set 2011-01-01 00:00:00\n",
      "2019-06-12 08:29:06.974591: Running DT with params: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 5} on train/test set 2011-01-01 00:00:00\n",
      "2019-06-12 08:29:07.592082: Running DT with params: {'criterion': 'entropy', 'max_depth': 2, 'min_samples_split': 2} on train/test set 2011-01-01 00:00:00\n",
      "2019-06-12 08:29:07.905863: Running DT with params: {'criterion': 'entropy', 'max_depth': 2, 'min_samples_split': 5} on train/test set 2011-01-01 00:00:00\n",
      "2019-06-12 08:29:08.217511: Running DT with params: {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 2} on train/test set 2011-01-01 00:00:00\n",
      "2019-06-12 08:29:08.647652: Running DT with params: {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 5} on train/test set 2011-01-01 00:00:00\n",
      "2019-06-12 08:29:09.066075: Running DT with params: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 2} on train/test set 2011-01-01 00:00:00\n",
      "2019-06-12 08:29:09.620817: Running DT with params: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 5} on train/test set 2011-01-01 00:00:00\n",
      "2019-06-12 08:29:10.158713: Running DT with params: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 2} on train/test set 2011-01-01 00:00:00\n",
      "2019-06-12 08:29:10.760327: Running DT with params: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 5} on train/test set 2011-01-01 00:00:00\n",
      "2019-06-12 08:29:11.368481: Running DT with params: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 2} on train/test set 2011-01-01 00:00:00\n",
      "2019-06-12 08:29:11.956449: Running DT with params: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 5} on train/test set 2011-01-01 00:00:00\n",
      "2019-06-12 08:29:12.554255: Running RF with params: {'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 2, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2011-01-01 00:00:00\n",
      "2019-06-12 08:29:13.549513: Running RF with params: {'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 2, 'n_estimators': 1000, 'n_jobs': -1} on train/test set 2011-01-01 00:00:00\n",
      "2019-06-12 08:29:19.156454: Running RF with params: {'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2011-01-01 00:00:00\n",
      "2019-06-12 08:29:20.125622: Running RF with params: {'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 1000, 'n_jobs': -1} on train/test set 2011-01-01 00:00:00\n",
      "2019-06-12 08:29:25.848918: Running RF with params: {'max_depth': 5, 'max_features': 'log2', 'min_samples_split': 2, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2011-01-01 00:00:00\n",
      "2019-06-12 08:29:26.774201: Running RF with params: {'max_depth': 5, 'max_features': 'log2', 'min_samples_split': 2, 'n_estimators': 1000, 'n_jobs': -1} on train/test set 2011-01-01 00:00:00\n",
      "2019-06-12 08:29:31.260795: Running RF with params: {'max_depth': 5, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2011-01-01 00:00:00\n",
      "2019-06-12 08:29:32.051384: Running RF with params: {'max_depth': 5, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 1000, 'n_jobs': -1} on train/test set 2011-01-01 00:00:00\n",
      "2019-06-12 08:29:36.642206: Running RF with params: {'max_depth': 50, 'max_features': 'sqrt', 'min_samples_split': 2, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2011-01-01 00:00:00\n",
      "2019-06-12 08:29:38.030233: Running RF with params: {'max_depth': 50, 'max_features': 'sqrt', 'min_samples_split': 2, 'n_estimators': 1000, 'n_jobs': -1} on train/test set 2011-01-01 00:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-12 08:29:49.017863: Running RF with params: {'max_depth': 50, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2011-01-01 00:00:00\n",
      "2019-06-12 08:29:50.500348: Running RF with params: {'max_depth': 50, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 1000, 'n_jobs': -1} on train/test set 2011-01-01 00:00:00\n",
      "2019-06-12 08:30:01.299882: Running RF with params: {'max_depth': 50, 'max_features': 'log2', 'min_samples_split': 2, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2011-01-01 00:00:00\n",
      "2019-06-12 08:30:02.453482: Running RF with params: {'max_depth': 50, 'max_features': 'log2', 'min_samples_split': 2, 'n_estimators': 1000, 'n_jobs': -1} on train/test set 2011-01-01 00:00:00\n",
      "2019-06-12 08:30:10.444072: Running RF with params: {'max_depth': 50, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2011-01-01 00:00:00\n",
      "2019-06-12 08:30:11.525518: Running RF with params: {'max_depth': 50, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 1000, 'n_jobs': -1} on train/test set 2011-01-01 00:00:00\n",
      "2019-06-12 08:30:19.333681: Running RF with params: {'max_depth': 100, 'max_features': 'sqrt', 'min_samples_split': 2, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2011-01-01 00:00:00\n",
      "2019-06-12 08:30:20.779021: Running RF with params: {'max_depth': 100, 'max_features': 'sqrt', 'min_samples_split': 2, 'n_estimators': 1000, 'n_jobs': -1} on train/test set 2011-01-01 00:00:00\n",
      "2019-06-12 08:30:31.994644: Running RF with params: {'max_depth': 100, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2011-01-01 00:00:00\n",
      "2019-06-12 08:30:33.350953: Running RF with params: {'max_depth': 100, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 1000, 'n_jobs': -1} on train/test set 2011-01-01 00:00:00\n",
      "2019-06-12 08:30:44.089227: Running RF with params: {'max_depth': 100, 'max_features': 'log2', 'min_samples_split': 2, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2011-01-01 00:00:00\n",
      "2019-06-12 08:30:45.263427: Running RF with params: {'max_depth': 100, 'max_features': 'log2', 'min_samples_split': 2, 'n_estimators': 1000, 'n_jobs': -1} on train/test set 2011-01-01 00:00:00\n",
      "2019-06-12 08:30:52.787493: Running RF with params: {'max_depth': 100, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2011-01-01 00:00:00\n",
      "2019-06-12 08:30:54.038476: Running RF with params: {'max_depth': 100, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 1000, 'n_jobs': -1} on train/test set 2011-01-01 00:00:00\n",
      "2019-06-12 08:31:01.353308: Running KNN with params: {'algorithm': 'auto', 'n_neighbors': 3, 'weights': 'uniform'} on train/test set 2011-01-01 00:00:00\n",
      "2019-06-12 08:31:01.841048: Running KNN with params: {'algorithm': 'auto', 'n_neighbors': 3, 'weights': 'distance'} on train/test set 2011-01-01 00:00:00\n",
      "2019-06-12 08:31:02.364577: Running KNN with params: {'algorithm': 'auto', 'n_neighbors': 5, 'weights': 'uniform'} on train/test set 2011-01-01 00:00:00\n",
      "2019-06-12 08:31:02.892939: Running KNN with params: {'algorithm': 'auto', 'n_neighbors': 5, 'weights': 'distance'} on train/test set 2011-01-01 00:00:00\n",
      "2019-06-12 08:31:03.426662: Running KNN with params: {'algorithm': 'auto', 'n_neighbors': 10, 'weights': 'uniform'} on train/test set 2011-01-01 00:00:00\n",
      "2019-06-12 08:31:03.967095: Running KNN with params: {'algorithm': 'auto', 'n_neighbors': 10, 'weights': 'distance'} on train/test set 2011-01-01 00:00:00\n",
      "2019-06-12 08:31:04.525455: Running KNN with params: {'algorithm': 'auto', 'n_neighbors': 50, 'weights': 'uniform'} on train/test set 2011-01-01 00:00:00\n",
      "2019-06-12 08:31:05.187993: Running KNN with params: {'algorithm': 'auto', 'n_neighbors': 50, 'weights': 'distance'} on train/test set 2011-01-01 00:00:00\n",
      "2019-06-12 08:31:05.890676: Running KNN with params: {'algorithm': 'auto', 'n_neighbors': 100, 'weights': 'uniform'} on train/test set 2011-01-01 00:00:00\n",
      "2019-06-12 08:31:06.666585: Running KNN with params: {'algorithm': 'auto', 'n_neighbors': 100, 'weights': 'distance'} on train/test set 2011-01-01 00:00:00\n",
      "2019-06-12 08:31:07.466157: Running KNN with params: {'algorithm': 'ball_tree', 'n_neighbors': 3, 'weights': 'uniform'} on train/test set 2011-01-01 00:00:00\n",
      "2019-06-12 08:31:08.451273: Running KNN with params: {'algorithm': 'ball_tree', 'n_neighbors': 3, 'weights': 'distance'} on train/test set 2011-01-01 00:00:00\n",
      "2019-06-12 08:31:09.426189: Running KNN with params: {'algorithm': 'ball_tree', 'n_neighbors': 5, 'weights': 'uniform'} on train/test set 2011-01-01 00:00:00\n",
      "2019-06-12 08:31:10.427843: Running KNN with params: {'algorithm': 'ball_tree', 'n_neighbors': 5, 'weights': 'distance'} on train/test set 2011-01-01 00:00:00\n",
      "2019-06-12 08:31:11.434133: Running KNN with params: {'algorithm': 'ball_tree', 'n_neighbors': 10, 'weights': 'uniform'} on train/test set 2011-01-01 00:00:00\n",
      "2019-06-12 08:31:12.488522: Running KNN with params: {'algorithm': 'ball_tree', 'n_neighbors': 10, 'weights': 'distance'} on train/test set 2011-01-01 00:00:00\n",
      "2019-06-12 08:31:13.546744: Running KNN with params: {'algorithm': 'ball_tree', 'n_neighbors': 50, 'weights': 'uniform'} on train/test set 2011-01-01 00:00:00\n",
      "2019-06-12 08:31:14.837242: Running KNN with params: {'algorithm': 'ball_tree', 'n_neighbors': 50, 'weights': 'distance'} on train/test set 2011-01-01 00:00:00\n",
      "2019-06-12 08:31:16.140377: Running KNN with params: {'algorithm': 'ball_tree', 'n_neighbors': 100, 'weights': 'uniform'} on train/test set 2011-01-01 00:00:00\n",
      "2019-06-12 08:31:17.634153: Running KNN with params: {'algorithm': 'ball_tree', 'n_neighbors': 100, 'weights': 'distance'} on train/test set 2011-01-01 00:00:00\n",
      "2019-06-12 08:31:19.160787: Running NB with params: {} on train/test set 2011-01-01 00:00:00\n",
      "2019-06-12 08:31:19.485752: Running BA with params: {'n_estimators': 10} on train/test set 2011-01-01 00:00:00\n",
      "2019-06-12 08:31:22.900047: Running BA with params: {'n_estimators': 100} on train/test set 2011-01-01 00:00:00\n",
      "2019-06-12 08:31:53.768719: Running AB with params: {'algorithm': 'SAMME', 'n_estimators': 10} on train/test set 2011-01-01 00:00:00\n",
      "2019-06-12 08:31:54.336496: Running AB with params: {'algorithm': 'SAMME', 'n_estimators': 100} on train/test set 2011-01-01 00:00:00\n",
      "2019-06-12 08:31:57.605545: Running AB with params: {'algorithm': 'SAMME.R', 'n_estimators': 10} on train/test set 2011-01-01 00:00:00\n",
      "2019-06-12 08:31:58.161899: Running AB with params: {'algorithm': 'SAMME.R', 'n_estimators': 100} on train/test set 2011-01-01 00:00:00\n",
      "2019-06-12 08:32:01.527302: Running GB with params: {'learning_rate': 0.001, 'n_estimators': 10, 'subsample': 0.1} on train/test set 2011-01-01 00:00:00\n",
      "2019-06-12 08:32:02.015175: Running GB with params: {'learning_rate': 0.001, 'n_estimators': 10, 'subsample': 1.0} on train/test set 2011-01-01 00:00:00\n",
      "2019-06-12 08:32:02.644170: Running GB with params: {'learning_rate': 0.001, 'n_estimators': 100, 'subsample': 0.1} on train/test set 2011-01-01 00:00:00\n",
      "2019-06-12 08:32:04.786282: Running GB with params: {'learning_rate': 0.001, 'n_estimators': 100, 'subsample': 1.0} on train/test set 2011-01-01 00:00:00\n",
      "2019-06-12 08:32:08.437620: Running GB with params: {'learning_rate': 0.1, 'n_estimators': 10, 'subsample': 0.1} on train/test set 2011-01-01 00:00:00\n",
      "2019-06-12 08:32:08.924574: Running GB with params: {'learning_rate': 0.1, 'n_estimators': 10, 'subsample': 1.0} on train/test set 2011-01-01 00:00:00\n",
      "2019-06-12 08:32:09.565058: Running GB with params: {'learning_rate': 0.1, 'n_estimators': 100, 'subsample': 0.1} on train/test set 2011-01-01 00:00:00\n",
      "2019-06-12 08:32:11.612529: Running GB with params: {'learning_rate': 0.1, 'n_estimators': 100, 'subsample': 1.0} on train/test set 2011-01-01 00:00:00\n",
      "2019-06-12 08:32:15.043290: Running ET with params: {'criterion': 'gini', 'max_depth': 2, 'n_estimators': 100} on train/test set 2011-01-01 00:00:00\n",
      "2019-06-12 08:32:15.633301: Running ET with params: {'criterion': 'gini', 'max_depth': 2, 'n_estimators': 1000} on train/test set 2011-01-01 00:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-12 08:32:18.328557: Running ET with params: {'criterion': 'gini', 'max_depth': 5, 'n_estimators': 100} on train/test set 2011-01-01 00:00:00\n",
      "2019-06-12 08:32:18.938172: Running ET with params: {'criterion': 'gini', 'max_depth': 5, 'n_estimators': 1000} on train/test set 2011-01-01 00:00:00\n",
      "2019-06-12 08:32:21.894271: Running ET with params: {'criterion': 'gini', 'max_depth': 50, 'n_estimators': 100} on train/test set 2011-01-01 00:00:00\n",
      "2019-06-12 08:32:22.960543: Running ET with params: {'criterion': 'gini', 'max_depth': 50, 'n_estimators': 1000} on train/test set 2011-01-01 00:00:00\n",
      "2019-06-12 08:32:30.272559: Running ET with params: {'criterion': 'entropy', 'max_depth': 2, 'n_estimators': 100} on train/test set 2011-01-01 00:00:00\n",
      "2019-06-12 08:32:30.739912: Running ET with params: {'criterion': 'entropy', 'max_depth': 2, 'n_estimators': 1000} on train/test set 2011-01-01 00:00:00\n",
      "2019-06-12 08:32:32.710806: Running ET with params: {'criterion': 'entropy', 'max_depth': 5, 'n_estimators': 100} on train/test set 2011-01-01 00:00:00\n",
      "2019-06-12 08:32:33.565069: Running ET with params: {'criterion': 'entropy', 'max_depth': 5, 'n_estimators': 1000} on train/test set 2011-01-01 00:00:00\n",
      "2019-06-12 08:32:37.367196: Running ET with params: {'criterion': 'entropy', 'max_depth': 50, 'n_estimators': 100} on train/test set 2011-01-01 00:00:00\n",
      "2019-06-12 08:32:38.303686: Running ET with params: {'criterion': 'entropy', 'max_depth': 50, 'n_estimators': 1000} on train/test set 2011-01-01 00:00:00\n",
      "2019-06-12 08:32:45.458219: Running LR with params: {'C': 0.001, 'penalty': 'l1'} on train/test set 2012-01-01 00:00:00\n",
      "2019-06-12 08:32:48.486755: Running LR with params: {'C': 0.001, 'penalty': 'l2'} on train/test set 2012-01-01 00:00:00\n",
      "2019-06-12 08:32:49.990744: Running LR with params: {'C': 0.1, 'penalty': 'l1'} on train/test set 2012-01-01 00:00:00\n",
      "2019-06-12 08:32:56.718943: Running LR with params: {'C': 0.1, 'penalty': 'l2'} on train/test set 2012-01-01 00:00:00\n",
      "2019-06-12 08:32:58.225276: Running LR with params: {'C': 1, 'penalty': 'l1'} on train/test set 2012-01-01 00:00:00\n",
      "2019-06-12 08:33:34.449522: Running LR with params: {'C': 1, 'penalty': 'l2'} on train/test set 2012-01-01 00:00:00\n",
      "2019-06-12 08:33:35.626337: Running LR with params: {'C': 10, 'penalty': 'l1'} on train/test set 2012-01-01 00:00:00\n",
      "2019-06-12 08:36:25.172045: Running LR with params: {'C': 10, 'penalty': 'l2'} on train/test set 2012-01-01 00:00:00\n",
      "2019-06-12 08:36:26.699240: Running DT with params: {'criterion': 'gini', 'max_depth': 2, 'min_samples_split': 2} on train/test set 2012-01-01 00:00:00\n",
      "2019-06-12 08:36:27.038619: Running DT with params: {'criterion': 'gini', 'max_depth': 2, 'min_samples_split': 5} on train/test set 2012-01-01 00:00:00\n",
      "2019-06-12 08:36:27.372876: Running DT with params: {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 2} on train/test set 2012-01-01 00:00:00\n",
      "2019-06-12 08:36:27.790836: Running DT with params: {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 5} on train/test set 2012-01-01 00:00:00\n",
      "2019-06-12 08:36:28.185777: Running DT with params: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 2} on train/test set 2012-01-01 00:00:00\n",
      "2019-06-12 08:36:28.735590: Running DT with params: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 5} on train/test set 2012-01-01 00:00:00\n",
      "2019-06-12 08:36:30.976151: Running DT with params: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 2} on train/test set 2012-01-01 00:00:00\n",
      "2019-06-12 08:36:31.585166: Running DT with params: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 5} on train/test set 2012-01-01 00:00:00\n",
      "2019-06-12 08:36:32.186666: Running DT with params: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 2} on train/test set 2012-01-01 00:00:00\n",
      "2019-06-12 08:36:32.799262: Running DT with params: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 5} on train/test set 2012-01-01 00:00:00\n",
      "2019-06-12 08:36:33.415286: Running DT with params: {'criterion': 'entropy', 'max_depth': 2, 'min_samples_split': 2} on train/test set 2012-01-01 00:00:00\n",
      "2019-06-12 08:36:33.707363: Running DT with params: {'criterion': 'entropy', 'max_depth': 2, 'min_samples_split': 5} on train/test set 2012-01-01 00:00:00\n",
      "2019-06-12 08:36:33.996074: Running DT with params: {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 2} on train/test set 2012-01-01 00:00:00\n",
      "2019-06-12 08:36:34.430615: Running DT with params: {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 5} on train/test set 2012-01-01 00:00:00\n",
      "2019-06-12 08:36:34.864328: Running DT with params: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 2} on train/test set 2012-01-01 00:00:00\n",
      "2019-06-12 08:36:35.466835: Running DT with params: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 5} on train/test set 2012-01-01 00:00:00\n",
      "2019-06-12 08:36:36.034222: Running DT with params: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 2} on train/test set 2012-01-01 00:00:00\n",
      "2019-06-12 08:36:36.669735: Running DT with params: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 5} on train/test set 2012-01-01 00:00:00\n",
      "2019-06-12 08:36:37.321643: Running DT with params: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 2} on train/test set 2012-01-01 00:00:00\n",
      "2019-06-12 08:36:37.951669: Running DT with params: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 5} on train/test set 2012-01-01 00:00:00\n",
      "2019-06-12 08:36:38.633712: Running RF with params: {'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 2, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2012-01-01 00:00:00\n",
      "2019-06-12 08:36:39.695357: Running RF with params: {'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 2, 'n_estimators': 1000, 'n_jobs': -1} on train/test set 2012-01-01 00:00:00\n",
      "2019-06-12 08:36:47.382377: Running RF with params: {'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2012-01-01 00:00:00\n",
      "2019-06-12 08:36:48.354997: Running RF with params: {'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 1000, 'n_jobs': -1} on train/test set 2012-01-01 00:00:00\n",
      "2019-06-12 08:36:54.218676: Running RF with params: {'max_depth': 5, 'max_features': 'log2', 'min_samples_split': 2, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2012-01-01 00:00:00\n",
      "2019-06-12 08:36:55.048899: Running RF with params: {'max_depth': 5, 'max_features': 'log2', 'min_samples_split': 2, 'n_estimators': 1000, 'n_jobs': -1} on train/test set 2012-01-01 00:00:00\n",
      "2019-06-12 08:37:00.247681: Running RF with params: {'max_depth': 5, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2012-01-01 00:00:00\n",
      "2019-06-12 08:37:01.044838: Running RF with params: {'max_depth': 5, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 1000, 'n_jobs': -1} on train/test set 2012-01-01 00:00:00\n",
      "2019-06-12 08:37:05.197731: Running RF with params: {'max_depth': 50, 'max_features': 'sqrt', 'min_samples_split': 2, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2012-01-01 00:00:00\n",
      "2019-06-12 08:37:06.933386: Running RF with params: {'max_depth': 50, 'max_features': 'sqrt', 'min_samples_split': 2, 'n_estimators': 1000, 'n_jobs': -1} on train/test set 2012-01-01 00:00:00\n",
      "2019-06-12 08:37:19.318218: Running RF with params: {'max_depth': 50, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2012-01-01 00:00:00\n",
      "2019-06-12 08:37:20.894505: Running RF with params: {'max_depth': 50, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 1000, 'n_jobs': -1} on train/test set 2012-01-01 00:00:00\n",
      "2019-06-12 08:37:33.181416: Running RF with params: {'max_depth': 50, 'max_features': 'log2', 'min_samples_split': 2, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2012-01-01 00:00:00\n",
      "2019-06-12 08:37:34.215239: Running RF with params: {'max_depth': 50, 'max_features': 'log2', 'min_samples_split': 2, 'n_estimators': 1000, 'n_jobs': -1} on train/test set 2012-01-01 00:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-12 08:37:42.620913: Running RF with params: {'max_depth': 50, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2012-01-01 00:00:00\n",
      "2019-06-12 08:37:43.796207: Running RF with params: {'max_depth': 50, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 1000, 'n_jobs': -1} on train/test set 2012-01-01 00:00:00\n",
      "2019-06-12 08:37:52.322876: Running RF with params: {'max_depth': 100, 'max_features': 'sqrt', 'min_samples_split': 2, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2012-01-01 00:00:00\n",
      "2019-06-12 08:37:53.858795: Running RF with params: {'max_depth': 100, 'max_features': 'sqrt', 'min_samples_split': 2, 'n_estimators': 1000, 'n_jobs': -1} on train/test set 2012-01-01 00:00:00\n",
      "2019-06-12 08:38:06.385236: Running RF with params: {'max_depth': 100, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2012-01-01 00:00:00\n",
      "2019-06-12 08:38:07.891467: Running RF with params: {'max_depth': 100, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 1000, 'n_jobs': -1} on train/test set 2012-01-01 00:00:00\n",
      "2019-06-12 08:38:23.269203: Running RF with params: {'max_depth': 100, 'max_features': 'log2', 'min_samples_split': 2, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2012-01-01 00:00:00\n",
      "2019-06-12 08:38:24.438905: Running RF with params: {'max_depth': 100, 'max_features': 'log2', 'min_samples_split': 2, 'n_estimators': 1000, 'n_jobs': -1} on train/test set 2012-01-01 00:00:00\n",
      "2019-06-12 08:38:33.399059: Running RF with params: {'max_depth': 100, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2012-01-01 00:00:00\n",
      "2019-06-12 08:38:34.571283: Running RF with params: {'max_depth': 100, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 1000, 'n_jobs': -1} on train/test set 2012-01-01 00:00:00\n",
      "2019-06-12 08:38:43.192642: Running KNN with params: {'algorithm': 'auto', 'n_neighbors': 3, 'weights': 'uniform'} on train/test set 2012-01-01 00:00:00\n",
      "2019-06-12 08:38:44.159668: Running KNN with params: {'algorithm': 'auto', 'n_neighbors': 3, 'weights': 'distance'} on train/test set 2012-01-01 00:00:00\n",
      "2019-06-12 08:38:44.794190: Running KNN with params: {'algorithm': 'auto', 'n_neighbors': 5, 'weights': 'uniform'} on train/test set 2012-01-01 00:00:00\n",
      "2019-06-12 08:38:45.375861: Running KNN with params: {'algorithm': 'auto', 'n_neighbors': 5, 'weights': 'distance'} on train/test set 2012-01-01 00:00:00\n",
      "2019-06-12 08:38:46.624261: Running KNN with params: {'algorithm': 'auto', 'n_neighbors': 10, 'weights': 'uniform'} on train/test set 2012-01-01 00:00:00\n",
      "2019-06-12 08:38:47.418841: Running KNN with params: {'algorithm': 'auto', 'n_neighbors': 10, 'weights': 'distance'} on train/test set 2012-01-01 00:00:00\n",
      "2019-06-12 08:38:48.323172: Running KNN with params: {'algorithm': 'auto', 'n_neighbors': 50, 'weights': 'uniform'} on train/test set 2012-01-01 00:00:00\n",
      "2019-06-12 08:38:49.219839: Running KNN with params: {'algorithm': 'auto', 'n_neighbors': 50, 'weights': 'distance'} on train/test set 2012-01-01 00:00:00\n",
      "2019-06-12 08:38:51.001678: Running KNN with params: {'algorithm': 'auto', 'n_neighbors': 100, 'weights': 'uniform'} on train/test set 2012-01-01 00:00:00\n",
      "2019-06-12 08:38:51.892578: Running KNN with params: {'algorithm': 'auto', 'n_neighbors': 100, 'weights': 'distance'} on train/test set 2012-01-01 00:00:00\n",
      "2019-06-12 08:38:52.726565: Running KNN with params: {'algorithm': 'ball_tree', 'n_neighbors': 3, 'weights': 'uniform'} on train/test set 2012-01-01 00:00:00\n",
      "2019-06-12 08:38:53.832577: Running KNN with params: {'algorithm': 'ball_tree', 'n_neighbors': 3, 'weights': 'distance'} on train/test set 2012-01-01 00:00:00\n",
      "2019-06-12 08:38:54.903108: Running KNN with params: {'algorithm': 'ball_tree', 'n_neighbors': 5, 'weights': 'uniform'} on train/test set 2012-01-01 00:00:00\n",
      "2019-06-12 08:38:56.016983: Running KNN with params: {'algorithm': 'ball_tree', 'n_neighbors': 5, 'weights': 'distance'} on train/test set 2012-01-01 00:00:00\n",
      "2019-06-12 08:38:57.111685: Running KNN with params: {'algorithm': 'ball_tree', 'n_neighbors': 10, 'weights': 'uniform'} on train/test set 2012-01-01 00:00:00\n",
      "2019-06-12 08:38:58.308654: Running KNN with params: {'algorithm': 'ball_tree', 'n_neighbors': 10, 'weights': 'distance'} on train/test set 2012-01-01 00:00:00\n",
      "2019-06-12 08:38:59.460000: Running KNN with params: {'algorithm': 'ball_tree', 'n_neighbors': 50, 'weights': 'uniform'} on train/test set 2012-01-01 00:00:00\n",
      "2019-06-12 08:39:00.894055: Running KNN with params: {'algorithm': 'ball_tree', 'n_neighbors': 50, 'weights': 'distance'} on train/test set 2012-01-01 00:00:00\n",
      "2019-06-12 08:39:02.332416: Running KNN with params: {'algorithm': 'ball_tree', 'n_neighbors': 100, 'weights': 'uniform'} on train/test set 2012-01-01 00:00:00\n",
      "2019-06-12 08:39:03.967778: Running KNN with params: {'algorithm': 'ball_tree', 'n_neighbors': 100, 'weights': 'distance'} on train/test set 2012-01-01 00:00:00\n",
      "2019-06-12 08:39:05.619904: Running NB with params: {} on train/test set 2012-01-01 00:00:00\n",
      "2019-06-12 08:39:05.947641: Running BA with params: {'n_estimators': 10} on train/test set 2012-01-01 00:00:00\n",
      "2019-06-12 08:39:09.644601: Running BA with params: {'n_estimators': 100} on train/test set 2012-01-01 00:00:00\n",
      "2019-06-12 08:39:43.912667: Running AB with params: {'algorithm': 'SAMME', 'n_estimators': 10} on train/test set 2012-01-01 00:00:00\n",
      "2019-06-12 08:39:44.492929: Running AB with params: {'algorithm': 'SAMME', 'n_estimators': 100} on train/test set 2012-01-01 00:00:00\n",
      "2019-06-12 08:39:48.020279: Running AB with params: {'algorithm': 'SAMME.R', 'n_estimators': 10} on train/test set 2012-01-01 00:00:00\n",
      "2019-06-12 08:39:48.624122: Running AB with params: {'algorithm': 'SAMME.R', 'n_estimators': 100} on train/test set 2012-01-01 00:00:00\n",
      "2019-06-12 08:39:52.273487: Running GB with params: {'learning_rate': 0.001, 'n_estimators': 10, 'subsample': 0.1} on train/test set 2012-01-01 00:00:00\n",
      "2019-06-12 08:39:52.784779: Running GB with params: {'learning_rate': 0.001, 'n_estimators': 10, 'subsample': 1.0} on train/test set 2012-01-01 00:00:00\n",
      "2019-06-12 08:39:53.460076: Running GB with params: {'learning_rate': 0.001, 'n_estimators': 100, 'subsample': 0.1} on train/test set 2012-01-01 00:00:00\n",
      "2019-06-12 08:39:55.802489: Running GB with params: {'learning_rate': 0.001, 'n_estimators': 100, 'subsample': 1.0} on train/test set 2012-01-01 00:00:00\n",
      "2019-06-12 08:39:59.789389: Running GB with params: {'learning_rate': 0.1, 'n_estimators': 10, 'subsample': 0.1} on train/test set 2012-01-01 00:00:00\n",
      "2019-06-12 08:40:00.312757: Running GB with params: {'learning_rate': 0.1, 'n_estimators': 10, 'subsample': 1.0} on train/test set 2012-01-01 00:00:00\n",
      "2019-06-12 08:40:01.002824: Running GB with params: {'learning_rate': 0.1, 'n_estimators': 100, 'subsample': 0.1} on train/test set 2012-01-01 00:00:00\n",
      "2019-06-12 08:40:03.270072: Running GB with params: {'learning_rate': 0.1, 'n_estimators': 100, 'subsample': 1.0} on train/test set 2012-01-01 00:00:00\n",
      "2019-06-12 08:40:06.969362: Running ET with params: {'criterion': 'gini', 'max_depth': 2, 'n_estimators': 100} on train/test set 2012-01-01 00:00:00\n",
      "2019-06-12 08:40:07.562488: Running ET with params: {'criterion': 'gini', 'max_depth': 2, 'n_estimators': 1000} on train/test set 2012-01-01 00:00:00\n",
      "2019-06-12 08:40:10.047991: Running ET with params: {'criterion': 'gini', 'max_depth': 5, 'n_estimators': 100} on train/test set 2012-01-01 00:00:00\n",
      "2019-06-12 08:40:10.763866: Running ET with params: {'criterion': 'gini', 'max_depth': 5, 'n_estimators': 1000} on train/test set 2012-01-01 00:00:00\n",
      "2019-06-12 08:40:14.334616: Running ET with params: {'criterion': 'gini', 'max_depth': 50, 'n_estimators': 100} on train/test set 2012-01-01 00:00:00\n",
      "2019-06-12 08:40:15.393297: Running ET with params: {'criterion': 'gini', 'max_depth': 50, 'n_estimators': 1000} on train/test set 2012-01-01 00:00:00\n",
      "2019-06-12 08:40:23.045781: Running ET with params: {'criterion': 'entropy', 'max_depth': 2, 'n_estimators': 100} on train/test set 2012-01-01 00:00:00\n",
      "2019-06-12 08:40:23.648199: Running ET with params: {'criterion': 'entropy', 'max_depth': 2, 'n_estimators': 1000} on train/test set 2012-01-01 00:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-12 08:40:26.411177: Running ET with params: {'criterion': 'entropy', 'max_depth': 5, 'n_estimators': 100} on train/test set 2012-01-01 00:00:00\n",
      "2019-06-12 08:40:27.007782: Running ET with params: {'criterion': 'entropy', 'max_depth': 5, 'n_estimators': 1000} on train/test set 2012-01-01 00:00:00\n",
      "2019-06-12 08:40:30.179264: Running ET with params: {'criterion': 'entropy', 'max_depth': 50, 'n_estimators': 100} on train/test set 2012-01-01 00:00:00\n",
      "2019-06-12 08:40:31.350755: Running ET with params: {'criterion': 'entropy', 'max_depth': 50, 'n_estimators': 1000} on train/test set 2012-01-01 00:00:00\n",
      "2019-06-12 08:40:39.139267: Running LR with params: {'C': 0.001, 'penalty': 'l1'} on train/test set 2013-01-01 00:00:00\n",
      "2019-06-12 08:40:43.928224: Running LR with params: {'C': 0.001, 'penalty': 'l2'} on train/test set 2013-01-01 00:00:00\n",
      "2019-06-12 08:40:45.151653: Running LR with params: {'C': 0.1, 'penalty': 'l1'} on train/test set 2013-01-01 00:00:00\n",
      "2019-06-12 08:42:00.789942: Running LR with params: {'C': 0.1, 'penalty': 'l2'} on train/test set 2013-01-01 00:00:00\n",
      "2019-06-12 08:42:02.372818: Running LR with params: {'C': 1, 'penalty': 'l1'} on train/test set 2013-01-01 00:00:00\n",
      "2019-06-12 08:43:02.440200: Running LR with params: {'C': 1, 'penalty': 'l2'} on train/test set 2013-01-01 00:00:00\n",
      "2019-06-12 08:43:03.921744: Running LR with params: {'C': 10, 'penalty': 'l1'} on train/test set 2013-01-01 00:00:00\n",
      "2019-06-12 08:46:08.750210: Running LR with params: {'C': 10, 'penalty': 'l2'} on train/test set 2013-01-01 00:00:00\n",
      "2019-06-12 08:46:10.127194: Running DT with params: {'criterion': 'gini', 'max_depth': 2, 'min_samples_split': 2} on train/test set 2013-01-01 00:00:00\n",
      "2019-06-12 08:46:10.475430: Running DT with params: {'criterion': 'gini', 'max_depth': 2, 'min_samples_split': 5} on train/test set 2013-01-01 00:00:00\n",
      "2019-06-12 08:46:10.824148: Running DT with params: {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 2} on train/test set 2013-01-01 00:00:00\n",
      "2019-06-12 08:46:11.258752: Running DT with params: {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 5} on train/test set 2013-01-01 00:00:00\n",
      "2019-06-12 08:46:11.686071: Running DT with params: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 2} on train/test set 2013-01-01 00:00:00\n",
      "2019-06-12 08:46:12.254137: Running DT with params: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 5} on train/test set 2013-01-01 00:00:00\n",
      "2019-06-12 08:46:12.813080: Running DT with params: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 2} on train/test set 2013-01-01 00:00:00\n",
      "2019-06-12 08:46:13.469242: Running DT with params: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 5} on train/test set 2013-01-01 00:00:00\n",
      "2019-06-12 08:46:14.132507: Running DT with params: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 2} on train/test set 2013-01-01 00:00:00\n",
      "2019-06-12 08:46:14.788625: Running DT with params: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 5} on train/test set 2013-01-01 00:00:00\n",
      "2019-06-12 08:46:15.449233: Running DT with params: {'criterion': 'entropy', 'max_depth': 2, 'min_samples_split': 2} on train/test set 2013-01-01 00:00:00\n",
      "2019-06-12 08:46:15.795100: Running DT with params: {'criterion': 'entropy', 'max_depth': 2, 'min_samples_split': 5} on train/test set 2013-01-01 00:00:00\n",
      "2019-06-12 08:46:16.142621: Running DT with params: {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 2} on train/test set 2013-01-01 00:00:00\n",
      "2019-06-12 08:46:16.605263: Running DT with params: {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 5} on train/test set 2013-01-01 00:00:00\n",
      "2019-06-12 08:46:17.072359: Running DT with params: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 2} on train/test set 2013-01-01 00:00:00\n",
      "2019-06-12 08:46:17.687288: Running DT with params: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 5} on train/test set 2013-01-01 00:00:00\n",
      "2019-06-12 08:46:18.303166: Running DT with params: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 2} on train/test set 2013-01-01 00:00:00\n",
      "2019-06-12 08:46:18.977392: Running DT with params: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 5} on train/test set 2013-01-01 00:00:00\n",
      "2019-06-12 08:46:19.648559: Running DT with params: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 2} on train/test set 2013-01-01 00:00:00\n",
      "2019-06-12 08:46:20.329276: Running DT with params: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 5} on train/test set 2013-01-01 00:00:00\n",
      "2019-06-12 08:46:21.004573: Running RF with params: {'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 2, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2013-01-01 00:00:00\n",
      "2019-06-12 08:46:22.086456: Running RF with params: {'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 2, 'n_estimators': 1000, 'n_jobs': -1} on train/test set 2013-01-01 00:00:00\n",
      "2019-06-12 08:46:28.894092: Running RF with params: {'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2013-01-01 00:00:00\n",
      "2019-06-12 08:46:29.865112: Running RF with params: {'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 1000, 'n_jobs': -1} on train/test set 2013-01-01 00:00:00\n",
      "2019-06-12 08:46:36.348995: Running RF with params: {'max_depth': 5, 'max_features': 'log2', 'min_samples_split': 2, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2013-01-01 00:00:00\n",
      "2019-06-12 08:46:37.197781: Running RF with params: {'max_depth': 5, 'max_features': 'log2', 'min_samples_split': 2, 'n_estimators': 1000, 'n_jobs': -1} on train/test set 2013-01-01 00:00:00\n",
      "2019-06-12 08:46:42.527102: Running RF with params: {'max_depth': 5, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2013-01-01 00:00:00\n",
      "2019-06-12 08:46:43.493349: Running RF with params: {'max_depth': 5, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 1000, 'n_jobs': -1} on train/test set 2013-01-01 00:00:00\n",
      "2019-06-12 08:46:49.451410: Running RF with params: {'max_depth': 50, 'max_features': 'sqrt', 'min_samples_split': 2, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2013-01-01 00:00:00\n",
      "2019-06-12 08:46:51.212056: Running RF with params: {'max_depth': 50, 'max_features': 'sqrt', 'min_samples_split': 2, 'n_estimators': 1000, 'n_jobs': -1} on train/test set 2013-01-01 00:00:00\n",
      "2019-06-12 08:47:05.199854: Running RF with params: {'max_depth': 50, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2013-01-01 00:00:00\n",
      "2019-06-12 08:47:06.769403: Running RF with params: {'max_depth': 50, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 1000, 'n_jobs': -1} on train/test set 2013-01-01 00:00:00\n",
      "2019-06-12 08:47:20.280469: Running RF with params: {'max_depth': 50, 'max_features': 'log2', 'min_samples_split': 2, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2013-01-01 00:00:00\n",
      "2019-06-12 08:47:21.657490: Running RF with params: {'max_depth': 50, 'max_features': 'log2', 'min_samples_split': 2, 'n_estimators': 1000, 'n_jobs': -1} on train/test set 2013-01-01 00:00:00\n",
      "2019-06-12 08:47:31.302113: Running RF with params: {'max_depth': 50, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2013-01-01 00:00:00\n",
      "2019-06-12 08:47:32.326379: Running RF with params: {'max_depth': 50, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 1000, 'n_jobs': -1} on train/test set 2013-01-01 00:00:00\n",
      "2019-06-12 08:47:41.339913: Running RF with params: {'max_depth': 100, 'max_features': 'sqrt', 'min_samples_split': 2, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2013-01-01 00:00:00\n",
      "2019-06-12 08:47:43.058791: Running RF with params: {'max_depth': 100, 'max_features': 'sqrt', 'min_samples_split': 2, 'n_estimators': 1000, 'n_jobs': -1} on train/test set 2013-01-01 00:00:00\n",
      "2019-06-12 08:47:56.370488: Running RF with params: {'max_depth': 100, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2013-01-01 00:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-12 08:47:58.067695: Running RF with params: {'max_depth': 100, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 1000, 'n_jobs': -1} on train/test set 2013-01-01 00:00:00\n",
      "2019-06-12 08:48:10.934061: Running RF with params: {'max_depth': 100, 'max_features': 'log2', 'min_samples_split': 2, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2013-01-01 00:00:00\n",
      "2019-06-12 08:48:12.593246: Running RF with params: {'max_depth': 100, 'max_features': 'log2', 'min_samples_split': 2, 'n_estimators': 1000, 'n_jobs': -1} on train/test set 2013-01-01 00:00:00\n",
      "2019-06-12 08:48:22.998246: Running RF with params: {'max_depth': 100, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2013-01-01 00:00:00\n",
      "2019-06-12 08:48:24.171878: Running RF with params: {'max_depth': 100, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 1000, 'n_jobs': -1} on train/test set 2013-01-01 00:00:00\n",
      "2019-06-12 08:48:33.303346: Running KNN with params: {'algorithm': 'auto', 'n_neighbors': 3, 'weights': 'uniform'} on train/test set 2013-01-01 00:00:00\n",
      "2019-06-12 08:48:33.938843: Running KNN with params: {'algorithm': 'auto', 'n_neighbors': 3, 'weights': 'distance'} on train/test set 2013-01-01 00:00:00\n",
      "2019-06-12 08:48:34.564177: Running KNN with params: {'algorithm': 'auto', 'n_neighbors': 5, 'weights': 'uniform'} on train/test set 2013-01-01 00:00:00\n",
      "2019-06-12 08:48:35.258770: Running KNN with params: {'algorithm': 'auto', 'n_neighbors': 5, 'weights': 'distance'} on train/test set 2013-01-01 00:00:00\n",
      "2019-06-12 08:48:35.993927: Running KNN with params: {'algorithm': 'auto', 'n_neighbors': 10, 'weights': 'uniform'} on train/test set 2013-01-01 00:00:00\n",
      "2019-06-12 08:48:36.730503: Running KNN with params: {'algorithm': 'auto', 'n_neighbors': 10, 'weights': 'distance'} on train/test set 2013-01-01 00:00:00\n",
      "2019-06-12 08:48:37.478621: Running KNN with params: {'algorithm': 'auto', 'n_neighbors': 50, 'weights': 'uniform'} on train/test set 2013-01-01 00:00:00\n",
      "2019-06-12 08:48:38.387795: Running KNN with params: {'algorithm': 'auto', 'n_neighbors': 50, 'weights': 'distance'} on train/test set 2013-01-01 00:00:00\n",
      "2019-06-12 08:48:39.328725: Running KNN with params: {'algorithm': 'auto', 'n_neighbors': 100, 'weights': 'uniform'} on train/test set 2013-01-01 00:00:00\n",
      "2019-06-12 08:48:40.382604: Running KNN with params: {'algorithm': 'auto', 'n_neighbors': 100, 'weights': 'distance'} on train/test set 2013-01-01 00:00:00\n",
      "2019-06-12 08:48:41.461977: Running KNN with params: {'algorithm': 'ball_tree', 'n_neighbors': 3, 'weights': 'uniform'} on train/test set 2013-01-01 00:00:00\n",
      "2019-06-12 08:48:42.410181: Running KNN with params: {'algorithm': 'ball_tree', 'n_neighbors': 3, 'weights': 'distance'} on train/test set 2013-01-01 00:00:00\n",
      "2019-06-12 08:48:43.346874: Running KNN with params: {'algorithm': 'ball_tree', 'n_neighbors': 5, 'weights': 'uniform'} on train/test set 2013-01-01 00:00:00\n",
      "2019-06-12 08:48:44.288725: Running KNN with params: {'algorithm': 'ball_tree', 'n_neighbors': 5, 'weights': 'distance'} on train/test set 2013-01-01 00:00:00\n",
      "2019-06-12 08:48:45.235074: Running KNN with params: {'algorithm': 'ball_tree', 'n_neighbors': 10, 'weights': 'uniform'} on train/test set 2013-01-01 00:00:00\n",
      "2019-06-12 08:48:46.224588: Running KNN with params: {'algorithm': 'ball_tree', 'n_neighbors': 10, 'weights': 'distance'} on train/test set 2013-01-01 00:00:00\n",
      "2019-06-12 08:48:47.217815: Running KNN with params: {'algorithm': 'ball_tree', 'n_neighbors': 50, 'weights': 'uniform'} on train/test set 2013-01-01 00:00:00\n",
      "2019-06-12 08:48:48.431238: Running KNN with params: {'algorithm': 'ball_tree', 'n_neighbors': 50, 'weights': 'distance'} on train/test set 2013-01-01 00:00:00\n",
      "2019-06-12 08:48:49.681143: Running KNN with params: {'algorithm': 'ball_tree', 'n_neighbors': 100, 'weights': 'uniform'} on train/test set 2013-01-01 00:00:00\n",
      "2019-06-12 08:48:51.065920: Running KNN with params: {'algorithm': 'ball_tree', 'n_neighbors': 100, 'weights': 'distance'} on train/test set 2013-01-01 00:00:00\n",
      "2019-06-12 08:48:52.459322: Running NB with params: {} on train/test set 2013-01-01 00:00:00\n",
      "2019-06-12 08:48:52.798743: Running BA with params: {'n_estimators': 10} on train/test set 2013-01-01 00:00:00\n",
      "2019-06-12 08:48:57.684132: Running BA with params: {'n_estimators': 100} on train/test set 2013-01-01 00:00:00\n",
      "2019-06-12 08:49:44.625462: Running AB with params: {'algorithm': 'SAMME', 'n_estimators': 10} on train/test set 2013-01-01 00:00:00\n",
      "2019-06-12 08:49:45.233097: Running AB with params: {'algorithm': 'SAMME', 'n_estimators': 100} on train/test set 2013-01-01 00:00:00\n",
      "2019-06-12 08:49:48.996207: Running AB with params: {'algorithm': 'SAMME.R', 'n_estimators': 10} on train/test set 2013-01-01 00:00:00\n",
      "2019-06-12 08:49:49.617843: Running AB with params: {'algorithm': 'SAMME.R', 'n_estimators': 100} on train/test set 2013-01-01 00:00:00\n",
      "2019-06-12 08:49:53.491868: Running GB with params: {'learning_rate': 0.001, 'n_estimators': 10, 'subsample': 0.1} on train/test set 2013-01-01 00:00:00\n",
      "2019-06-12 08:49:54.024257: Running GB with params: {'learning_rate': 0.001, 'n_estimators': 10, 'subsample': 1.0} on train/test set 2013-01-01 00:00:00\n",
      "2019-06-12 08:49:54.729695: Running GB with params: {'learning_rate': 0.001, 'n_estimators': 100, 'subsample': 0.1} on train/test set 2013-01-01 00:00:00\n",
      "2019-06-12 08:49:57.232222: Running GB with params: {'learning_rate': 0.001, 'n_estimators': 100, 'subsample': 1.0} on train/test set 2013-01-01 00:00:00\n",
      "2019-06-12 08:50:01.491859: Running GB with params: {'learning_rate': 0.1, 'n_estimators': 10, 'subsample': 0.1} on train/test set 2013-01-01 00:00:00\n",
      "2019-06-12 08:50:02.026210: Running GB with params: {'learning_rate': 0.1, 'n_estimators': 10, 'subsample': 1.0} on train/test set 2013-01-01 00:00:00\n",
      "2019-06-12 08:50:02.740267: Running GB with params: {'learning_rate': 0.1, 'n_estimators': 100, 'subsample': 0.1} on train/test set 2013-01-01 00:00:00\n",
      "2019-06-12 08:50:05.111481: Running GB with params: {'learning_rate': 0.1, 'n_estimators': 100, 'subsample': 1.0} on train/test set 2013-01-01 00:00:00\n",
      "2019-06-12 08:50:09.043731: Running ET with params: {'criterion': 'gini', 'max_depth': 2, 'n_estimators': 100} on train/test set 2013-01-01 00:00:00\n",
      "2019-06-12 08:50:09.631742: Running ET with params: {'criterion': 'gini', 'max_depth': 2, 'n_estimators': 1000} on train/test set 2013-01-01 00:00:00\n",
      "2019-06-12 08:50:12.424854: Running ET with params: {'criterion': 'gini', 'max_depth': 5, 'n_estimators': 100} on train/test set 2013-01-01 00:00:00\n",
      "2019-06-12 08:50:13.264069: Running ET with params: {'criterion': 'gini', 'max_depth': 5, 'n_estimators': 1000} on train/test set 2013-01-01 00:00:00\n",
      "2019-06-12 08:50:16.554410: Running ET with params: {'criterion': 'gini', 'max_depth': 50, 'n_estimators': 100} on train/test set 2013-01-01 00:00:00\n",
      "2019-06-12 08:50:17.694852: Running ET with params: {'criterion': 'gini', 'max_depth': 50, 'n_estimators': 1000} on train/test set 2013-01-01 00:00:00\n",
      "2019-06-12 08:50:26.152138: Running ET with params: {'criterion': 'entropy', 'max_depth': 2, 'n_estimators': 100} on train/test set 2013-01-01 00:00:00\n",
      "2019-06-12 08:50:26.852823: Running ET with params: {'criterion': 'entropy', 'max_depth': 2, 'n_estimators': 1000} on train/test set 2013-01-01 00:00:00\n",
      "2019-06-12 08:50:29.471909: Running ET with params: {'criterion': 'entropy', 'max_depth': 5, 'n_estimators': 100} on train/test set 2013-01-01 00:00:00\n",
      "2019-06-12 08:50:30.292558: Running ET with params: {'criterion': 'entropy', 'max_depth': 5, 'n_estimators': 1000} on train/test set 2013-01-01 00:00:00\n",
      "2019-06-12 08:50:36.486740: Running ET with params: {'criterion': 'entropy', 'max_depth': 50, 'n_estimators': 100} on train/test set 2013-01-01 00:00:00\n",
      "2019-06-12 08:50:37.516709: Running ET with params: {'criterion': 'entropy', 'max_depth': 50, 'n_estimators': 1000} on train/test set 2013-01-01 00:00:00\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>model</th>\n",
       "      <th>parameters</th>\n",
       "      <th>test_set_start_date</th>\n",
       "      <th>baseline</th>\n",
       "      <th>p_at_1</th>\n",
       "      <th>r_at_1</th>\n",
       "      <th>f1_at_1</th>\n",
       "      <th>p_at_2</th>\n",
       "      <th>r_at_2</th>\n",
       "      <th>...</th>\n",
       "      <th>p_at_20</th>\n",
       "      <th>r_at_20</th>\n",
       "      <th>f1_at_20</th>\n",
       "      <th>p_at_30</th>\n",
       "      <th>r_at_30</th>\n",
       "      <th>f1_at_30</th>\n",
       "      <th>p_at_50</th>\n",
       "      <th>r_at_50</th>\n",
       "      <th>f1_at_50</th>\n",
       "      <th>auc-roc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LR</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>{'C': 0.001, 'penalty': 'l1'}</td>\n",
       "      <td>2004-01-01</td>\n",
       "      <td>0.139671</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.068441</td>\n",
       "      <td>0.128114</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.140684</td>\n",
       "      <td>...</td>\n",
       "      <td>0.574468</td>\n",
       "      <td>0.821293</td>\n",
       "      <td>0.676056</td>\n",
       "      <td>0.423759</td>\n",
       "      <td>0.908745</td>\n",
       "      <td>0.577993</td>\n",
       "      <td>0.274176</td>\n",
       "      <td>0.980989</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.940694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LR</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>{'C': 0.001, 'penalty': 'l2'}</td>\n",
       "      <td>2004-01-01</td>\n",
       "      <td>0.139671</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.068441</td>\n",
       "      <td>0.128114</td>\n",
       "      <td>0.972973</td>\n",
       "      <td>0.136882</td>\n",
       "      <td>...</td>\n",
       "      <td>0.593085</td>\n",
       "      <td>0.847909</td>\n",
       "      <td>0.697966</td>\n",
       "      <td>0.439716</td>\n",
       "      <td>0.942966</td>\n",
       "      <td>0.599758</td>\n",
       "      <td>0.277365</td>\n",
       "      <td>0.992395</td>\n",
       "      <td>0.433555</td>\n",
       "      <td>0.955272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LR</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>{'C': 0.1, 'penalty': 'l1'}</td>\n",
       "      <td>2004-01-01</td>\n",
       "      <td>0.139671</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.053232</td>\n",
       "      <td>0.099644</td>\n",
       "      <td>0.783784</td>\n",
       "      <td>0.110266</td>\n",
       "      <td>...</td>\n",
       "      <td>0.555851</td>\n",
       "      <td>0.794677</td>\n",
       "      <td>0.654147</td>\n",
       "      <td>0.425532</td>\n",
       "      <td>0.912548</td>\n",
       "      <td>0.580411</td>\n",
       "      <td>0.272051</td>\n",
       "      <td>0.973384</td>\n",
       "      <td>0.425249</td>\n",
       "      <td>0.927996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LR</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>{'C': 0.1, 'penalty': 'l2'}</td>\n",
       "      <td>2004-01-01</td>\n",
       "      <td>0.139671</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.068441</td>\n",
       "      <td>0.128114</td>\n",
       "      <td>0.972973</td>\n",
       "      <td>0.136882</td>\n",
       "      <td>...</td>\n",
       "      <td>0.590426</td>\n",
       "      <td>0.844106</td>\n",
       "      <td>0.694836</td>\n",
       "      <td>0.439716</td>\n",
       "      <td>0.942966</td>\n",
       "      <td>0.599758</td>\n",
       "      <td>0.277365</td>\n",
       "      <td>0.992395</td>\n",
       "      <td>0.433555</td>\n",
       "      <td>0.953185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LR</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>{'C': 1, 'penalty': 'l1'}</td>\n",
       "      <td>2004-01-01</td>\n",
       "      <td>0.139671</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.057034</td>\n",
       "      <td>0.106762</td>\n",
       "      <td>0.567568</td>\n",
       "      <td>0.079848</td>\n",
       "      <td>...</td>\n",
       "      <td>0.563830</td>\n",
       "      <td>0.806084</td>\n",
       "      <td>0.663537</td>\n",
       "      <td>0.423759</td>\n",
       "      <td>0.908745</td>\n",
       "      <td>0.577993</td>\n",
       "      <td>0.269926</td>\n",
       "      <td>0.965779</td>\n",
       "      <td>0.421927</td>\n",
       "      <td>0.918296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LR</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>{'C': 1, 'penalty': 'l2'}</td>\n",
       "      <td>2004-01-01</td>\n",
       "      <td>0.139671</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.068441</td>\n",
       "      <td>0.128114</td>\n",
       "      <td>0.972973</td>\n",
       "      <td>0.136882</td>\n",
       "      <td>...</td>\n",
       "      <td>0.614362</td>\n",
       "      <td>0.878327</td>\n",
       "      <td>0.723005</td>\n",
       "      <td>0.439716</td>\n",
       "      <td>0.942966</td>\n",
       "      <td>0.599758</td>\n",
       "      <td>0.276302</td>\n",
       "      <td>0.988593</td>\n",
       "      <td>0.431894</td>\n",
       "      <td>0.955891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LR</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>{'C': 10, 'penalty': 'l1'}</td>\n",
       "      <td>2004-01-01</td>\n",
       "      <td>0.139671</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.057034</td>\n",
       "      <td>0.106762</td>\n",
       "      <td>0.513514</td>\n",
       "      <td>0.072243</td>\n",
       "      <td>...</td>\n",
       "      <td>0.555851</td>\n",
       "      <td>0.794677</td>\n",
       "      <td>0.654147</td>\n",
       "      <td>0.425532</td>\n",
       "      <td>0.912548</td>\n",
       "      <td>0.580411</td>\n",
       "      <td>0.268863</td>\n",
       "      <td>0.961977</td>\n",
       "      <td>0.420266</td>\n",
       "      <td>0.912693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LR</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>{'C': 10, 'penalty': 'l2'}</td>\n",
       "      <td>2004-01-01</td>\n",
       "      <td>0.139671</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.068441</td>\n",
       "      <td>0.128114</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.140684</td>\n",
       "      <td>...</td>\n",
       "      <td>0.601064</td>\n",
       "      <td>0.859316</td>\n",
       "      <td>0.707355</td>\n",
       "      <td>0.443262</td>\n",
       "      <td>0.950570</td>\n",
       "      <td>0.604595</td>\n",
       "      <td>0.277365</td>\n",
       "      <td>0.992395</td>\n",
       "      <td>0.433555</td>\n",
       "      <td>0.958478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 2, 'min_sam...</td>\n",
       "      <td>2004-01-01</td>\n",
       "      <td>0.139671</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.068441</td>\n",
       "      <td>0.128114</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.140684</td>\n",
       "      <td>...</td>\n",
       "      <td>0.523936</td>\n",
       "      <td>0.749049</td>\n",
       "      <td>0.616588</td>\n",
       "      <td>0.349291</td>\n",
       "      <td>0.749049</td>\n",
       "      <td>0.476421</td>\n",
       "      <td>0.279490</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.436877</td>\n",
       "      <td>0.912381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 2, 'min_sam...</td>\n",
       "      <td>2004-01-01</td>\n",
       "      <td>0.139671</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.068441</td>\n",
       "      <td>0.128114</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.140684</td>\n",
       "      <td>...</td>\n",
       "      <td>0.523936</td>\n",
       "      <td>0.749049</td>\n",
       "      <td>0.616588</td>\n",
       "      <td>0.349291</td>\n",
       "      <td>0.749049</td>\n",
       "      <td>0.476421</td>\n",
       "      <td>0.279490</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.436877</td>\n",
       "      <td>0.912381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'min_sam...</td>\n",
       "      <td>2004-01-01</td>\n",
       "      <td>0.139671</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.030418</td>\n",
       "      <td>0.056940</td>\n",
       "      <td>0.729730</td>\n",
       "      <td>0.102662</td>\n",
       "      <td>...</td>\n",
       "      <td>0.526596</td>\n",
       "      <td>0.752852</td>\n",
       "      <td>0.619718</td>\n",
       "      <td>0.402482</td>\n",
       "      <td>0.863118</td>\n",
       "      <td>0.548972</td>\n",
       "      <td>0.264612</td>\n",
       "      <td>0.946768</td>\n",
       "      <td>0.413621</td>\n",
       "      <td>0.903642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'min_sam...</td>\n",
       "      <td>2004-01-01</td>\n",
       "      <td>0.139671</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.034221</td>\n",
       "      <td>0.064057</td>\n",
       "      <td>0.756757</td>\n",
       "      <td>0.106464</td>\n",
       "      <td>...</td>\n",
       "      <td>0.523936</td>\n",
       "      <td>0.749049</td>\n",
       "      <td>0.616588</td>\n",
       "      <td>0.406028</td>\n",
       "      <td>0.870722</td>\n",
       "      <td>0.553809</td>\n",
       "      <td>0.266738</td>\n",
       "      <td>0.954373</td>\n",
       "      <td>0.416944</td>\n",
       "      <td>0.907642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 10, 'min_sa...</td>\n",
       "      <td>2004-01-01</td>\n",
       "      <td>0.139671</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.003802</td>\n",
       "      <td>0.007117</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>0.003802</td>\n",
       "      <td>...</td>\n",
       "      <td>0.476064</td>\n",
       "      <td>0.680608</td>\n",
       "      <td>0.560250</td>\n",
       "      <td>0.358156</td>\n",
       "      <td>0.768061</td>\n",
       "      <td>0.488513</td>\n",
       "      <td>0.279490</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.436877</td>\n",
       "      <td>0.821502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 10, 'min_sa...</td>\n",
       "      <td>2004-01-01</td>\n",
       "      <td>0.139671</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.003802</td>\n",
       "      <td>0.007117</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>0.003802</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.714829</td>\n",
       "      <td>0.588419</td>\n",
       "      <td>0.372340</td>\n",
       "      <td>0.798479</td>\n",
       "      <td>0.507860</td>\n",
       "      <td>0.279490</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.436877</td>\n",
       "      <td>0.835716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 50, 'min_sa...</td>\n",
       "      <td>2004-01-01</td>\n",
       "      <td>0.139671</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.003802</td>\n",
       "      <td>0.007117</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>0.003802</td>\n",
       "      <td>...</td>\n",
       "      <td>0.438830</td>\n",
       "      <td>0.627376</td>\n",
       "      <td>0.516432</td>\n",
       "      <td>0.365248</td>\n",
       "      <td>0.783270</td>\n",
       "      <td>0.498186</td>\n",
       "      <td>0.279490</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.436877</td>\n",
       "      <td>0.826512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 50, 'min_sa...</td>\n",
       "      <td>2004-01-01</td>\n",
       "      <td>0.139671</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.003802</td>\n",
       "      <td>0.007117</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>0.003802</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.714829</td>\n",
       "      <td>0.588419</td>\n",
       "      <td>0.379433</td>\n",
       "      <td>0.813688</td>\n",
       "      <td>0.517533</td>\n",
       "      <td>0.279490</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.436877</td>\n",
       "      <td>0.841249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 100, 'min_s...</td>\n",
       "      <td>2004-01-01</td>\n",
       "      <td>0.139671</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.003802</td>\n",
       "      <td>0.007117</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>0.003802</td>\n",
       "      <td>...</td>\n",
       "      <td>0.438830</td>\n",
       "      <td>0.627376</td>\n",
       "      <td>0.516432</td>\n",
       "      <td>0.365248</td>\n",
       "      <td>0.783270</td>\n",
       "      <td>0.498186</td>\n",
       "      <td>0.279490</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.436877</td>\n",
       "      <td>0.826512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 100, 'min_s...</td>\n",
       "      <td>2004-01-01</td>\n",
       "      <td>0.139671</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.003802</td>\n",
       "      <td>0.007117</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>0.003802</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.714829</td>\n",
       "      <td>0.588419</td>\n",
       "      <td>0.379433</td>\n",
       "      <td>0.813688</td>\n",
       "      <td>0.517533</td>\n",
       "      <td>0.279490</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.436877</td>\n",
       "      <td>0.841249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 2, 'min_...</td>\n",
       "      <td>2004-01-01</td>\n",
       "      <td>0.139671</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.030418</td>\n",
       "      <td>0.056940</td>\n",
       "      <td>0.216216</td>\n",
       "      <td>0.030418</td>\n",
       "      <td>...</td>\n",
       "      <td>0.574468</td>\n",
       "      <td>0.821293</td>\n",
       "      <td>0.676056</td>\n",
       "      <td>0.406028</td>\n",
       "      <td>0.870722</td>\n",
       "      <td>0.553809</td>\n",
       "      <td>0.279490</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.436877</td>\n",
       "      <td>0.917399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 2, 'min_...</td>\n",
       "      <td>2004-01-01</td>\n",
       "      <td>0.139671</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.030418</td>\n",
       "      <td>0.056940</td>\n",
       "      <td>0.216216</td>\n",
       "      <td>0.030418</td>\n",
       "      <td>...</td>\n",
       "      <td>0.574468</td>\n",
       "      <td>0.821293</td>\n",
       "      <td>0.676056</td>\n",
       "      <td>0.406028</td>\n",
       "      <td>0.870722</td>\n",
       "      <td>0.553809</td>\n",
       "      <td>0.279490</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.436877</td>\n",
       "      <td>0.917399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 5, 'min_...</td>\n",
       "      <td>2004-01-01</td>\n",
       "      <td>0.139671</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.068441</td>\n",
       "      <td>0.128114</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.140684</td>\n",
       "      <td>...</td>\n",
       "      <td>0.574468</td>\n",
       "      <td>0.821293</td>\n",
       "      <td>0.676056</td>\n",
       "      <td>0.404255</td>\n",
       "      <td>0.866920</td>\n",
       "      <td>0.551391</td>\n",
       "      <td>0.279490</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.436877</td>\n",
       "      <td>0.898019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 5, 'min_...</td>\n",
       "      <td>2004-01-01</td>\n",
       "      <td>0.139671</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.068441</td>\n",
       "      <td>0.128114</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.140684</td>\n",
       "      <td>...</td>\n",
       "      <td>0.574468</td>\n",
       "      <td>0.821293</td>\n",
       "      <td>0.676056</td>\n",
       "      <td>0.404255</td>\n",
       "      <td>0.866920</td>\n",
       "      <td>0.551391</td>\n",
       "      <td>0.279490</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.436877</td>\n",
       "      <td>0.898019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 10, 'min...</td>\n",
       "      <td>2004-01-01</td>\n",
       "      <td>0.139671</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.003802</td>\n",
       "      <td>0.007117</td>\n",
       "      <td>0.054054</td>\n",
       "      <td>0.007605</td>\n",
       "      <td>...</td>\n",
       "      <td>0.534574</td>\n",
       "      <td>0.764259</td>\n",
       "      <td>0.629108</td>\n",
       "      <td>0.356383</td>\n",
       "      <td>0.764259</td>\n",
       "      <td>0.486094</td>\n",
       "      <td>0.279490</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.436877</td>\n",
       "      <td>0.832923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 10, 'min...</td>\n",
       "      <td>2004-01-01</td>\n",
       "      <td>0.139671</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.019011</td>\n",
       "      <td>0.035587</td>\n",
       "      <td>0.189189</td>\n",
       "      <td>0.026616</td>\n",
       "      <td>...</td>\n",
       "      <td>0.547872</td>\n",
       "      <td>0.783270</td>\n",
       "      <td>0.644757</td>\n",
       "      <td>0.370567</td>\n",
       "      <td>0.794677</td>\n",
       "      <td>0.505441</td>\n",
       "      <td>0.279490</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.436877</td>\n",
       "      <td>0.855848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 50, 'min...</td>\n",
       "      <td>2004-01-01</td>\n",
       "      <td>0.139671</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.003802</td>\n",
       "      <td>0.007117</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>0.003802</td>\n",
       "      <td>...</td>\n",
       "      <td>0.526596</td>\n",
       "      <td>0.752852</td>\n",
       "      <td>0.619718</td>\n",
       "      <td>0.351064</td>\n",
       "      <td>0.752852</td>\n",
       "      <td>0.478839</td>\n",
       "      <td>0.279490</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.436877</td>\n",
       "      <td>0.833216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 50, 'min...</td>\n",
       "      <td>2004-01-01</td>\n",
       "      <td>0.139671</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.003802</td>\n",
       "      <td>0.007117</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>0.003802</td>\n",
       "      <td>...</td>\n",
       "      <td>0.507979</td>\n",
       "      <td>0.726236</td>\n",
       "      <td>0.597809</td>\n",
       "      <td>0.354610</td>\n",
       "      <td>0.760456</td>\n",
       "      <td>0.483676</td>\n",
       "      <td>0.279490</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.436877</td>\n",
       "      <td>0.827743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 100, 'mi...</td>\n",
       "      <td>2004-01-01</td>\n",
       "      <td>0.139671</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.003802</td>\n",
       "      <td>0.007117</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>0.003802</td>\n",
       "      <td>...</td>\n",
       "      <td>0.526596</td>\n",
       "      <td>0.752852</td>\n",
       "      <td>0.619718</td>\n",
       "      <td>0.351064</td>\n",
       "      <td>0.752852</td>\n",
       "      <td>0.478839</td>\n",
       "      <td>0.279490</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.436877</td>\n",
       "      <td>0.833216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 100, 'mi...</td>\n",
       "      <td>2004-01-01</td>\n",
       "      <td>0.139671</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.003802</td>\n",
       "      <td>0.007117</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>0.003802</td>\n",
       "      <td>...</td>\n",
       "      <td>0.507979</td>\n",
       "      <td>0.726236</td>\n",
       "      <td>0.597809</td>\n",
       "      <td>0.354610</td>\n",
       "      <td>0.760456</td>\n",
       "      <td>0.483676</td>\n",
       "      <td>0.279490</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.436877</td>\n",
       "      <td>0.827743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 'sqrt', 'min_...</td>\n",
       "      <td>2004-01-01</td>\n",
       "      <td>0.139671</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.068441</td>\n",
       "      <td>0.128114</td>\n",
       "      <td>0.972973</td>\n",
       "      <td>0.136882</td>\n",
       "      <td>...</td>\n",
       "      <td>0.587766</td>\n",
       "      <td>0.840304</td>\n",
       "      <td>0.691706</td>\n",
       "      <td>0.429078</td>\n",
       "      <td>0.920152</td>\n",
       "      <td>0.585248</td>\n",
       "      <td>0.273114</td>\n",
       "      <td>0.977186</td>\n",
       "      <td>0.426910</td>\n",
       "      <td>0.943213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 'sqrt', 'min_...</td>\n",
       "      <td>2004-01-01</td>\n",
       "      <td>0.139671</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.068441</td>\n",
       "      <td>0.128114</td>\n",
       "      <td>0.972973</td>\n",
       "      <td>0.136882</td>\n",
       "      <td>...</td>\n",
       "      <td>0.590426</td>\n",
       "      <td>0.844106</td>\n",
       "      <td>0.694836</td>\n",
       "      <td>0.430851</td>\n",
       "      <td>0.923954</td>\n",
       "      <td>0.587666</td>\n",
       "      <td>0.273114</td>\n",
       "      <td>0.977186</td>\n",
       "      <td>0.426910</td>\n",
       "      <td>0.942787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>960</th>\n",
       "      <td>KNN</td>\n",
       "      <td>KNeighborsClassifier(algorithm='ball_tree', le...</td>\n",
       "      <td>{'algorithm': 'ball_tree', 'n_neighbors': 50, ...</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>0.146552</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.110294</td>\n",
       "      <td>0.794118</td>\n",
       "      <td>0.105882</td>\n",
       "      <td>...</td>\n",
       "      <td>0.347701</td>\n",
       "      <td>0.474510</td>\n",
       "      <td>0.401327</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.568627</td>\n",
       "      <td>0.373230</td>\n",
       "      <td>0.219540</td>\n",
       "      <td>0.749020</td>\n",
       "      <td>0.339556</td>\n",
       "      <td>0.723173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>961</th>\n",
       "      <td>KNN</td>\n",
       "      <td>KNeighborsClassifier(algorithm='ball_tree', le...</td>\n",
       "      <td>{'algorithm': 'ball_tree', 'n_neighbors': 100,...</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>0.146552</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.110294</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.101961</td>\n",
       "      <td>...</td>\n",
       "      <td>0.350575</td>\n",
       "      <td>0.478431</td>\n",
       "      <td>0.404643</td>\n",
       "      <td>0.281609</td>\n",
       "      <td>0.576471</td>\n",
       "      <td>0.378378</td>\n",
       "      <td>0.217241</td>\n",
       "      <td>0.741176</td>\n",
       "      <td>0.336000</td>\n",
       "      <td>0.719687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>962</th>\n",
       "      <td>KNN</td>\n",
       "      <td>KNeighborsClassifier(algorithm='ball_tree', le...</td>\n",
       "      <td>{'algorithm': 'ball_tree', 'n_neighbors': 100,...</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>0.146552</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.110294</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.101961</td>\n",
       "      <td>...</td>\n",
       "      <td>0.353448</td>\n",
       "      <td>0.482353</td>\n",
       "      <td>0.407960</td>\n",
       "      <td>0.291188</td>\n",
       "      <td>0.596078</td>\n",
       "      <td>0.391248</td>\n",
       "      <td>0.217241</td>\n",
       "      <td>0.741176</td>\n",
       "      <td>0.336000</td>\n",
       "      <td>0.722970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>963</th>\n",
       "      <td>NB</td>\n",
       "      <td>GaussianNB(priors=None, var_smoothing=1e-09)</td>\n",
       "      <td>{}</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>0.146552</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.794118</td>\n",
       "      <td>0.105882</td>\n",
       "      <td>...</td>\n",
       "      <td>0.534483</td>\n",
       "      <td>0.729412</td>\n",
       "      <td>0.616915</td>\n",
       "      <td>0.409962</td>\n",
       "      <td>0.839216</td>\n",
       "      <td>0.550837</td>\n",
       "      <td>0.272414</td>\n",
       "      <td>0.929412</td>\n",
       "      <td>0.421333</td>\n",
       "      <td>0.902033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>964</th>\n",
       "      <td>BA</td>\n",
       "      <td>(KNeighborsClassifier(algorithm='auto', leaf_s...</td>\n",
       "      <td>{'n_estimators': 10}</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>0.146552</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.035294</td>\n",
       "      <td>0.066176</td>\n",
       "      <td>0.676471</td>\n",
       "      <td>0.090196</td>\n",
       "      <td>...</td>\n",
       "      <td>0.316092</td>\n",
       "      <td>0.431373</td>\n",
       "      <td>0.364842</td>\n",
       "      <td>0.279693</td>\n",
       "      <td>0.572549</td>\n",
       "      <td>0.375804</td>\n",
       "      <td>0.293103</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.453333</td>\n",
       "      <td>0.681541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>965</th>\n",
       "      <td>BA</td>\n",
       "      <td>(KNeighborsClassifier(algorithm='auto', leaf_s...</td>\n",
       "      <td>{'n_estimators': 100}</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>0.146552</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.110294</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.094118</td>\n",
       "      <td>...</td>\n",
       "      <td>0.330460</td>\n",
       "      <td>0.450980</td>\n",
       "      <td>0.381426</td>\n",
       "      <td>0.287356</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.386100</td>\n",
       "      <td>0.293103</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.453333</td>\n",
       "      <td>0.697448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>966</th>\n",
       "      <td>AB</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'algorithm': 'SAMME', 'n_estimators': 10}</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>0.146552</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.502874</td>\n",
       "      <td>0.686275</td>\n",
       "      <td>0.580431</td>\n",
       "      <td>0.450192</td>\n",
       "      <td>0.921569</td>\n",
       "      <td>0.604891</td>\n",
       "      <td>0.288506</td>\n",
       "      <td>0.984314</td>\n",
       "      <td>0.446222</td>\n",
       "      <td>0.939806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>967</th>\n",
       "      <td>AB</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'algorithm': 'SAMME', 'n_estimators': 100}</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>0.146552</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.603448</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.696517</td>\n",
       "      <td>0.454023</td>\n",
       "      <td>0.929412</td>\n",
       "      <td>0.610039</td>\n",
       "      <td>0.289655</td>\n",
       "      <td>0.988235</td>\n",
       "      <td>0.448000</td>\n",
       "      <td>0.950007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>968</th>\n",
       "      <td>AB</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'algorithm': 'SAMME.R', 'n_estimators': 10}</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>0.146552</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.911765</td>\n",
       "      <td>0.121569</td>\n",
       "      <td>...</td>\n",
       "      <td>0.580460</td>\n",
       "      <td>0.792157</td>\n",
       "      <td>0.669983</td>\n",
       "      <td>0.461686</td>\n",
       "      <td>0.945098</td>\n",
       "      <td>0.620335</td>\n",
       "      <td>0.289655</td>\n",
       "      <td>0.988235</td>\n",
       "      <td>0.448000</td>\n",
       "      <td>0.951052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>969</th>\n",
       "      <td>AB</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'algorithm': 'SAMME.R', 'n_estimators': 100}</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>0.146552</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.603448</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.696517</td>\n",
       "      <td>0.442529</td>\n",
       "      <td>0.905882</td>\n",
       "      <td>0.594595</td>\n",
       "      <td>0.283908</td>\n",
       "      <td>0.968627</td>\n",
       "      <td>0.439111</td>\n",
       "      <td>0.934299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>970</th>\n",
       "      <td>GB</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>{'learning_rate': 0.001, 'n_estimators': 10, '...</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>0.146552</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.970588</td>\n",
       "      <td>0.129412</td>\n",
       "      <td>...</td>\n",
       "      <td>0.617816</td>\n",
       "      <td>0.843137</td>\n",
       "      <td>0.713101</td>\n",
       "      <td>0.446360</td>\n",
       "      <td>0.913725</td>\n",
       "      <td>0.599743</td>\n",
       "      <td>0.290805</td>\n",
       "      <td>0.992157</td>\n",
       "      <td>0.449778</td>\n",
       "      <td>0.954604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971</th>\n",
       "      <td>GB</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>{'learning_rate': 0.001, 'n_estimators': 10, '...</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>0.146552</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.911765</td>\n",
       "      <td>0.121569</td>\n",
       "      <td>...</td>\n",
       "      <td>0.603448</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.696517</td>\n",
       "      <td>0.402299</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.540541</td>\n",
       "      <td>0.293103</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.453333</td>\n",
       "      <td>0.930850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>972</th>\n",
       "      <td>GB</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>{'learning_rate': 0.001, 'n_estimators': 100, ...</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>0.146552</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.617816</td>\n",
       "      <td>0.843137</td>\n",
       "      <td>0.713101</td>\n",
       "      <td>0.465517</td>\n",
       "      <td>0.952941</td>\n",
       "      <td>0.625483</td>\n",
       "      <td>0.293103</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.453333</td>\n",
       "      <td>0.960463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973</th>\n",
       "      <td>GB</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>{'learning_rate': 0.001, 'n_estimators': 100, ...</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>0.146552</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.911765</td>\n",
       "      <td>0.121569</td>\n",
       "      <td>...</td>\n",
       "      <td>0.603448</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.696517</td>\n",
       "      <td>0.423372</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.568855</td>\n",
       "      <td>0.293103</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.453333</td>\n",
       "      <td>0.941950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>974</th>\n",
       "      <td>GB</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>{'learning_rate': 0.1, 'n_estimators': 10, 'su...</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>0.146552</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.612069</td>\n",
       "      <td>0.835294</td>\n",
       "      <td>0.706468</td>\n",
       "      <td>0.448276</td>\n",
       "      <td>0.917647</td>\n",
       "      <td>0.602317</td>\n",
       "      <td>0.290805</td>\n",
       "      <td>0.992157</td>\n",
       "      <td>0.449778</td>\n",
       "      <td>0.951563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>975</th>\n",
       "      <td>GB</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>{'learning_rate': 0.1, 'n_estimators': 10, 'su...</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>0.146552</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.970588</td>\n",
       "      <td>0.129412</td>\n",
       "      <td>...</td>\n",
       "      <td>0.609195</td>\n",
       "      <td>0.831373</td>\n",
       "      <td>0.703151</td>\n",
       "      <td>0.457854</td>\n",
       "      <td>0.937255</td>\n",
       "      <td>0.615187</td>\n",
       "      <td>0.291954</td>\n",
       "      <td>0.996078</td>\n",
       "      <td>0.451556</td>\n",
       "      <td>0.955656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>976</th>\n",
       "      <td>GB</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>{'learning_rate': 0.1, 'n_estimators': 100, 's...</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>0.146552</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.970588</td>\n",
       "      <td>0.129412</td>\n",
       "      <td>...</td>\n",
       "      <td>0.594828</td>\n",
       "      <td>0.811765</td>\n",
       "      <td>0.686567</td>\n",
       "      <td>0.452107</td>\n",
       "      <td>0.925490</td>\n",
       "      <td>0.607465</td>\n",
       "      <td>0.289655</td>\n",
       "      <td>0.988235</td>\n",
       "      <td>0.448000</td>\n",
       "      <td>0.940630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>977</th>\n",
       "      <td>GB</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>{'learning_rate': 0.1, 'n_estimators': 100, 's...</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>0.146552</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.603448</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.696517</td>\n",
       "      <td>0.452107</td>\n",
       "      <td>0.925490</td>\n",
       "      <td>0.607465</td>\n",
       "      <td>0.291954</td>\n",
       "      <td>0.996078</td>\n",
       "      <td>0.451556</td>\n",
       "      <td>0.952982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>978</th>\n",
       "      <td>ET</td>\n",
       "      <td>(ExtraTreeClassifier(class_weight=None, criter...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 2, 'n_estim...</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>0.146552</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.560345</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.646766</td>\n",
       "      <td>0.438697</td>\n",
       "      <td>0.898039</td>\n",
       "      <td>0.589447</td>\n",
       "      <td>0.288506</td>\n",
       "      <td>0.984314</td>\n",
       "      <td>0.446222</td>\n",
       "      <td>0.934054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>979</th>\n",
       "      <td>ET</td>\n",
       "      <td>(ExtraTreeClassifier(class_weight=None, criter...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 2, 'n_estim...</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>0.146552</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.571839</td>\n",
       "      <td>0.780392</td>\n",
       "      <td>0.660033</td>\n",
       "      <td>0.440613</td>\n",
       "      <td>0.901961</td>\n",
       "      <td>0.592021</td>\n",
       "      <td>0.287356</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.935496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>980</th>\n",
       "      <td>ET</td>\n",
       "      <td>(ExtraTreeClassifier(class_weight=None, criter...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'n_estim...</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>0.146552</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.580460</td>\n",
       "      <td>0.792157</td>\n",
       "      <td>0.669983</td>\n",
       "      <td>0.436782</td>\n",
       "      <td>0.894118</td>\n",
       "      <td>0.586873</td>\n",
       "      <td>0.289655</td>\n",
       "      <td>0.988235</td>\n",
       "      <td>0.448000</td>\n",
       "      <td>0.939774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981</th>\n",
       "      <td>ET</td>\n",
       "      <td>(ExtraTreeClassifier(class_weight=None, criter...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'n_estim...</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>0.146552</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.796078</td>\n",
       "      <td>0.673300</td>\n",
       "      <td>0.442529</td>\n",
       "      <td>0.905882</td>\n",
       "      <td>0.594595</td>\n",
       "      <td>0.288506</td>\n",
       "      <td>0.984314</td>\n",
       "      <td>0.446222</td>\n",
       "      <td>0.939589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>ET</td>\n",
       "      <td>(ExtraTreeClassifier(class_weight=None, criter...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 50, 'n_esti...</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>0.146552</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.594828</td>\n",
       "      <td>0.811765</td>\n",
       "      <td>0.686567</td>\n",
       "      <td>0.446360</td>\n",
       "      <td>0.913725</td>\n",
       "      <td>0.599743</td>\n",
       "      <td>0.289655</td>\n",
       "      <td>0.988235</td>\n",
       "      <td>0.448000</td>\n",
       "      <td>0.943382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>ET</td>\n",
       "      <td>(ExtraTreeClassifier(class_weight=None, criter...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 50, 'n_esti...</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>0.146552</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.970588</td>\n",
       "      <td>0.129412</td>\n",
       "      <td>...</td>\n",
       "      <td>0.597701</td>\n",
       "      <td>0.815686</td>\n",
       "      <td>0.689884</td>\n",
       "      <td>0.448276</td>\n",
       "      <td>0.917647</td>\n",
       "      <td>0.602317</td>\n",
       "      <td>0.288506</td>\n",
       "      <td>0.984314</td>\n",
       "      <td>0.446222</td>\n",
       "      <td>0.947307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>ET</td>\n",
       "      <td>(ExtraTreeClassifier(class_weight=None, criter...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 2, 'n_es...</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>0.146552</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.571839</td>\n",
       "      <td>0.780392</td>\n",
       "      <td>0.660033</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.909804</td>\n",
       "      <td>0.597169</td>\n",
       "      <td>0.287356</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.934981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>ET</td>\n",
       "      <td>(ExtraTreeClassifier(class_weight=None, criter...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 2, 'n_es...</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>0.146552</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.571839</td>\n",
       "      <td>0.780392</td>\n",
       "      <td>0.660033</td>\n",
       "      <td>0.438697</td>\n",
       "      <td>0.898039</td>\n",
       "      <td>0.589447</td>\n",
       "      <td>0.286207</td>\n",
       "      <td>0.976471</td>\n",
       "      <td>0.442667</td>\n",
       "      <td>0.934538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>ET</td>\n",
       "      <td>(ExtraTreeClassifier(class_weight=None, criter...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 5, 'n_es...</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>0.146552</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.580460</td>\n",
       "      <td>0.792157</td>\n",
       "      <td>0.669983</td>\n",
       "      <td>0.442529</td>\n",
       "      <td>0.905882</td>\n",
       "      <td>0.594595</td>\n",
       "      <td>0.288506</td>\n",
       "      <td>0.984314</td>\n",
       "      <td>0.446222</td>\n",
       "      <td>0.939040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>ET</td>\n",
       "      <td>(ExtraTreeClassifier(class_weight=None, criter...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 5, 'n_es...</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>0.146552</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.580460</td>\n",
       "      <td>0.792157</td>\n",
       "      <td>0.669983</td>\n",
       "      <td>0.442529</td>\n",
       "      <td>0.905882</td>\n",
       "      <td>0.594595</td>\n",
       "      <td>0.287356</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.938892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>ET</td>\n",
       "      <td>(ExtraTreeClassifier(class_weight=None, criter...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 50, 'n_e...</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>0.146552</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.125490</td>\n",
       "      <td>...</td>\n",
       "      <td>0.603448</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.696517</td>\n",
       "      <td>0.455939</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.612613</td>\n",
       "      <td>0.287356</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.944054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>ET</td>\n",
       "      <td>(ExtraTreeClassifier(class_weight=None, criter...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 50, 'n_e...</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>0.146552</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.062745</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.970588</td>\n",
       "      <td>0.129412</td>\n",
       "      <td>...</td>\n",
       "      <td>0.606322</td>\n",
       "      <td>0.827451</td>\n",
       "      <td>0.699834</td>\n",
       "      <td>0.452107</td>\n",
       "      <td>0.925490</td>\n",
       "      <td>0.607465</td>\n",
       "      <td>0.288506</td>\n",
       "      <td>0.984314</td>\n",
       "      <td>0.446222</td>\n",
       "      <td>0.946935</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>990 rows  27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    model_name                                              model  \\\n",
       "0           LR  LogisticRegression(C=10, class_weight=None, du...   \n",
       "1           LR  LogisticRegression(C=10, class_weight=None, du...   \n",
       "2           LR  LogisticRegression(C=10, class_weight=None, du...   \n",
       "3           LR  LogisticRegression(C=10, class_weight=None, du...   \n",
       "4           LR  LogisticRegression(C=10, class_weight=None, du...   \n",
       "5           LR  LogisticRegression(C=10, class_weight=None, du...   \n",
       "6           LR  LogisticRegression(C=10, class_weight=None, du...   \n",
       "7           LR  LogisticRegression(C=10, class_weight=None, du...   \n",
       "8           DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "9           DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "10          DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "11          DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "12          DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "13          DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "14          DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "15          DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "16          DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "17          DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "18          DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "19          DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "20          DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "21          DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "22          DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "23          DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "24          DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "25          DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "26          DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "27          DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "28          RF  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "29          RF  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "..         ...                                                ...   \n",
       "960        KNN  KNeighborsClassifier(algorithm='ball_tree', le...   \n",
       "961        KNN  KNeighborsClassifier(algorithm='ball_tree', le...   \n",
       "962        KNN  KNeighborsClassifier(algorithm='ball_tree', le...   \n",
       "963         NB       GaussianNB(priors=None, var_smoothing=1e-09)   \n",
       "964         BA  (KNeighborsClassifier(algorithm='auto', leaf_s...   \n",
       "965         BA  (KNeighborsClassifier(algorithm='auto', leaf_s...   \n",
       "966         AB  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "967         AB  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "968         AB  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "969         AB  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "970         GB  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "971         GB  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "972         GB  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "973         GB  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "974         GB  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "975         GB  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "976         GB  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "977         GB  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "978         ET  (ExtraTreeClassifier(class_weight=None, criter...   \n",
       "979         ET  (ExtraTreeClassifier(class_weight=None, criter...   \n",
       "980         ET  (ExtraTreeClassifier(class_weight=None, criter...   \n",
       "981         ET  (ExtraTreeClassifier(class_weight=None, criter...   \n",
       "982         ET  (ExtraTreeClassifier(class_weight=None, criter...   \n",
       "983         ET  (ExtraTreeClassifier(class_weight=None, criter...   \n",
       "984         ET  (ExtraTreeClassifier(class_weight=None, criter...   \n",
       "985         ET  (ExtraTreeClassifier(class_weight=None, criter...   \n",
       "986         ET  (ExtraTreeClassifier(class_weight=None, criter...   \n",
       "987         ET  (ExtraTreeClassifier(class_weight=None, criter...   \n",
       "988         ET  (ExtraTreeClassifier(class_weight=None, criter...   \n",
       "989         ET  (ExtraTreeClassifier(class_weight=None, criter...   \n",
       "\n",
       "                                            parameters test_set_start_date  \\\n",
       "0                        {'C': 0.001, 'penalty': 'l1'}          2004-01-01   \n",
       "1                        {'C': 0.001, 'penalty': 'l2'}          2004-01-01   \n",
       "2                          {'C': 0.1, 'penalty': 'l1'}          2004-01-01   \n",
       "3                          {'C': 0.1, 'penalty': 'l2'}          2004-01-01   \n",
       "4                            {'C': 1, 'penalty': 'l1'}          2004-01-01   \n",
       "5                            {'C': 1, 'penalty': 'l2'}          2004-01-01   \n",
       "6                           {'C': 10, 'penalty': 'l1'}          2004-01-01   \n",
       "7                           {'C': 10, 'penalty': 'l2'}          2004-01-01   \n",
       "8    {'criterion': 'gini', 'max_depth': 2, 'min_sam...          2004-01-01   \n",
       "9    {'criterion': 'gini', 'max_depth': 2, 'min_sam...          2004-01-01   \n",
       "10   {'criterion': 'gini', 'max_depth': 5, 'min_sam...          2004-01-01   \n",
       "11   {'criterion': 'gini', 'max_depth': 5, 'min_sam...          2004-01-01   \n",
       "12   {'criterion': 'gini', 'max_depth': 10, 'min_sa...          2004-01-01   \n",
       "13   {'criterion': 'gini', 'max_depth': 10, 'min_sa...          2004-01-01   \n",
       "14   {'criterion': 'gini', 'max_depth': 50, 'min_sa...          2004-01-01   \n",
       "15   {'criterion': 'gini', 'max_depth': 50, 'min_sa...          2004-01-01   \n",
       "16   {'criterion': 'gini', 'max_depth': 100, 'min_s...          2004-01-01   \n",
       "17   {'criterion': 'gini', 'max_depth': 100, 'min_s...          2004-01-01   \n",
       "18   {'criterion': 'entropy', 'max_depth': 2, 'min_...          2004-01-01   \n",
       "19   {'criterion': 'entropy', 'max_depth': 2, 'min_...          2004-01-01   \n",
       "20   {'criterion': 'entropy', 'max_depth': 5, 'min_...          2004-01-01   \n",
       "21   {'criterion': 'entropy', 'max_depth': 5, 'min_...          2004-01-01   \n",
       "22   {'criterion': 'entropy', 'max_depth': 10, 'min...          2004-01-01   \n",
       "23   {'criterion': 'entropy', 'max_depth': 10, 'min...          2004-01-01   \n",
       "24   {'criterion': 'entropy', 'max_depth': 50, 'min...          2004-01-01   \n",
       "25   {'criterion': 'entropy', 'max_depth': 50, 'min...          2004-01-01   \n",
       "26   {'criterion': 'entropy', 'max_depth': 100, 'mi...          2004-01-01   \n",
       "27   {'criterion': 'entropy', 'max_depth': 100, 'mi...          2004-01-01   \n",
       "28   {'max_depth': 5, 'max_features': 'sqrt', 'min_...          2004-01-01   \n",
       "29   {'max_depth': 5, 'max_features': 'sqrt', 'min_...          2004-01-01   \n",
       "..                                                 ...                 ...   \n",
       "960  {'algorithm': 'ball_tree', 'n_neighbors': 50, ...          2013-01-01   \n",
       "961  {'algorithm': 'ball_tree', 'n_neighbors': 100,...          2013-01-01   \n",
       "962  {'algorithm': 'ball_tree', 'n_neighbors': 100,...          2013-01-01   \n",
       "963                                                 {}          2013-01-01   \n",
       "964                               {'n_estimators': 10}          2013-01-01   \n",
       "965                              {'n_estimators': 100}          2013-01-01   \n",
       "966         {'algorithm': 'SAMME', 'n_estimators': 10}          2013-01-01   \n",
       "967        {'algorithm': 'SAMME', 'n_estimators': 100}          2013-01-01   \n",
       "968       {'algorithm': 'SAMME.R', 'n_estimators': 10}          2013-01-01   \n",
       "969      {'algorithm': 'SAMME.R', 'n_estimators': 100}          2013-01-01   \n",
       "970  {'learning_rate': 0.001, 'n_estimators': 10, '...          2013-01-01   \n",
       "971  {'learning_rate': 0.001, 'n_estimators': 10, '...          2013-01-01   \n",
       "972  {'learning_rate': 0.001, 'n_estimators': 100, ...          2013-01-01   \n",
       "973  {'learning_rate': 0.001, 'n_estimators': 100, ...          2013-01-01   \n",
       "974  {'learning_rate': 0.1, 'n_estimators': 10, 'su...          2013-01-01   \n",
       "975  {'learning_rate': 0.1, 'n_estimators': 10, 'su...          2013-01-01   \n",
       "976  {'learning_rate': 0.1, 'n_estimators': 100, 's...          2013-01-01   \n",
       "977  {'learning_rate': 0.1, 'n_estimators': 100, 's...          2013-01-01   \n",
       "978  {'criterion': 'gini', 'max_depth': 2, 'n_estim...          2013-01-01   \n",
       "979  {'criterion': 'gini', 'max_depth': 2, 'n_estim...          2013-01-01   \n",
       "980  {'criterion': 'gini', 'max_depth': 5, 'n_estim...          2013-01-01   \n",
       "981  {'criterion': 'gini', 'max_depth': 5, 'n_estim...          2013-01-01   \n",
       "982  {'criterion': 'gini', 'max_depth': 50, 'n_esti...          2013-01-01   \n",
       "983  {'criterion': 'gini', 'max_depth': 50, 'n_esti...          2013-01-01   \n",
       "984  {'criterion': 'entropy', 'max_depth': 2, 'n_es...          2013-01-01   \n",
       "985  {'criterion': 'entropy', 'max_depth': 2, 'n_es...          2013-01-01   \n",
       "986  {'criterion': 'entropy', 'max_depth': 5, 'n_es...          2013-01-01   \n",
       "987  {'criterion': 'entropy', 'max_depth': 5, 'n_es...          2013-01-01   \n",
       "988  {'criterion': 'entropy', 'max_depth': 50, 'n_e...          2013-01-01   \n",
       "989  {'criterion': 'entropy', 'max_depth': 50, 'n_e...          2013-01-01   \n",
       "\n",
       "     baseline    p_at_1    r_at_1   f1_at_1    p_at_2    r_at_2  ...  \\\n",
       "0    0.139671  1.000000  0.068441  0.128114  1.000000  0.140684  ...   \n",
       "1    0.139671  1.000000  0.068441  0.128114  0.972973  0.136882  ...   \n",
       "2    0.139671  0.777778  0.053232  0.099644  0.783784  0.110266  ...   \n",
       "3    0.139671  1.000000  0.068441  0.128114  0.972973  0.136882  ...   \n",
       "4    0.139671  0.833333  0.057034  0.106762  0.567568  0.079848  ...   \n",
       "5    0.139671  1.000000  0.068441  0.128114  0.972973  0.136882  ...   \n",
       "6    0.139671  0.833333  0.057034  0.106762  0.513514  0.072243  ...   \n",
       "7    0.139671  1.000000  0.068441  0.128114  1.000000  0.140684  ...   \n",
       "8    0.139671  1.000000  0.068441  0.128114  1.000000  0.140684  ...   \n",
       "9    0.139671  1.000000  0.068441  0.128114  1.000000  0.140684  ...   \n",
       "10   0.139671  0.444444  0.030418  0.056940  0.729730  0.102662  ...   \n",
       "11   0.139671  0.500000  0.034221  0.064057  0.756757  0.106464  ...   \n",
       "12   0.139671  0.055556  0.003802  0.007117  0.027027  0.003802  ...   \n",
       "13   0.139671  0.055556  0.003802  0.007117  0.027027  0.003802  ...   \n",
       "14   0.139671  0.055556  0.003802  0.007117  0.027027  0.003802  ...   \n",
       "15   0.139671  0.055556  0.003802  0.007117  0.027027  0.003802  ...   \n",
       "16   0.139671  0.055556  0.003802  0.007117  0.027027  0.003802  ...   \n",
       "17   0.139671  0.055556  0.003802  0.007117  0.027027  0.003802  ...   \n",
       "18   0.139671  0.444444  0.030418  0.056940  0.216216  0.030418  ...   \n",
       "19   0.139671  0.444444  0.030418  0.056940  0.216216  0.030418  ...   \n",
       "20   0.139671  1.000000  0.068441  0.128114  1.000000  0.140684  ...   \n",
       "21   0.139671  1.000000  0.068441  0.128114  1.000000  0.140684  ...   \n",
       "22   0.139671  0.055556  0.003802  0.007117  0.054054  0.007605  ...   \n",
       "23   0.139671  0.277778  0.019011  0.035587  0.189189  0.026616  ...   \n",
       "24   0.139671  0.055556  0.003802  0.007117  0.027027  0.003802  ...   \n",
       "25   0.139671  0.055556  0.003802  0.007117  0.027027  0.003802  ...   \n",
       "26   0.139671  0.055556  0.003802  0.007117  0.027027  0.003802  ...   \n",
       "27   0.139671  0.055556  0.003802  0.007117  0.027027  0.003802  ...   \n",
       "28   0.139671  1.000000  0.068441  0.128114  0.972973  0.136882  ...   \n",
       "29   0.139671  1.000000  0.068441  0.128114  0.972973  0.136882  ...   \n",
       "..        ...       ...       ...       ...       ...       ...  ...   \n",
       "960  0.146552  0.882353  0.058824  0.110294  0.794118  0.105882  ...   \n",
       "961  0.146552  0.882353  0.058824  0.110294  0.764706  0.101961  ...   \n",
       "962  0.146552  0.882353  0.058824  0.110294  0.764706  0.101961  ...   \n",
       "963  0.146552  1.000000  0.066667  0.125000  0.794118  0.105882  ...   \n",
       "964  0.146552  0.529412  0.035294  0.066176  0.676471  0.090196  ...   \n",
       "965  0.146552  0.882353  0.058824  0.110294  0.705882  0.094118  ...   \n",
       "966  0.146552  1.000000  0.066667  0.125000  1.000000  0.133333  ...   \n",
       "967  0.146552  1.000000  0.066667  0.125000  1.000000  0.133333  ...   \n",
       "968  0.146552  1.000000  0.066667  0.125000  0.911765  0.121569  ...   \n",
       "969  0.146552  1.000000  0.066667  0.125000  1.000000  0.133333  ...   \n",
       "970  0.146552  1.000000  0.066667  0.125000  0.970588  0.129412  ...   \n",
       "971  0.146552  1.000000  0.066667  0.125000  0.911765  0.121569  ...   \n",
       "972  0.146552  1.000000  0.066667  0.125000  1.000000  0.133333  ...   \n",
       "973  0.146552  1.000000  0.066667  0.125000  0.911765  0.121569  ...   \n",
       "974  0.146552  1.000000  0.066667  0.125000  1.000000  0.133333  ...   \n",
       "975  0.146552  1.000000  0.066667  0.125000  0.970588  0.129412  ...   \n",
       "976  0.146552  1.000000  0.066667  0.125000  0.970588  0.129412  ...   \n",
       "977  0.146552  1.000000  0.066667  0.125000  1.000000  0.133333  ...   \n",
       "978  0.146552  1.000000  0.066667  0.125000  1.000000  0.133333  ...   \n",
       "979  0.146552  1.000000  0.066667  0.125000  1.000000  0.133333  ...   \n",
       "980  0.146552  1.000000  0.066667  0.125000  1.000000  0.133333  ...   \n",
       "981  0.146552  1.000000  0.066667  0.125000  1.000000  0.133333  ...   \n",
       "982  0.146552  1.000000  0.066667  0.125000  1.000000  0.133333  ...   \n",
       "983  0.146552  1.000000  0.066667  0.125000  0.970588  0.129412  ...   \n",
       "984  0.146552  1.000000  0.066667  0.125000  1.000000  0.133333  ...   \n",
       "985  0.146552  1.000000  0.066667  0.125000  1.000000  0.133333  ...   \n",
       "986  0.146552  1.000000  0.066667  0.125000  1.000000  0.133333  ...   \n",
       "987  0.146552  1.000000  0.066667  0.125000  1.000000  0.133333  ...   \n",
       "988  0.146552  1.000000  0.066667  0.125000  0.941176  0.125490  ...   \n",
       "989  0.146552  0.941176  0.062745  0.117647  0.970588  0.129412  ...   \n",
       "\n",
       "      p_at_20   r_at_20  f1_at_20   p_at_30   r_at_30  f1_at_30   p_at_50  \\\n",
       "0    0.574468  0.821293  0.676056  0.423759  0.908745  0.577993  0.274176   \n",
       "1    0.593085  0.847909  0.697966  0.439716  0.942966  0.599758  0.277365   \n",
       "2    0.555851  0.794677  0.654147  0.425532  0.912548  0.580411  0.272051   \n",
       "3    0.590426  0.844106  0.694836  0.439716  0.942966  0.599758  0.277365   \n",
       "4    0.563830  0.806084  0.663537  0.423759  0.908745  0.577993  0.269926   \n",
       "5    0.614362  0.878327  0.723005  0.439716  0.942966  0.599758  0.276302   \n",
       "6    0.555851  0.794677  0.654147  0.425532  0.912548  0.580411  0.268863   \n",
       "7    0.601064  0.859316  0.707355  0.443262  0.950570  0.604595  0.277365   \n",
       "8    0.523936  0.749049  0.616588  0.349291  0.749049  0.476421  0.279490   \n",
       "9    0.523936  0.749049  0.616588  0.349291  0.749049  0.476421  0.279490   \n",
       "10   0.526596  0.752852  0.619718  0.402482  0.863118  0.548972  0.264612   \n",
       "11   0.523936  0.749049  0.616588  0.406028  0.870722  0.553809  0.266738   \n",
       "12   0.476064  0.680608  0.560250  0.358156  0.768061  0.488513  0.279490   \n",
       "13   0.500000  0.714829  0.588419  0.372340  0.798479  0.507860  0.279490   \n",
       "14   0.438830  0.627376  0.516432  0.365248  0.783270  0.498186  0.279490   \n",
       "15   0.500000  0.714829  0.588419  0.379433  0.813688  0.517533  0.279490   \n",
       "16   0.438830  0.627376  0.516432  0.365248  0.783270  0.498186  0.279490   \n",
       "17   0.500000  0.714829  0.588419  0.379433  0.813688  0.517533  0.279490   \n",
       "18   0.574468  0.821293  0.676056  0.406028  0.870722  0.553809  0.279490   \n",
       "19   0.574468  0.821293  0.676056  0.406028  0.870722  0.553809  0.279490   \n",
       "20   0.574468  0.821293  0.676056  0.404255  0.866920  0.551391  0.279490   \n",
       "21   0.574468  0.821293  0.676056  0.404255  0.866920  0.551391  0.279490   \n",
       "22   0.534574  0.764259  0.629108  0.356383  0.764259  0.486094  0.279490   \n",
       "23   0.547872  0.783270  0.644757  0.370567  0.794677  0.505441  0.279490   \n",
       "24   0.526596  0.752852  0.619718  0.351064  0.752852  0.478839  0.279490   \n",
       "25   0.507979  0.726236  0.597809  0.354610  0.760456  0.483676  0.279490   \n",
       "26   0.526596  0.752852  0.619718  0.351064  0.752852  0.478839  0.279490   \n",
       "27   0.507979  0.726236  0.597809  0.354610  0.760456  0.483676  0.279490   \n",
       "28   0.587766  0.840304  0.691706  0.429078  0.920152  0.585248  0.273114   \n",
       "29   0.590426  0.844106  0.694836  0.430851  0.923954  0.587666  0.273114   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "960  0.347701  0.474510  0.401327  0.277778  0.568627  0.373230  0.219540   \n",
       "961  0.350575  0.478431  0.404643  0.281609  0.576471  0.378378  0.217241   \n",
       "962  0.353448  0.482353  0.407960  0.291188  0.596078  0.391248  0.217241   \n",
       "963  0.534483  0.729412  0.616915  0.409962  0.839216  0.550837  0.272414   \n",
       "964  0.316092  0.431373  0.364842  0.279693  0.572549  0.375804  0.293103   \n",
       "965  0.330460  0.450980  0.381426  0.287356  0.588235  0.386100  0.293103   \n",
       "966  0.502874  0.686275  0.580431  0.450192  0.921569  0.604891  0.288506   \n",
       "967  0.603448  0.823529  0.696517  0.454023  0.929412  0.610039  0.289655   \n",
       "968  0.580460  0.792157  0.669983  0.461686  0.945098  0.620335  0.289655   \n",
       "969  0.603448  0.823529  0.696517  0.442529  0.905882  0.594595  0.283908   \n",
       "970  0.617816  0.843137  0.713101  0.446360  0.913725  0.599743  0.290805   \n",
       "971  0.603448  0.823529  0.696517  0.402299  0.823529  0.540541  0.293103   \n",
       "972  0.617816  0.843137  0.713101  0.465517  0.952941  0.625483  0.293103   \n",
       "973  0.603448  0.823529  0.696517  0.423372  0.866667  0.568855  0.293103   \n",
       "974  0.612069  0.835294  0.706468  0.448276  0.917647  0.602317  0.290805   \n",
       "975  0.609195  0.831373  0.703151  0.457854  0.937255  0.615187  0.291954   \n",
       "976  0.594828  0.811765  0.686567  0.452107  0.925490  0.607465  0.289655   \n",
       "977  0.603448  0.823529  0.696517  0.452107  0.925490  0.607465  0.291954   \n",
       "978  0.560345  0.764706  0.646766  0.438697  0.898039  0.589447  0.288506   \n",
       "979  0.571839  0.780392  0.660033  0.440613  0.901961  0.592021  0.287356   \n",
       "980  0.580460  0.792157  0.669983  0.436782  0.894118  0.586873  0.289655   \n",
       "981  0.583333  0.796078  0.673300  0.442529  0.905882  0.594595  0.288506   \n",
       "982  0.594828  0.811765  0.686567  0.446360  0.913725  0.599743  0.289655   \n",
       "983  0.597701  0.815686  0.689884  0.448276  0.917647  0.602317  0.288506   \n",
       "984  0.571839  0.780392  0.660033  0.444444  0.909804  0.597169  0.287356   \n",
       "985  0.571839  0.780392  0.660033  0.438697  0.898039  0.589447  0.286207   \n",
       "986  0.580460  0.792157  0.669983  0.442529  0.905882  0.594595  0.288506   \n",
       "987  0.580460  0.792157  0.669983  0.442529  0.905882  0.594595  0.287356   \n",
       "988  0.603448  0.823529  0.696517  0.455939  0.933333  0.612613  0.287356   \n",
       "989  0.606322  0.827451  0.699834  0.452107  0.925490  0.607465  0.288506   \n",
       "\n",
       "      r_at_50  f1_at_50   auc-roc  \n",
       "0    0.980989  0.428571  0.940694  \n",
       "1    0.992395  0.433555  0.955272  \n",
       "2    0.973384  0.425249  0.927996  \n",
       "3    0.992395  0.433555  0.953185  \n",
       "4    0.965779  0.421927  0.918296  \n",
       "5    0.988593  0.431894  0.955891  \n",
       "6    0.961977  0.420266  0.912693  \n",
       "7    0.992395  0.433555  0.958478  \n",
       "8    1.000000  0.436877  0.912381  \n",
       "9    1.000000  0.436877  0.912381  \n",
       "10   0.946768  0.413621  0.903642  \n",
       "11   0.954373  0.416944  0.907642  \n",
       "12   1.000000  0.436877  0.821502  \n",
       "13   1.000000  0.436877  0.835716  \n",
       "14   1.000000  0.436877  0.826512  \n",
       "15   1.000000  0.436877  0.841249  \n",
       "16   1.000000  0.436877  0.826512  \n",
       "17   1.000000  0.436877  0.841249  \n",
       "18   1.000000  0.436877  0.917399  \n",
       "19   1.000000  0.436877  0.917399  \n",
       "20   1.000000  0.436877  0.898019  \n",
       "21   1.000000  0.436877  0.898019  \n",
       "22   1.000000  0.436877  0.832923  \n",
       "23   1.000000  0.436877  0.855848  \n",
       "24   1.000000  0.436877  0.833216  \n",
       "25   1.000000  0.436877  0.827743  \n",
       "26   1.000000  0.436877  0.833216  \n",
       "27   1.000000  0.436877  0.827743  \n",
       "28   0.977186  0.426910  0.943213  \n",
       "29   0.977186  0.426910  0.942787  \n",
       "..        ...       ...       ...  \n",
       "960  0.749020  0.339556  0.723173  \n",
       "961  0.741176  0.336000  0.719687  \n",
       "962  0.741176  0.336000  0.722970  \n",
       "963  0.929412  0.421333  0.902033  \n",
       "964  1.000000  0.453333  0.681541  \n",
       "965  1.000000  0.453333  0.697448  \n",
       "966  0.984314  0.446222  0.939806  \n",
       "967  0.988235  0.448000  0.950007  \n",
       "968  0.988235  0.448000  0.951052  \n",
       "969  0.968627  0.439111  0.934299  \n",
       "970  0.992157  0.449778  0.954604  \n",
       "971  1.000000  0.453333  0.930850  \n",
       "972  1.000000  0.453333  0.960463  \n",
       "973  1.000000  0.453333  0.941950  \n",
       "974  0.992157  0.449778  0.951563  \n",
       "975  0.996078  0.451556  0.955656  \n",
       "976  0.988235  0.448000  0.940630  \n",
       "977  0.996078  0.451556  0.952982  \n",
       "978  0.984314  0.446222  0.934054  \n",
       "979  0.980392  0.444444  0.935496  \n",
       "980  0.988235  0.448000  0.939774  \n",
       "981  0.984314  0.446222  0.939589  \n",
       "982  0.988235  0.448000  0.943382  \n",
       "983  0.984314  0.446222  0.947307  \n",
       "984  0.980392  0.444444  0.934981  \n",
       "985  0.976471  0.442667  0.934538  \n",
       "986  0.984314  0.446222  0.939040  \n",
       "987  0.980392  0.444444  0.938892  \n",
       "988  0.980392  0.444444  0.944054  \n",
       "989  0.984314  0.446222  0.946935  \n",
       "\n",
       "[990 rows x 27 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "importlib.reload(pipeline)\n",
    "importlib.reload(loop)\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "results = loop.iterate_over_models_and_training_test_sets(models_to_run, models, parameters_grid, train_test_sets)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observe best models for each train/test set, for different metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>model</th>\n",
       "      <th>parameters</th>\n",
       "      <th>test_set_start_date</th>\n",
       "      <th>baseline</th>\n",
       "      <th>p_at_1</th>\n",
       "      <th>r_at_1</th>\n",
       "      <th>f1_at_1</th>\n",
       "      <th>p_at_2</th>\n",
       "      <th>r_at_2</th>\n",
       "      <th>...</th>\n",
       "      <th>p_at_20</th>\n",
       "      <th>r_at_20</th>\n",
       "      <th>f1_at_20</th>\n",
       "      <th>p_at_30</th>\n",
       "      <th>r_at_30</th>\n",
       "      <th>f1_at_30</th>\n",
       "      <th>p_at_50</th>\n",
       "      <th>r_at_50</th>\n",
       "      <th>f1_at_50</th>\n",
       "      <th>auc-roc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LR</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>{'C': 0.001, 'penalty': 'l1'}</td>\n",
       "      <td>2004-01-01</td>\n",
       "      <td>0.139671</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.068441</td>\n",
       "      <td>0.128114</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.140684</td>\n",
       "      <td>...</td>\n",
       "      <td>0.574468</td>\n",
       "      <td>0.821293</td>\n",
       "      <td>0.676056</td>\n",
       "      <td>0.423759</td>\n",
       "      <td>0.908745</td>\n",
       "      <td>0.577993</td>\n",
       "      <td>0.274176</td>\n",
       "      <td>0.980989</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.940694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LR</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>{'C': 0.001, 'penalty': 'l2'}</td>\n",
       "      <td>2004-01-01</td>\n",
       "      <td>0.139671</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.068441</td>\n",
       "      <td>0.128114</td>\n",
       "      <td>0.972973</td>\n",
       "      <td>0.136882</td>\n",
       "      <td>...</td>\n",
       "      <td>0.593085</td>\n",
       "      <td>0.847909</td>\n",
       "      <td>0.697966</td>\n",
       "      <td>0.439716</td>\n",
       "      <td>0.942966</td>\n",
       "      <td>0.599758</td>\n",
       "      <td>0.277365</td>\n",
       "      <td>0.992395</td>\n",
       "      <td>0.433555</td>\n",
       "      <td>0.955272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LR</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>{'C': 0.1, 'penalty': 'l1'}</td>\n",
       "      <td>2004-01-01</td>\n",
       "      <td>0.139671</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.053232</td>\n",
       "      <td>0.099644</td>\n",
       "      <td>0.783784</td>\n",
       "      <td>0.110266</td>\n",
       "      <td>...</td>\n",
       "      <td>0.555851</td>\n",
       "      <td>0.794677</td>\n",
       "      <td>0.654147</td>\n",
       "      <td>0.425532</td>\n",
       "      <td>0.912548</td>\n",
       "      <td>0.580411</td>\n",
       "      <td>0.272051</td>\n",
       "      <td>0.973384</td>\n",
       "      <td>0.425249</td>\n",
       "      <td>0.927996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LR</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>{'C': 0.1, 'penalty': 'l2'}</td>\n",
       "      <td>2004-01-01</td>\n",
       "      <td>0.139671</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.068441</td>\n",
       "      <td>0.128114</td>\n",
       "      <td>0.972973</td>\n",
       "      <td>0.136882</td>\n",
       "      <td>...</td>\n",
       "      <td>0.590426</td>\n",
       "      <td>0.844106</td>\n",
       "      <td>0.694836</td>\n",
       "      <td>0.439716</td>\n",
       "      <td>0.942966</td>\n",
       "      <td>0.599758</td>\n",
       "      <td>0.277365</td>\n",
       "      <td>0.992395</td>\n",
       "      <td>0.433555</td>\n",
       "      <td>0.953185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LR</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>{'C': 1, 'penalty': 'l1'}</td>\n",
       "      <td>2004-01-01</td>\n",
       "      <td>0.139671</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.057034</td>\n",
       "      <td>0.106762</td>\n",
       "      <td>0.567568</td>\n",
       "      <td>0.079848</td>\n",
       "      <td>...</td>\n",
       "      <td>0.563830</td>\n",
       "      <td>0.806084</td>\n",
       "      <td>0.663537</td>\n",
       "      <td>0.423759</td>\n",
       "      <td>0.908745</td>\n",
       "      <td>0.577993</td>\n",
       "      <td>0.269926</td>\n",
       "      <td>0.965779</td>\n",
       "      <td>0.421927</td>\n",
       "      <td>0.918296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LR</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>{'C': 1, 'penalty': 'l2'}</td>\n",
       "      <td>2004-01-01</td>\n",
       "      <td>0.139671</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.068441</td>\n",
       "      <td>0.128114</td>\n",
       "      <td>0.972973</td>\n",
       "      <td>0.136882</td>\n",
       "      <td>...</td>\n",
       "      <td>0.614362</td>\n",
       "      <td>0.878327</td>\n",
       "      <td>0.723005</td>\n",
       "      <td>0.439716</td>\n",
       "      <td>0.942966</td>\n",
       "      <td>0.599758</td>\n",
       "      <td>0.276302</td>\n",
       "      <td>0.988593</td>\n",
       "      <td>0.431894</td>\n",
       "      <td>0.955891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LR</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>{'C': 10, 'penalty': 'l1'}</td>\n",
       "      <td>2004-01-01</td>\n",
       "      <td>0.139671</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.057034</td>\n",
       "      <td>0.106762</td>\n",
       "      <td>0.513514</td>\n",
       "      <td>0.072243</td>\n",
       "      <td>...</td>\n",
       "      <td>0.555851</td>\n",
       "      <td>0.794677</td>\n",
       "      <td>0.654147</td>\n",
       "      <td>0.425532</td>\n",
       "      <td>0.912548</td>\n",
       "      <td>0.580411</td>\n",
       "      <td>0.268863</td>\n",
       "      <td>0.961977</td>\n",
       "      <td>0.420266</td>\n",
       "      <td>0.912693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LR</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>{'C': 10, 'penalty': 'l2'}</td>\n",
       "      <td>2004-01-01</td>\n",
       "      <td>0.139671</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.068441</td>\n",
       "      <td>0.128114</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.140684</td>\n",
       "      <td>...</td>\n",
       "      <td>0.601064</td>\n",
       "      <td>0.859316</td>\n",
       "      <td>0.707355</td>\n",
       "      <td>0.443262</td>\n",
       "      <td>0.950570</td>\n",
       "      <td>0.604595</td>\n",
       "      <td>0.277365</td>\n",
       "      <td>0.992395</td>\n",
       "      <td>0.433555</td>\n",
       "      <td>0.958478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 2, 'min_sam...</td>\n",
       "      <td>2004-01-01</td>\n",
       "      <td>0.139671</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.068441</td>\n",
       "      <td>0.128114</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.140684</td>\n",
       "      <td>...</td>\n",
       "      <td>0.523936</td>\n",
       "      <td>0.749049</td>\n",
       "      <td>0.616588</td>\n",
       "      <td>0.349291</td>\n",
       "      <td>0.749049</td>\n",
       "      <td>0.476421</td>\n",
       "      <td>0.279490</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.436877</td>\n",
       "      <td>0.912381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 2, 'min_sam...</td>\n",
       "      <td>2004-01-01</td>\n",
       "      <td>0.139671</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.068441</td>\n",
       "      <td>0.128114</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.140684</td>\n",
       "      <td>...</td>\n",
       "      <td>0.523936</td>\n",
       "      <td>0.749049</td>\n",
       "      <td>0.616588</td>\n",
       "      <td>0.349291</td>\n",
       "      <td>0.749049</td>\n",
       "      <td>0.476421</td>\n",
       "      <td>0.279490</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.436877</td>\n",
       "      <td>0.912381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'min_sam...</td>\n",
       "      <td>2004-01-01</td>\n",
       "      <td>0.139671</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.030418</td>\n",
       "      <td>0.056940</td>\n",
       "      <td>0.729730</td>\n",
       "      <td>0.102662</td>\n",
       "      <td>...</td>\n",
       "      <td>0.526596</td>\n",
       "      <td>0.752852</td>\n",
       "      <td>0.619718</td>\n",
       "      <td>0.402482</td>\n",
       "      <td>0.863118</td>\n",
       "      <td>0.548972</td>\n",
       "      <td>0.264612</td>\n",
       "      <td>0.946768</td>\n",
       "      <td>0.413621</td>\n",
       "      <td>0.903642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'min_sam...</td>\n",
       "      <td>2004-01-01</td>\n",
       "      <td>0.139671</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.034221</td>\n",
       "      <td>0.064057</td>\n",
       "      <td>0.756757</td>\n",
       "      <td>0.106464</td>\n",
       "      <td>...</td>\n",
       "      <td>0.523936</td>\n",
       "      <td>0.749049</td>\n",
       "      <td>0.616588</td>\n",
       "      <td>0.406028</td>\n",
       "      <td>0.870722</td>\n",
       "      <td>0.553809</td>\n",
       "      <td>0.266738</td>\n",
       "      <td>0.954373</td>\n",
       "      <td>0.416944</td>\n",
       "      <td>0.907642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 10, 'min_sa...</td>\n",
       "      <td>2004-01-01</td>\n",
       "      <td>0.139671</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.003802</td>\n",
       "      <td>0.007117</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>0.003802</td>\n",
       "      <td>...</td>\n",
       "      <td>0.476064</td>\n",
       "      <td>0.680608</td>\n",
       "      <td>0.560250</td>\n",
       "      <td>0.358156</td>\n",
       "      <td>0.768061</td>\n",
       "      <td>0.488513</td>\n",
       "      <td>0.279490</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.436877</td>\n",
       "      <td>0.821502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 10, 'min_sa...</td>\n",
       "      <td>2004-01-01</td>\n",
       "      <td>0.139671</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.003802</td>\n",
       "      <td>0.007117</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>0.003802</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.714829</td>\n",
       "      <td>0.588419</td>\n",
       "      <td>0.372340</td>\n",
       "      <td>0.798479</td>\n",
       "      <td>0.507860</td>\n",
       "      <td>0.279490</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.436877</td>\n",
       "      <td>0.835716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 50, 'min_sa...</td>\n",
       "      <td>2004-01-01</td>\n",
       "      <td>0.139671</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.003802</td>\n",
       "      <td>0.007117</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>0.003802</td>\n",
       "      <td>...</td>\n",
       "      <td>0.438830</td>\n",
       "      <td>0.627376</td>\n",
       "      <td>0.516432</td>\n",
       "      <td>0.365248</td>\n",
       "      <td>0.783270</td>\n",
       "      <td>0.498186</td>\n",
       "      <td>0.279490</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.436877</td>\n",
       "      <td>0.826512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 50, 'min_sa...</td>\n",
       "      <td>2004-01-01</td>\n",
       "      <td>0.139671</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.003802</td>\n",
       "      <td>0.007117</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>0.003802</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.714829</td>\n",
       "      <td>0.588419</td>\n",
       "      <td>0.379433</td>\n",
       "      <td>0.813688</td>\n",
       "      <td>0.517533</td>\n",
       "      <td>0.279490</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.436877</td>\n",
       "      <td>0.841249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 100, 'min_s...</td>\n",
       "      <td>2004-01-01</td>\n",
       "      <td>0.139671</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.003802</td>\n",
       "      <td>0.007117</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>0.003802</td>\n",
       "      <td>...</td>\n",
       "      <td>0.438830</td>\n",
       "      <td>0.627376</td>\n",
       "      <td>0.516432</td>\n",
       "      <td>0.365248</td>\n",
       "      <td>0.783270</td>\n",
       "      <td>0.498186</td>\n",
       "      <td>0.279490</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.436877</td>\n",
       "      <td>0.826512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 100, 'min_s...</td>\n",
       "      <td>2004-01-01</td>\n",
       "      <td>0.139671</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.003802</td>\n",
       "      <td>0.007117</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>0.003802</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.714829</td>\n",
       "      <td>0.588419</td>\n",
       "      <td>0.379433</td>\n",
       "      <td>0.813688</td>\n",
       "      <td>0.517533</td>\n",
       "      <td>0.279490</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.436877</td>\n",
       "      <td>0.841249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 2, 'min_...</td>\n",
       "      <td>2004-01-01</td>\n",
       "      <td>0.139671</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.030418</td>\n",
       "      <td>0.056940</td>\n",
       "      <td>0.216216</td>\n",
       "      <td>0.030418</td>\n",
       "      <td>...</td>\n",
       "      <td>0.574468</td>\n",
       "      <td>0.821293</td>\n",
       "      <td>0.676056</td>\n",
       "      <td>0.406028</td>\n",
       "      <td>0.870722</td>\n",
       "      <td>0.553809</td>\n",
       "      <td>0.279490</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.436877</td>\n",
       "      <td>0.917399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 2, 'min_...</td>\n",
       "      <td>2004-01-01</td>\n",
       "      <td>0.139671</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.030418</td>\n",
       "      <td>0.056940</td>\n",
       "      <td>0.216216</td>\n",
       "      <td>0.030418</td>\n",
       "      <td>...</td>\n",
       "      <td>0.574468</td>\n",
       "      <td>0.821293</td>\n",
       "      <td>0.676056</td>\n",
       "      <td>0.406028</td>\n",
       "      <td>0.870722</td>\n",
       "      <td>0.553809</td>\n",
       "      <td>0.279490</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.436877</td>\n",
       "      <td>0.917399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 5, 'min_...</td>\n",
       "      <td>2004-01-01</td>\n",
       "      <td>0.139671</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.068441</td>\n",
       "      <td>0.128114</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.140684</td>\n",
       "      <td>...</td>\n",
       "      <td>0.574468</td>\n",
       "      <td>0.821293</td>\n",
       "      <td>0.676056</td>\n",
       "      <td>0.404255</td>\n",
       "      <td>0.866920</td>\n",
       "      <td>0.551391</td>\n",
       "      <td>0.279490</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.436877</td>\n",
       "      <td>0.898019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 5, 'min_...</td>\n",
       "      <td>2004-01-01</td>\n",
       "      <td>0.139671</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.068441</td>\n",
       "      <td>0.128114</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.140684</td>\n",
       "      <td>...</td>\n",
       "      <td>0.574468</td>\n",
       "      <td>0.821293</td>\n",
       "      <td>0.676056</td>\n",
       "      <td>0.404255</td>\n",
       "      <td>0.866920</td>\n",
       "      <td>0.551391</td>\n",
       "      <td>0.279490</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.436877</td>\n",
       "      <td>0.898019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 10, 'min...</td>\n",
       "      <td>2004-01-01</td>\n",
       "      <td>0.139671</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.003802</td>\n",
       "      <td>0.007117</td>\n",
       "      <td>0.054054</td>\n",
       "      <td>0.007605</td>\n",
       "      <td>...</td>\n",
       "      <td>0.534574</td>\n",
       "      <td>0.764259</td>\n",
       "      <td>0.629108</td>\n",
       "      <td>0.356383</td>\n",
       "      <td>0.764259</td>\n",
       "      <td>0.486094</td>\n",
       "      <td>0.279490</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.436877</td>\n",
       "      <td>0.832923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 10, 'min...</td>\n",
       "      <td>2004-01-01</td>\n",
       "      <td>0.139671</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.019011</td>\n",
       "      <td>0.035587</td>\n",
       "      <td>0.189189</td>\n",
       "      <td>0.026616</td>\n",
       "      <td>...</td>\n",
       "      <td>0.547872</td>\n",
       "      <td>0.783270</td>\n",
       "      <td>0.644757</td>\n",
       "      <td>0.370567</td>\n",
       "      <td>0.794677</td>\n",
       "      <td>0.505441</td>\n",
       "      <td>0.279490</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.436877</td>\n",
       "      <td>0.855848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 50, 'min...</td>\n",
       "      <td>2004-01-01</td>\n",
       "      <td>0.139671</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.003802</td>\n",
       "      <td>0.007117</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>0.003802</td>\n",
       "      <td>...</td>\n",
       "      <td>0.526596</td>\n",
       "      <td>0.752852</td>\n",
       "      <td>0.619718</td>\n",
       "      <td>0.351064</td>\n",
       "      <td>0.752852</td>\n",
       "      <td>0.478839</td>\n",
       "      <td>0.279490</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.436877</td>\n",
       "      <td>0.833216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 50, 'min...</td>\n",
       "      <td>2004-01-01</td>\n",
       "      <td>0.139671</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.003802</td>\n",
       "      <td>0.007117</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>0.003802</td>\n",
       "      <td>...</td>\n",
       "      <td>0.507979</td>\n",
       "      <td>0.726236</td>\n",
       "      <td>0.597809</td>\n",
       "      <td>0.354610</td>\n",
       "      <td>0.760456</td>\n",
       "      <td>0.483676</td>\n",
       "      <td>0.279490</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.436877</td>\n",
       "      <td>0.827743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 100, 'mi...</td>\n",
       "      <td>2004-01-01</td>\n",
       "      <td>0.139671</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.003802</td>\n",
       "      <td>0.007117</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>0.003802</td>\n",
       "      <td>...</td>\n",
       "      <td>0.526596</td>\n",
       "      <td>0.752852</td>\n",
       "      <td>0.619718</td>\n",
       "      <td>0.351064</td>\n",
       "      <td>0.752852</td>\n",
       "      <td>0.478839</td>\n",
       "      <td>0.279490</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.436877</td>\n",
       "      <td>0.833216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 100, 'mi...</td>\n",
       "      <td>2004-01-01</td>\n",
       "      <td>0.139671</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.003802</td>\n",
       "      <td>0.007117</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>0.003802</td>\n",
       "      <td>...</td>\n",
       "      <td>0.507979</td>\n",
       "      <td>0.726236</td>\n",
       "      <td>0.597809</td>\n",
       "      <td>0.354610</td>\n",
       "      <td>0.760456</td>\n",
       "      <td>0.483676</td>\n",
       "      <td>0.279490</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.436877</td>\n",
       "      <td>0.827743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 'sqrt', 'min_...</td>\n",
       "      <td>2004-01-01</td>\n",
       "      <td>0.139671</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.068441</td>\n",
       "      <td>0.128114</td>\n",
       "      <td>0.972973</td>\n",
       "      <td>0.136882</td>\n",
       "      <td>...</td>\n",
       "      <td>0.587766</td>\n",
       "      <td>0.840304</td>\n",
       "      <td>0.691706</td>\n",
       "      <td>0.429078</td>\n",
       "      <td>0.920152</td>\n",
       "      <td>0.585248</td>\n",
       "      <td>0.273114</td>\n",
       "      <td>0.977186</td>\n",
       "      <td>0.426910</td>\n",
       "      <td>0.943213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 'sqrt', 'min_...</td>\n",
       "      <td>2004-01-01</td>\n",
       "      <td>0.139671</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.068441</td>\n",
       "      <td>0.128114</td>\n",
       "      <td>0.972973</td>\n",
       "      <td>0.136882</td>\n",
       "      <td>...</td>\n",
       "      <td>0.590426</td>\n",
       "      <td>0.844106</td>\n",
       "      <td>0.694836</td>\n",
       "      <td>0.430851</td>\n",
       "      <td>0.923954</td>\n",
       "      <td>0.587666</td>\n",
       "      <td>0.273114</td>\n",
       "      <td>0.977186</td>\n",
       "      <td>0.426910</td>\n",
       "      <td>0.942787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>960</th>\n",
       "      <td>KNN</td>\n",
       "      <td>KNeighborsClassifier(algorithm='ball_tree', le...</td>\n",
       "      <td>{'algorithm': 'ball_tree', 'n_neighbors': 50, ...</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>0.146552</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.110294</td>\n",
       "      <td>0.794118</td>\n",
       "      <td>0.105882</td>\n",
       "      <td>...</td>\n",
       "      <td>0.347701</td>\n",
       "      <td>0.474510</td>\n",
       "      <td>0.401327</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.568627</td>\n",
       "      <td>0.373230</td>\n",
       "      <td>0.219540</td>\n",
       "      <td>0.749020</td>\n",
       "      <td>0.339556</td>\n",
       "      <td>0.723173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>961</th>\n",
       "      <td>KNN</td>\n",
       "      <td>KNeighborsClassifier(algorithm='ball_tree', le...</td>\n",
       "      <td>{'algorithm': 'ball_tree', 'n_neighbors': 100,...</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>0.146552</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.110294</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.101961</td>\n",
       "      <td>...</td>\n",
       "      <td>0.350575</td>\n",
       "      <td>0.478431</td>\n",
       "      <td>0.404643</td>\n",
       "      <td>0.281609</td>\n",
       "      <td>0.576471</td>\n",
       "      <td>0.378378</td>\n",
       "      <td>0.217241</td>\n",
       "      <td>0.741176</td>\n",
       "      <td>0.336000</td>\n",
       "      <td>0.719687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>962</th>\n",
       "      <td>KNN</td>\n",
       "      <td>KNeighborsClassifier(algorithm='ball_tree', le...</td>\n",
       "      <td>{'algorithm': 'ball_tree', 'n_neighbors': 100,...</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>0.146552</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.110294</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.101961</td>\n",
       "      <td>...</td>\n",
       "      <td>0.353448</td>\n",
       "      <td>0.482353</td>\n",
       "      <td>0.407960</td>\n",
       "      <td>0.291188</td>\n",
       "      <td>0.596078</td>\n",
       "      <td>0.391248</td>\n",
       "      <td>0.217241</td>\n",
       "      <td>0.741176</td>\n",
       "      <td>0.336000</td>\n",
       "      <td>0.722970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>963</th>\n",
       "      <td>NB</td>\n",
       "      <td>GaussianNB(priors=None, var_smoothing=1e-09)</td>\n",
       "      <td>{}</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>0.146552</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.794118</td>\n",
       "      <td>0.105882</td>\n",
       "      <td>...</td>\n",
       "      <td>0.534483</td>\n",
       "      <td>0.729412</td>\n",
       "      <td>0.616915</td>\n",
       "      <td>0.409962</td>\n",
       "      <td>0.839216</td>\n",
       "      <td>0.550837</td>\n",
       "      <td>0.272414</td>\n",
       "      <td>0.929412</td>\n",
       "      <td>0.421333</td>\n",
       "      <td>0.902033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>964</th>\n",
       "      <td>BA</td>\n",
       "      <td>(KNeighborsClassifier(algorithm='auto', leaf_s...</td>\n",
       "      <td>{'n_estimators': 10}</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>0.146552</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.035294</td>\n",
       "      <td>0.066176</td>\n",
       "      <td>0.676471</td>\n",
       "      <td>0.090196</td>\n",
       "      <td>...</td>\n",
       "      <td>0.316092</td>\n",
       "      <td>0.431373</td>\n",
       "      <td>0.364842</td>\n",
       "      <td>0.279693</td>\n",
       "      <td>0.572549</td>\n",
       "      <td>0.375804</td>\n",
       "      <td>0.293103</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.453333</td>\n",
       "      <td>0.681541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>965</th>\n",
       "      <td>BA</td>\n",
       "      <td>(KNeighborsClassifier(algorithm='auto', leaf_s...</td>\n",
       "      <td>{'n_estimators': 100}</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>0.146552</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.110294</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.094118</td>\n",
       "      <td>...</td>\n",
       "      <td>0.330460</td>\n",
       "      <td>0.450980</td>\n",
       "      <td>0.381426</td>\n",
       "      <td>0.287356</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.386100</td>\n",
       "      <td>0.293103</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.453333</td>\n",
       "      <td>0.697448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>966</th>\n",
       "      <td>AB</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'algorithm': 'SAMME', 'n_estimators': 10}</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>0.146552</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.502874</td>\n",
       "      <td>0.686275</td>\n",
       "      <td>0.580431</td>\n",
       "      <td>0.450192</td>\n",
       "      <td>0.921569</td>\n",
       "      <td>0.604891</td>\n",
       "      <td>0.288506</td>\n",
       "      <td>0.984314</td>\n",
       "      <td>0.446222</td>\n",
       "      <td>0.939806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>967</th>\n",
       "      <td>AB</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'algorithm': 'SAMME', 'n_estimators': 100}</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>0.146552</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.603448</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.696517</td>\n",
       "      <td>0.454023</td>\n",
       "      <td>0.929412</td>\n",
       "      <td>0.610039</td>\n",
       "      <td>0.289655</td>\n",
       "      <td>0.988235</td>\n",
       "      <td>0.448000</td>\n",
       "      <td>0.950007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>968</th>\n",
       "      <td>AB</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'algorithm': 'SAMME.R', 'n_estimators': 10}</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>0.146552</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.911765</td>\n",
       "      <td>0.121569</td>\n",
       "      <td>...</td>\n",
       "      <td>0.580460</td>\n",
       "      <td>0.792157</td>\n",
       "      <td>0.669983</td>\n",
       "      <td>0.461686</td>\n",
       "      <td>0.945098</td>\n",
       "      <td>0.620335</td>\n",
       "      <td>0.289655</td>\n",
       "      <td>0.988235</td>\n",
       "      <td>0.448000</td>\n",
       "      <td>0.951052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>969</th>\n",
       "      <td>AB</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'algorithm': 'SAMME.R', 'n_estimators': 100}</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>0.146552</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.603448</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.696517</td>\n",
       "      <td>0.442529</td>\n",
       "      <td>0.905882</td>\n",
       "      <td>0.594595</td>\n",
       "      <td>0.283908</td>\n",
       "      <td>0.968627</td>\n",
       "      <td>0.439111</td>\n",
       "      <td>0.934299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>970</th>\n",
       "      <td>GB</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>{'learning_rate': 0.001, 'n_estimators': 10, '...</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>0.146552</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.970588</td>\n",
       "      <td>0.129412</td>\n",
       "      <td>...</td>\n",
       "      <td>0.617816</td>\n",
       "      <td>0.843137</td>\n",
       "      <td>0.713101</td>\n",
       "      <td>0.446360</td>\n",
       "      <td>0.913725</td>\n",
       "      <td>0.599743</td>\n",
       "      <td>0.290805</td>\n",
       "      <td>0.992157</td>\n",
       "      <td>0.449778</td>\n",
       "      <td>0.954604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971</th>\n",
       "      <td>GB</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>{'learning_rate': 0.001, 'n_estimators': 10, '...</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>0.146552</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.911765</td>\n",
       "      <td>0.121569</td>\n",
       "      <td>...</td>\n",
       "      <td>0.603448</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.696517</td>\n",
       "      <td>0.402299</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.540541</td>\n",
       "      <td>0.293103</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.453333</td>\n",
       "      <td>0.930850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>972</th>\n",
       "      <td>GB</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>{'learning_rate': 0.001, 'n_estimators': 100, ...</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>0.146552</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.617816</td>\n",
       "      <td>0.843137</td>\n",
       "      <td>0.713101</td>\n",
       "      <td>0.465517</td>\n",
       "      <td>0.952941</td>\n",
       "      <td>0.625483</td>\n",
       "      <td>0.293103</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.453333</td>\n",
       "      <td>0.960463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973</th>\n",
       "      <td>GB</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>{'learning_rate': 0.001, 'n_estimators': 100, ...</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>0.146552</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.911765</td>\n",
       "      <td>0.121569</td>\n",
       "      <td>...</td>\n",
       "      <td>0.603448</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.696517</td>\n",
       "      <td>0.423372</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.568855</td>\n",
       "      <td>0.293103</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.453333</td>\n",
       "      <td>0.941950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>974</th>\n",
       "      <td>GB</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>{'learning_rate': 0.1, 'n_estimators': 10, 'su...</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>0.146552</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.612069</td>\n",
       "      <td>0.835294</td>\n",
       "      <td>0.706468</td>\n",
       "      <td>0.448276</td>\n",
       "      <td>0.917647</td>\n",
       "      <td>0.602317</td>\n",
       "      <td>0.290805</td>\n",
       "      <td>0.992157</td>\n",
       "      <td>0.449778</td>\n",
       "      <td>0.951563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>975</th>\n",
       "      <td>GB</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>{'learning_rate': 0.1, 'n_estimators': 10, 'su...</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>0.146552</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.970588</td>\n",
       "      <td>0.129412</td>\n",
       "      <td>...</td>\n",
       "      <td>0.609195</td>\n",
       "      <td>0.831373</td>\n",
       "      <td>0.703151</td>\n",
       "      <td>0.457854</td>\n",
       "      <td>0.937255</td>\n",
       "      <td>0.615187</td>\n",
       "      <td>0.291954</td>\n",
       "      <td>0.996078</td>\n",
       "      <td>0.451556</td>\n",
       "      <td>0.955656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>976</th>\n",
       "      <td>GB</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>{'learning_rate': 0.1, 'n_estimators': 100, 's...</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>0.146552</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.970588</td>\n",
       "      <td>0.129412</td>\n",
       "      <td>...</td>\n",
       "      <td>0.594828</td>\n",
       "      <td>0.811765</td>\n",
       "      <td>0.686567</td>\n",
       "      <td>0.452107</td>\n",
       "      <td>0.925490</td>\n",
       "      <td>0.607465</td>\n",
       "      <td>0.289655</td>\n",
       "      <td>0.988235</td>\n",
       "      <td>0.448000</td>\n",
       "      <td>0.940630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>977</th>\n",
       "      <td>GB</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>{'learning_rate': 0.1, 'n_estimators': 100, 's...</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>0.146552</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.603448</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.696517</td>\n",
       "      <td>0.452107</td>\n",
       "      <td>0.925490</td>\n",
       "      <td>0.607465</td>\n",
       "      <td>0.291954</td>\n",
       "      <td>0.996078</td>\n",
       "      <td>0.451556</td>\n",
       "      <td>0.952982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>978</th>\n",
       "      <td>ET</td>\n",
       "      <td>(ExtraTreeClassifier(class_weight=None, criter...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 2, 'n_estim...</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>0.146552</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.560345</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.646766</td>\n",
       "      <td>0.438697</td>\n",
       "      <td>0.898039</td>\n",
       "      <td>0.589447</td>\n",
       "      <td>0.288506</td>\n",
       "      <td>0.984314</td>\n",
       "      <td>0.446222</td>\n",
       "      <td>0.934054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>979</th>\n",
       "      <td>ET</td>\n",
       "      <td>(ExtraTreeClassifier(class_weight=None, criter...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 2, 'n_estim...</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>0.146552</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.571839</td>\n",
       "      <td>0.780392</td>\n",
       "      <td>0.660033</td>\n",
       "      <td>0.440613</td>\n",
       "      <td>0.901961</td>\n",
       "      <td>0.592021</td>\n",
       "      <td>0.287356</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.935496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>980</th>\n",
       "      <td>ET</td>\n",
       "      <td>(ExtraTreeClassifier(class_weight=None, criter...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'n_estim...</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>0.146552</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.580460</td>\n",
       "      <td>0.792157</td>\n",
       "      <td>0.669983</td>\n",
       "      <td>0.436782</td>\n",
       "      <td>0.894118</td>\n",
       "      <td>0.586873</td>\n",
       "      <td>0.289655</td>\n",
       "      <td>0.988235</td>\n",
       "      <td>0.448000</td>\n",
       "      <td>0.939774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981</th>\n",
       "      <td>ET</td>\n",
       "      <td>(ExtraTreeClassifier(class_weight=None, criter...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'n_estim...</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>0.146552</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.796078</td>\n",
       "      <td>0.673300</td>\n",
       "      <td>0.442529</td>\n",
       "      <td>0.905882</td>\n",
       "      <td>0.594595</td>\n",
       "      <td>0.288506</td>\n",
       "      <td>0.984314</td>\n",
       "      <td>0.446222</td>\n",
       "      <td>0.939589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>ET</td>\n",
       "      <td>(ExtraTreeClassifier(class_weight=None, criter...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 50, 'n_esti...</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>0.146552</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.594828</td>\n",
       "      <td>0.811765</td>\n",
       "      <td>0.686567</td>\n",
       "      <td>0.446360</td>\n",
       "      <td>0.913725</td>\n",
       "      <td>0.599743</td>\n",
       "      <td>0.289655</td>\n",
       "      <td>0.988235</td>\n",
       "      <td>0.448000</td>\n",
       "      <td>0.943382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>ET</td>\n",
       "      <td>(ExtraTreeClassifier(class_weight=None, criter...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 50, 'n_esti...</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>0.146552</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.970588</td>\n",
       "      <td>0.129412</td>\n",
       "      <td>...</td>\n",
       "      <td>0.597701</td>\n",
       "      <td>0.815686</td>\n",
       "      <td>0.689884</td>\n",
       "      <td>0.448276</td>\n",
       "      <td>0.917647</td>\n",
       "      <td>0.602317</td>\n",
       "      <td>0.288506</td>\n",
       "      <td>0.984314</td>\n",
       "      <td>0.446222</td>\n",
       "      <td>0.947307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>ET</td>\n",
       "      <td>(ExtraTreeClassifier(class_weight=None, criter...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 2, 'n_es...</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>0.146552</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.571839</td>\n",
       "      <td>0.780392</td>\n",
       "      <td>0.660033</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.909804</td>\n",
       "      <td>0.597169</td>\n",
       "      <td>0.287356</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.934981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>ET</td>\n",
       "      <td>(ExtraTreeClassifier(class_weight=None, criter...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 2, 'n_es...</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>0.146552</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.571839</td>\n",
       "      <td>0.780392</td>\n",
       "      <td>0.660033</td>\n",
       "      <td>0.438697</td>\n",
       "      <td>0.898039</td>\n",
       "      <td>0.589447</td>\n",
       "      <td>0.286207</td>\n",
       "      <td>0.976471</td>\n",
       "      <td>0.442667</td>\n",
       "      <td>0.934538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>ET</td>\n",
       "      <td>(ExtraTreeClassifier(class_weight=None, criter...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 5, 'n_es...</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>0.146552</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.580460</td>\n",
       "      <td>0.792157</td>\n",
       "      <td>0.669983</td>\n",
       "      <td>0.442529</td>\n",
       "      <td>0.905882</td>\n",
       "      <td>0.594595</td>\n",
       "      <td>0.288506</td>\n",
       "      <td>0.984314</td>\n",
       "      <td>0.446222</td>\n",
       "      <td>0.939040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>ET</td>\n",
       "      <td>(ExtraTreeClassifier(class_weight=None, criter...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 5, 'n_es...</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>0.146552</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.580460</td>\n",
       "      <td>0.792157</td>\n",
       "      <td>0.669983</td>\n",
       "      <td>0.442529</td>\n",
       "      <td>0.905882</td>\n",
       "      <td>0.594595</td>\n",
       "      <td>0.287356</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.938892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>ET</td>\n",
       "      <td>(ExtraTreeClassifier(class_weight=None, criter...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 50, 'n_e...</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>0.146552</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.125490</td>\n",
       "      <td>...</td>\n",
       "      <td>0.603448</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.696517</td>\n",
       "      <td>0.455939</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.612613</td>\n",
       "      <td>0.287356</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.944054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>ET</td>\n",
       "      <td>(ExtraTreeClassifier(class_weight=None, criter...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 50, 'n_e...</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>0.146552</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.062745</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.970588</td>\n",
       "      <td>0.129412</td>\n",
       "      <td>...</td>\n",
       "      <td>0.606322</td>\n",
       "      <td>0.827451</td>\n",
       "      <td>0.699834</td>\n",
       "      <td>0.452107</td>\n",
       "      <td>0.925490</td>\n",
       "      <td>0.607465</td>\n",
       "      <td>0.288506</td>\n",
       "      <td>0.984314</td>\n",
       "      <td>0.446222</td>\n",
       "      <td>0.946935</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>990 rows  27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    model_name                                              model  \\\n",
       "0           LR  LogisticRegression(C=10, class_weight=None, du...   \n",
       "1           LR  LogisticRegression(C=10, class_weight=None, du...   \n",
       "2           LR  LogisticRegression(C=10, class_weight=None, du...   \n",
       "3           LR  LogisticRegression(C=10, class_weight=None, du...   \n",
       "4           LR  LogisticRegression(C=10, class_weight=None, du...   \n",
       "5           LR  LogisticRegression(C=10, class_weight=None, du...   \n",
       "6           LR  LogisticRegression(C=10, class_weight=None, du...   \n",
       "7           LR  LogisticRegression(C=10, class_weight=None, du...   \n",
       "8           DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "9           DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "10          DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "11          DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "12          DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "13          DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "14          DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "15          DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "16          DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "17          DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "18          DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "19          DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "20          DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "21          DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "22          DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "23          DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "24          DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "25          DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "26          DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "27          DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "28          RF  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "29          RF  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "..         ...                                                ...   \n",
       "960        KNN  KNeighborsClassifier(algorithm='ball_tree', le...   \n",
       "961        KNN  KNeighborsClassifier(algorithm='ball_tree', le...   \n",
       "962        KNN  KNeighborsClassifier(algorithm='ball_tree', le...   \n",
       "963         NB       GaussianNB(priors=None, var_smoothing=1e-09)   \n",
       "964         BA  (KNeighborsClassifier(algorithm='auto', leaf_s...   \n",
       "965         BA  (KNeighborsClassifier(algorithm='auto', leaf_s...   \n",
       "966         AB  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "967         AB  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "968         AB  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "969         AB  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "970         GB  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "971         GB  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "972         GB  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "973         GB  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "974         GB  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "975         GB  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "976         GB  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "977         GB  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "978         ET  (ExtraTreeClassifier(class_weight=None, criter...   \n",
       "979         ET  (ExtraTreeClassifier(class_weight=None, criter...   \n",
       "980         ET  (ExtraTreeClassifier(class_weight=None, criter...   \n",
       "981         ET  (ExtraTreeClassifier(class_weight=None, criter...   \n",
       "982         ET  (ExtraTreeClassifier(class_weight=None, criter...   \n",
       "983         ET  (ExtraTreeClassifier(class_weight=None, criter...   \n",
       "984         ET  (ExtraTreeClassifier(class_weight=None, criter...   \n",
       "985         ET  (ExtraTreeClassifier(class_weight=None, criter...   \n",
       "986         ET  (ExtraTreeClassifier(class_weight=None, criter...   \n",
       "987         ET  (ExtraTreeClassifier(class_weight=None, criter...   \n",
       "988         ET  (ExtraTreeClassifier(class_weight=None, criter...   \n",
       "989         ET  (ExtraTreeClassifier(class_weight=None, criter...   \n",
       "\n",
       "                                            parameters test_set_start_date  \\\n",
       "0                        {'C': 0.001, 'penalty': 'l1'}          2004-01-01   \n",
       "1                        {'C': 0.001, 'penalty': 'l2'}          2004-01-01   \n",
       "2                          {'C': 0.1, 'penalty': 'l1'}          2004-01-01   \n",
       "3                          {'C': 0.1, 'penalty': 'l2'}          2004-01-01   \n",
       "4                            {'C': 1, 'penalty': 'l1'}          2004-01-01   \n",
       "5                            {'C': 1, 'penalty': 'l2'}          2004-01-01   \n",
       "6                           {'C': 10, 'penalty': 'l1'}          2004-01-01   \n",
       "7                           {'C': 10, 'penalty': 'l2'}          2004-01-01   \n",
       "8    {'criterion': 'gini', 'max_depth': 2, 'min_sam...          2004-01-01   \n",
       "9    {'criterion': 'gini', 'max_depth': 2, 'min_sam...          2004-01-01   \n",
       "10   {'criterion': 'gini', 'max_depth': 5, 'min_sam...          2004-01-01   \n",
       "11   {'criterion': 'gini', 'max_depth': 5, 'min_sam...          2004-01-01   \n",
       "12   {'criterion': 'gini', 'max_depth': 10, 'min_sa...          2004-01-01   \n",
       "13   {'criterion': 'gini', 'max_depth': 10, 'min_sa...          2004-01-01   \n",
       "14   {'criterion': 'gini', 'max_depth': 50, 'min_sa...          2004-01-01   \n",
       "15   {'criterion': 'gini', 'max_depth': 50, 'min_sa...          2004-01-01   \n",
       "16   {'criterion': 'gini', 'max_depth': 100, 'min_s...          2004-01-01   \n",
       "17   {'criterion': 'gini', 'max_depth': 100, 'min_s...          2004-01-01   \n",
       "18   {'criterion': 'entropy', 'max_depth': 2, 'min_...          2004-01-01   \n",
       "19   {'criterion': 'entropy', 'max_depth': 2, 'min_...          2004-01-01   \n",
       "20   {'criterion': 'entropy', 'max_depth': 5, 'min_...          2004-01-01   \n",
       "21   {'criterion': 'entropy', 'max_depth': 5, 'min_...          2004-01-01   \n",
       "22   {'criterion': 'entropy', 'max_depth': 10, 'min...          2004-01-01   \n",
       "23   {'criterion': 'entropy', 'max_depth': 10, 'min...          2004-01-01   \n",
       "24   {'criterion': 'entropy', 'max_depth': 50, 'min...          2004-01-01   \n",
       "25   {'criterion': 'entropy', 'max_depth': 50, 'min...          2004-01-01   \n",
       "26   {'criterion': 'entropy', 'max_depth': 100, 'mi...          2004-01-01   \n",
       "27   {'criterion': 'entropy', 'max_depth': 100, 'mi...          2004-01-01   \n",
       "28   {'max_depth': 5, 'max_features': 'sqrt', 'min_...          2004-01-01   \n",
       "29   {'max_depth': 5, 'max_features': 'sqrt', 'min_...          2004-01-01   \n",
       "..                                                 ...                 ...   \n",
       "960  {'algorithm': 'ball_tree', 'n_neighbors': 50, ...          2013-01-01   \n",
       "961  {'algorithm': 'ball_tree', 'n_neighbors': 100,...          2013-01-01   \n",
       "962  {'algorithm': 'ball_tree', 'n_neighbors': 100,...          2013-01-01   \n",
       "963                                                 {}          2013-01-01   \n",
       "964                               {'n_estimators': 10}          2013-01-01   \n",
       "965                              {'n_estimators': 100}          2013-01-01   \n",
       "966         {'algorithm': 'SAMME', 'n_estimators': 10}          2013-01-01   \n",
       "967        {'algorithm': 'SAMME', 'n_estimators': 100}          2013-01-01   \n",
       "968       {'algorithm': 'SAMME.R', 'n_estimators': 10}          2013-01-01   \n",
       "969      {'algorithm': 'SAMME.R', 'n_estimators': 100}          2013-01-01   \n",
       "970  {'learning_rate': 0.001, 'n_estimators': 10, '...          2013-01-01   \n",
       "971  {'learning_rate': 0.001, 'n_estimators': 10, '...          2013-01-01   \n",
       "972  {'learning_rate': 0.001, 'n_estimators': 100, ...          2013-01-01   \n",
       "973  {'learning_rate': 0.001, 'n_estimators': 100, ...          2013-01-01   \n",
       "974  {'learning_rate': 0.1, 'n_estimators': 10, 'su...          2013-01-01   \n",
       "975  {'learning_rate': 0.1, 'n_estimators': 10, 'su...          2013-01-01   \n",
       "976  {'learning_rate': 0.1, 'n_estimators': 100, 's...          2013-01-01   \n",
       "977  {'learning_rate': 0.1, 'n_estimators': 100, 's...          2013-01-01   \n",
       "978  {'criterion': 'gini', 'max_depth': 2, 'n_estim...          2013-01-01   \n",
       "979  {'criterion': 'gini', 'max_depth': 2, 'n_estim...          2013-01-01   \n",
       "980  {'criterion': 'gini', 'max_depth': 5, 'n_estim...          2013-01-01   \n",
       "981  {'criterion': 'gini', 'max_depth': 5, 'n_estim...          2013-01-01   \n",
       "982  {'criterion': 'gini', 'max_depth': 50, 'n_esti...          2013-01-01   \n",
       "983  {'criterion': 'gini', 'max_depth': 50, 'n_esti...          2013-01-01   \n",
       "984  {'criterion': 'entropy', 'max_depth': 2, 'n_es...          2013-01-01   \n",
       "985  {'criterion': 'entropy', 'max_depth': 2, 'n_es...          2013-01-01   \n",
       "986  {'criterion': 'entropy', 'max_depth': 5, 'n_es...          2013-01-01   \n",
       "987  {'criterion': 'entropy', 'max_depth': 5, 'n_es...          2013-01-01   \n",
       "988  {'criterion': 'entropy', 'max_depth': 50, 'n_e...          2013-01-01   \n",
       "989  {'criterion': 'entropy', 'max_depth': 50, 'n_e...          2013-01-01   \n",
       "\n",
       "     baseline    p_at_1    r_at_1   f1_at_1    p_at_2    r_at_2  ...  \\\n",
       "0    0.139671  1.000000  0.068441  0.128114  1.000000  0.140684  ...   \n",
       "1    0.139671  1.000000  0.068441  0.128114  0.972973  0.136882  ...   \n",
       "2    0.139671  0.777778  0.053232  0.099644  0.783784  0.110266  ...   \n",
       "3    0.139671  1.000000  0.068441  0.128114  0.972973  0.136882  ...   \n",
       "4    0.139671  0.833333  0.057034  0.106762  0.567568  0.079848  ...   \n",
       "5    0.139671  1.000000  0.068441  0.128114  0.972973  0.136882  ...   \n",
       "6    0.139671  0.833333  0.057034  0.106762  0.513514  0.072243  ...   \n",
       "7    0.139671  1.000000  0.068441  0.128114  1.000000  0.140684  ...   \n",
       "8    0.139671  1.000000  0.068441  0.128114  1.000000  0.140684  ...   \n",
       "9    0.139671  1.000000  0.068441  0.128114  1.000000  0.140684  ...   \n",
       "10   0.139671  0.444444  0.030418  0.056940  0.729730  0.102662  ...   \n",
       "11   0.139671  0.500000  0.034221  0.064057  0.756757  0.106464  ...   \n",
       "12   0.139671  0.055556  0.003802  0.007117  0.027027  0.003802  ...   \n",
       "13   0.139671  0.055556  0.003802  0.007117  0.027027  0.003802  ...   \n",
       "14   0.139671  0.055556  0.003802  0.007117  0.027027  0.003802  ...   \n",
       "15   0.139671  0.055556  0.003802  0.007117  0.027027  0.003802  ...   \n",
       "16   0.139671  0.055556  0.003802  0.007117  0.027027  0.003802  ...   \n",
       "17   0.139671  0.055556  0.003802  0.007117  0.027027  0.003802  ...   \n",
       "18   0.139671  0.444444  0.030418  0.056940  0.216216  0.030418  ...   \n",
       "19   0.139671  0.444444  0.030418  0.056940  0.216216  0.030418  ...   \n",
       "20   0.139671  1.000000  0.068441  0.128114  1.000000  0.140684  ...   \n",
       "21   0.139671  1.000000  0.068441  0.128114  1.000000  0.140684  ...   \n",
       "22   0.139671  0.055556  0.003802  0.007117  0.054054  0.007605  ...   \n",
       "23   0.139671  0.277778  0.019011  0.035587  0.189189  0.026616  ...   \n",
       "24   0.139671  0.055556  0.003802  0.007117  0.027027  0.003802  ...   \n",
       "25   0.139671  0.055556  0.003802  0.007117  0.027027  0.003802  ...   \n",
       "26   0.139671  0.055556  0.003802  0.007117  0.027027  0.003802  ...   \n",
       "27   0.139671  0.055556  0.003802  0.007117  0.027027  0.003802  ...   \n",
       "28   0.139671  1.000000  0.068441  0.128114  0.972973  0.136882  ...   \n",
       "29   0.139671  1.000000  0.068441  0.128114  0.972973  0.136882  ...   \n",
       "..        ...       ...       ...       ...       ...       ...  ...   \n",
       "960  0.146552  0.882353  0.058824  0.110294  0.794118  0.105882  ...   \n",
       "961  0.146552  0.882353  0.058824  0.110294  0.764706  0.101961  ...   \n",
       "962  0.146552  0.882353  0.058824  0.110294  0.764706  0.101961  ...   \n",
       "963  0.146552  1.000000  0.066667  0.125000  0.794118  0.105882  ...   \n",
       "964  0.146552  0.529412  0.035294  0.066176  0.676471  0.090196  ...   \n",
       "965  0.146552  0.882353  0.058824  0.110294  0.705882  0.094118  ...   \n",
       "966  0.146552  1.000000  0.066667  0.125000  1.000000  0.133333  ...   \n",
       "967  0.146552  1.000000  0.066667  0.125000  1.000000  0.133333  ...   \n",
       "968  0.146552  1.000000  0.066667  0.125000  0.911765  0.121569  ...   \n",
       "969  0.146552  1.000000  0.066667  0.125000  1.000000  0.133333  ...   \n",
       "970  0.146552  1.000000  0.066667  0.125000  0.970588  0.129412  ...   \n",
       "971  0.146552  1.000000  0.066667  0.125000  0.911765  0.121569  ...   \n",
       "972  0.146552  1.000000  0.066667  0.125000  1.000000  0.133333  ...   \n",
       "973  0.146552  1.000000  0.066667  0.125000  0.911765  0.121569  ...   \n",
       "974  0.146552  1.000000  0.066667  0.125000  1.000000  0.133333  ...   \n",
       "975  0.146552  1.000000  0.066667  0.125000  0.970588  0.129412  ...   \n",
       "976  0.146552  1.000000  0.066667  0.125000  0.970588  0.129412  ...   \n",
       "977  0.146552  1.000000  0.066667  0.125000  1.000000  0.133333  ...   \n",
       "978  0.146552  1.000000  0.066667  0.125000  1.000000  0.133333  ...   \n",
       "979  0.146552  1.000000  0.066667  0.125000  1.000000  0.133333  ...   \n",
       "980  0.146552  1.000000  0.066667  0.125000  1.000000  0.133333  ...   \n",
       "981  0.146552  1.000000  0.066667  0.125000  1.000000  0.133333  ...   \n",
       "982  0.146552  1.000000  0.066667  0.125000  1.000000  0.133333  ...   \n",
       "983  0.146552  1.000000  0.066667  0.125000  0.970588  0.129412  ...   \n",
       "984  0.146552  1.000000  0.066667  0.125000  1.000000  0.133333  ...   \n",
       "985  0.146552  1.000000  0.066667  0.125000  1.000000  0.133333  ...   \n",
       "986  0.146552  1.000000  0.066667  0.125000  1.000000  0.133333  ...   \n",
       "987  0.146552  1.000000  0.066667  0.125000  1.000000  0.133333  ...   \n",
       "988  0.146552  1.000000  0.066667  0.125000  0.941176  0.125490  ...   \n",
       "989  0.146552  0.941176  0.062745  0.117647  0.970588  0.129412  ...   \n",
       "\n",
       "      p_at_20   r_at_20  f1_at_20   p_at_30   r_at_30  f1_at_30   p_at_50  \\\n",
       "0    0.574468  0.821293  0.676056  0.423759  0.908745  0.577993  0.274176   \n",
       "1    0.593085  0.847909  0.697966  0.439716  0.942966  0.599758  0.277365   \n",
       "2    0.555851  0.794677  0.654147  0.425532  0.912548  0.580411  0.272051   \n",
       "3    0.590426  0.844106  0.694836  0.439716  0.942966  0.599758  0.277365   \n",
       "4    0.563830  0.806084  0.663537  0.423759  0.908745  0.577993  0.269926   \n",
       "5    0.614362  0.878327  0.723005  0.439716  0.942966  0.599758  0.276302   \n",
       "6    0.555851  0.794677  0.654147  0.425532  0.912548  0.580411  0.268863   \n",
       "7    0.601064  0.859316  0.707355  0.443262  0.950570  0.604595  0.277365   \n",
       "8    0.523936  0.749049  0.616588  0.349291  0.749049  0.476421  0.279490   \n",
       "9    0.523936  0.749049  0.616588  0.349291  0.749049  0.476421  0.279490   \n",
       "10   0.526596  0.752852  0.619718  0.402482  0.863118  0.548972  0.264612   \n",
       "11   0.523936  0.749049  0.616588  0.406028  0.870722  0.553809  0.266738   \n",
       "12   0.476064  0.680608  0.560250  0.358156  0.768061  0.488513  0.279490   \n",
       "13   0.500000  0.714829  0.588419  0.372340  0.798479  0.507860  0.279490   \n",
       "14   0.438830  0.627376  0.516432  0.365248  0.783270  0.498186  0.279490   \n",
       "15   0.500000  0.714829  0.588419  0.379433  0.813688  0.517533  0.279490   \n",
       "16   0.438830  0.627376  0.516432  0.365248  0.783270  0.498186  0.279490   \n",
       "17   0.500000  0.714829  0.588419  0.379433  0.813688  0.517533  0.279490   \n",
       "18   0.574468  0.821293  0.676056  0.406028  0.870722  0.553809  0.279490   \n",
       "19   0.574468  0.821293  0.676056  0.406028  0.870722  0.553809  0.279490   \n",
       "20   0.574468  0.821293  0.676056  0.404255  0.866920  0.551391  0.279490   \n",
       "21   0.574468  0.821293  0.676056  0.404255  0.866920  0.551391  0.279490   \n",
       "22   0.534574  0.764259  0.629108  0.356383  0.764259  0.486094  0.279490   \n",
       "23   0.547872  0.783270  0.644757  0.370567  0.794677  0.505441  0.279490   \n",
       "24   0.526596  0.752852  0.619718  0.351064  0.752852  0.478839  0.279490   \n",
       "25   0.507979  0.726236  0.597809  0.354610  0.760456  0.483676  0.279490   \n",
       "26   0.526596  0.752852  0.619718  0.351064  0.752852  0.478839  0.279490   \n",
       "27   0.507979  0.726236  0.597809  0.354610  0.760456  0.483676  0.279490   \n",
       "28   0.587766  0.840304  0.691706  0.429078  0.920152  0.585248  0.273114   \n",
       "29   0.590426  0.844106  0.694836  0.430851  0.923954  0.587666  0.273114   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "960  0.347701  0.474510  0.401327  0.277778  0.568627  0.373230  0.219540   \n",
       "961  0.350575  0.478431  0.404643  0.281609  0.576471  0.378378  0.217241   \n",
       "962  0.353448  0.482353  0.407960  0.291188  0.596078  0.391248  0.217241   \n",
       "963  0.534483  0.729412  0.616915  0.409962  0.839216  0.550837  0.272414   \n",
       "964  0.316092  0.431373  0.364842  0.279693  0.572549  0.375804  0.293103   \n",
       "965  0.330460  0.450980  0.381426  0.287356  0.588235  0.386100  0.293103   \n",
       "966  0.502874  0.686275  0.580431  0.450192  0.921569  0.604891  0.288506   \n",
       "967  0.603448  0.823529  0.696517  0.454023  0.929412  0.610039  0.289655   \n",
       "968  0.580460  0.792157  0.669983  0.461686  0.945098  0.620335  0.289655   \n",
       "969  0.603448  0.823529  0.696517  0.442529  0.905882  0.594595  0.283908   \n",
       "970  0.617816  0.843137  0.713101  0.446360  0.913725  0.599743  0.290805   \n",
       "971  0.603448  0.823529  0.696517  0.402299  0.823529  0.540541  0.293103   \n",
       "972  0.617816  0.843137  0.713101  0.465517  0.952941  0.625483  0.293103   \n",
       "973  0.603448  0.823529  0.696517  0.423372  0.866667  0.568855  0.293103   \n",
       "974  0.612069  0.835294  0.706468  0.448276  0.917647  0.602317  0.290805   \n",
       "975  0.609195  0.831373  0.703151  0.457854  0.937255  0.615187  0.291954   \n",
       "976  0.594828  0.811765  0.686567  0.452107  0.925490  0.607465  0.289655   \n",
       "977  0.603448  0.823529  0.696517  0.452107  0.925490  0.607465  0.291954   \n",
       "978  0.560345  0.764706  0.646766  0.438697  0.898039  0.589447  0.288506   \n",
       "979  0.571839  0.780392  0.660033  0.440613  0.901961  0.592021  0.287356   \n",
       "980  0.580460  0.792157  0.669983  0.436782  0.894118  0.586873  0.289655   \n",
       "981  0.583333  0.796078  0.673300  0.442529  0.905882  0.594595  0.288506   \n",
       "982  0.594828  0.811765  0.686567  0.446360  0.913725  0.599743  0.289655   \n",
       "983  0.597701  0.815686  0.689884  0.448276  0.917647  0.602317  0.288506   \n",
       "984  0.571839  0.780392  0.660033  0.444444  0.909804  0.597169  0.287356   \n",
       "985  0.571839  0.780392  0.660033  0.438697  0.898039  0.589447  0.286207   \n",
       "986  0.580460  0.792157  0.669983  0.442529  0.905882  0.594595  0.288506   \n",
       "987  0.580460  0.792157  0.669983  0.442529  0.905882  0.594595  0.287356   \n",
       "988  0.603448  0.823529  0.696517  0.455939  0.933333  0.612613  0.287356   \n",
       "989  0.606322  0.827451  0.699834  0.452107  0.925490  0.607465  0.288506   \n",
       "\n",
       "      r_at_50  f1_at_50   auc-roc  \n",
       "0    0.980989  0.428571  0.940694  \n",
       "1    0.992395  0.433555  0.955272  \n",
       "2    0.973384  0.425249  0.927996  \n",
       "3    0.992395  0.433555  0.953185  \n",
       "4    0.965779  0.421927  0.918296  \n",
       "5    0.988593  0.431894  0.955891  \n",
       "6    0.961977  0.420266  0.912693  \n",
       "7    0.992395  0.433555  0.958478  \n",
       "8    1.000000  0.436877  0.912381  \n",
       "9    1.000000  0.436877  0.912381  \n",
       "10   0.946768  0.413621  0.903642  \n",
       "11   0.954373  0.416944  0.907642  \n",
       "12   1.000000  0.436877  0.821502  \n",
       "13   1.000000  0.436877  0.835716  \n",
       "14   1.000000  0.436877  0.826512  \n",
       "15   1.000000  0.436877  0.841249  \n",
       "16   1.000000  0.436877  0.826512  \n",
       "17   1.000000  0.436877  0.841249  \n",
       "18   1.000000  0.436877  0.917399  \n",
       "19   1.000000  0.436877  0.917399  \n",
       "20   1.000000  0.436877  0.898019  \n",
       "21   1.000000  0.436877  0.898019  \n",
       "22   1.000000  0.436877  0.832923  \n",
       "23   1.000000  0.436877  0.855848  \n",
       "24   1.000000  0.436877  0.833216  \n",
       "25   1.000000  0.436877  0.827743  \n",
       "26   1.000000  0.436877  0.833216  \n",
       "27   1.000000  0.436877  0.827743  \n",
       "28   0.977186  0.426910  0.943213  \n",
       "29   0.977186  0.426910  0.942787  \n",
       "..        ...       ...       ...  \n",
       "960  0.749020  0.339556  0.723173  \n",
       "961  0.741176  0.336000  0.719687  \n",
       "962  0.741176  0.336000  0.722970  \n",
       "963  0.929412  0.421333  0.902033  \n",
       "964  1.000000  0.453333  0.681541  \n",
       "965  1.000000  0.453333  0.697448  \n",
       "966  0.984314  0.446222  0.939806  \n",
       "967  0.988235  0.448000  0.950007  \n",
       "968  0.988235  0.448000  0.951052  \n",
       "969  0.968627  0.439111  0.934299  \n",
       "970  0.992157  0.449778  0.954604  \n",
       "971  1.000000  0.453333  0.930850  \n",
       "972  1.000000  0.453333  0.960463  \n",
       "973  1.000000  0.453333  0.941950  \n",
       "974  0.992157  0.449778  0.951563  \n",
       "975  0.996078  0.451556  0.955656  \n",
       "976  0.988235  0.448000  0.940630  \n",
       "977  0.996078  0.451556  0.952982  \n",
       "978  0.984314  0.446222  0.934054  \n",
       "979  0.980392  0.444444  0.935496  \n",
       "980  0.988235  0.448000  0.939774  \n",
       "981  0.984314  0.446222  0.939589  \n",
       "982  0.988235  0.448000  0.943382  \n",
       "983  0.984314  0.446222  0.947307  \n",
       "984  0.980392  0.444444  0.934981  \n",
       "985  0.976471  0.442667  0.934538  \n",
       "986  0.984314  0.446222  0.939040  \n",
       "987  0.980392  0.444444  0.938892  \n",
       "988  0.980392  0.444444  0.944054  \n",
       "989  0.984314  0.446222  0.946935  \n",
       "\n",
       "[990 rows x 27 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(pipeline)\n",
    "\n",
    "#Lets obtain the best model for each train/test set, for each metric\n",
    "metrics_to_display = ['p_at_5','p_at_10', 'auc-roc']\n",
    "\n",
    "best_models_per_metric = {}\n",
    "\n",
    "for metric in metrics_to_display:\n",
    "    #indices of rows that have max value in specific metric for each train/test set\n",
    "    idx = results.groupby(['test_set_start_date'])[metric].transform(max) == results[metric]\n",
    "\n",
    "    #save table of best models at the specific metric\n",
    "    best_models_per_metric[metric] = results[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best models for Precision at 5%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>parameters</th>\n",
       "      <th>test_set_start_date</th>\n",
       "      <th>baseline</th>\n",
       "      <th>p_at_5</th>\n",
       "      <th>r_at_5</th>\n",
       "      <th>f1_at_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LR</td>\n",
       "      <td>{'C': 10, 'penalty': 'l2'}</td>\n",
       "      <td>2004-01-01</td>\n",
       "      <td>0.139671</td>\n",
       "      <td>0.968085</td>\n",
       "      <td>0.346008</td>\n",
       "      <td>0.509804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>RF</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 'sqrt', 'min_...</td>\n",
       "      <td>2005-01-01</td>\n",
       "      <td>0.140202</td>\n",
       "      <td>0.968085</td>\n",
       "      <td>0.344697</td>\n",
       "      <td>0.508380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>RF</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 'sqrt', 'min_...</td>\n",
       "      <td>2005-01-01</td>\n",
       "      <td>0.140202</td>\n",
       "      <td>0.968085</td>\n",
       "      <td>0.344697</td>\n",
       "      <td>0.508380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>RF</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 'log2', 'min_...</td>\n",
       "      <td>2005-01-01</td>\n",
       "      <td>0.140202</td>\n",
       "      <td>0.968085</td>\n",
       "      <td>0.344697</td>\n",
       "      <td>0.508380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>RF</td>\n",
       "      <td>{'max_depth': 50, 'max_features': 'sqrt', 'min...</td>\n",
       "      <td>2005-01-01</td>\n",
       "      <td>0.140202</td>\n",
       "      <td>0.968085</td>\n",
       "      <td>0.344697</td>\n",
       "      <td>0.508380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>RF</td>\n",
       "      <td>{'max_depth': 50, 'max_features': 'sqrt', 'min...</td>\n",
       "      <td>2005-01-01</td>\n",
       "      <td>0.140202</td>\n",
       "      <td>0.968085</td>\n",
       "      <td>0.344697</td>\n",
       "      <td>0.508380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>RF</td>\n",
       "      <td>{'max_depth': 50, 'max_features': 'log2', 'min...</td>\n",
       "      <td>2005-01-01</td>\n",
       "      <td>0.140202</td>\n",
       "      <td>0.968085</td>\n",
       "      <td>0.344697</td>\n",
       "      <td>0.508380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>RF</td>\n",
       "      <td>{'max_depth': 100, 'max_features': 'sqrt', 'mi...</td>\n",
       "      <td>2005-01-01</td>\n",
       "      <td>0.140202</td>\n",
       "      <td>0.968085</td>\n",
       "      <td>0.344697</td>\n",
       "      <td>0.508380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>RF</td>\n",
       "      <td>{'max_depth': 100, 'max_features': 'sqrt', 'mi...</td>\n",
       "      <td>2005-01-01</td>\n",
       "      <td>0.140202</td>\n",
       "      <td>0.968085</td>\n",
       "      <td>0.344697</td>\n",
       "      <td>0.508380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>RF</td>\n",
       "      <td>{'max_depth': 100, 'max_features': 'log2', 'mi...</td>\n",
       "      <td>2005-01-01</td>\n",
       "      <td>0.140202</td>\n",
       "      <td>0.968085</td>\n",
       "      <td>0.344697</td>\n",
       "      <td>0.508380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>GB</td>\n",
       "      <td>{'learning_rate': 0.001, 'n_estimators': 10, '...</td>\n",
       "      <td>2006-01-01</td>\n",
       "      <td>0.111524</td>\n",
       "      <td>0.648936</td>\n",
       "      <td>0.290476</td>\n",
       "      <td>0.401316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>GB</td>\n",
       "      <td>{'learning_rate': 0.001, 'n_estimators': 100, ...</td>\n",
       "      <td>2006-01-01</td>\n",
       "      <td>0.111524</td>\n",
       "      <td>0.648936</td>\n",
       "      <td>0.290476</td>\n",
       "      <td>0.401316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>GB</td>\n",
       "      <td>{'learning_rate': 0.1, 'n_estimators': 10, 'su...</td>\n",
       "      <td>2006-01-01</td>\n",
       "      <td>0.111524</td>\n",
       "      <td>0.648936</td>\n",
       "      <td>0.290476</td>\n",
       "      <td>0.401316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>DT</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 2, 'min_sam...</td>\n",
       "      <td>2007-01-01</td>\n",
       "      <td>0.154198</td>\n",
       "      <td>0.953846</td>\n",
       "      <td>0.306931</td>\n",
       "      <td>0.464419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>DT</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 2, 'min_sam...</td>\n",
       "      <td>2007-01-01</td>\n",
       "      <td>0.154198</td>\n",
       "      <td>0.953846</td>\n",
       "      <td>0.306931</td>\n",
       "      <td>0.464419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>DT</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 2, 'min_...</td>\n",
       "      <td>2007-01-01</td>\n",
       "      <td>0.154198</td>\n",
       "      <td>0.953846</td>\n",
       "      <td>0.306931</td>\n",
       "      <td>0.464419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>DT</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 2, 'min_...</td>\n",
       "      <td>2007-01-01</td>\n",
       "      <td>0.154198</td>\n",
       "      <td>0.953846</td>\n",
       "      <td>0.306931</td>\n",
       "      <td>0.464419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>RF</td>\n",
       "      <td>{'max_depth': 50, 'max_features': 'sqrt', 'min...</td>\n",
       "      <td>2008-01-01</td>\n",
       "      <td>0.145802</td>\n",
       "      <td>0.953846</td>\n",
       "      <td>0.324607</td>\n",
       "      <td>0.484375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>RF</td>\n",
       "      <td>{'max_depth': 100, 'max_features': 'sqrt', 'mi...</td>\n",
       "      <td>2008-01-01</td>\n",
       "      <td>0.145802</td>\n",
       "      <td>0.953846</td>\n",
       "      <td>0.324607</td>\n",
       "      <td>0.484375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>RF</td>\n",
       "      <td>{'max_depth': 50, 'max_features': 'log2', 'min...</td>\n",
       "      <td>2009-01-01</td>\n",
       "      <td>0.146154</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.342105</td>\n",
       "      <td>0.509804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>RF</td>\n",
       "      <td>{'max_depth': 100, 'max_features': 'log2', 'mi...</td>\n",
       "      <td>2009-01-01</td>\n",
       "      <td>0.146154</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.342105</td>\n",
       "      <td>0.509804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629</th>\n",
       "      <td>RF</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 'log2', 'min_...</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>0.170803</td>\n",
       "      <td>0.985294</td>\n",
       "      <td>0.286325</td>\n",
       "      <td>0.443709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>675</th>\n",
       "      <td>GB</td>\n",
       "      <td>{'learning_rate': 0.001, 'n_estimators': 100, ...</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>0.170803</td>\n",
       "      <td>0.985294</td>\n",
       "      <td>0.286325</td>\n",
       "      <td>0.443709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697</th>\n",
       "      <td>LR</td>\n",
       "      <td>{'C': 1, 'penalty': 'l1'}</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>0.148040</td>\n",
       "      <td>0.964706</td>\n",
       "      <td>0.324111</td>\n",
       "      <td>0.485207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>721</th>\n",
       "      <td>RF</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 'sqrt', 'min_...</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>0.148040</td>\n",
       "      <td>0.964706</td>\n",
       "      <td>0.324111</td>\n",
       "      <td>0.485207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>723</th>\n",
       "      <td>RF</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 'sqrt', 'min_...</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>0.148040</td>\n",
       "      <td>0.964706</td>\n",
       "      <td>0.324111</td>\n",
       "      <td>0.485207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>725</th>\n",
       "      <td>RF</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 'log2', 'min_...</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>0.148040</td>\n",
       "      <td>0.964706</td>\n",
       "      <td>0.324111</td>\n",
       "      <td>0.485207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>726</th>\n",
       "      <td>RF</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 'log2', 'min_...</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>0.148040</td>\n",
       "      <td>0.964706</td>\n",
       "      <td>0.324111</td>\n",
       "      <td>0.485207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727</th>\n",
       "      <td>RF</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 'log2', 'min_...</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>0.148040</td>\n",
       "      <td>0.964706</td>\n",
       "      <td>0.324111</td>\n",
       "      <td>0.485207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>826</th>\n",
       "      <td>RF</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 'log2', 'min_...</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>0.149533</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.332031</td>\n",
       "      <td>0.498534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893</th>\n",
       "      <td>LR</td>\n",
       "      <td>{'C': 0.1, 'penalty': 'l1'}</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>0.146552</td>\n",
       "      <td>0.988506</td>\n",
       "      <td>0.337255</td>\n",
       "      <td>0.502924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>LR</td>\n",
       "      <td>{'C': 1, 'penalty': 'l1'}</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>0.146552</td>\n",
       "      <td>0.988506</td>\n",
       "      <td>0.337255</td>\n",
       "      <td>0.502924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>897</th>\n",
       "      <td>LR</td>\n",
       "      <td>{'C': 10, 'penalty': 'l1'}</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>0.146552</td>\n",
       "      <td>0.988506</td>\n",
       "      <td>0.337255</td>\n",
       "      <td>0.502924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>920</th>\n",
       "      <td>RF</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 'sqrt', 'min_...</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>0.146552</td>\n",
       "      <td>0.988506</td>\n",
       "      <td>0.337255</td>\n",
       "      <td>0.502924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>922</th>\n",
       "      <td>RF</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 'sqrt', 'min_...</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>0.146552</td>\n",
       "      <td>0.988506</td>\n",
       "      <td>0.337255</td>\n",
       "      <td>0.502924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>924</th>\n",
       "      <td>RF</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 'log2', 'min_...</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>0.146552</td>\n",
       "      <td>0.988506</td>\n",
       "      <td>0.337255</td>\n",
       "      <td>0.502924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>925</th>\n",
       "      <td>RF</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 'log2', 'min_...</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>0.146552</td>\n",
       "      <td>0.988506</td>\n",
       "      <td>0.337255</td>\n",
       "      <td>0.502924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>926</th>\n",
       "      <td>RF</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 'log2', 'min_...</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>0.146552</td>\n",
       "      <td>0.988506</td>\n",
       "      <td>0.337255</td>\n",
       "      <td>0.502924</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    model_name                                         parameters  \\\n",
       "7           LR                         {'C': 10, 'penalty': 'l2'}   \n",
       "128         RF  {'max_depth': 5, 'max_features': 'sqrt', 'min_...   \n",
       "130         RF  {'max_depth': 5, 'max_features': 'sqrt', 'min_...   \n",
       "134         RF  {'max_depth': 5, 'max_features': 'log2', 'min_...   \n",
       "136         RF  {'max_depth': 50, 'max_features': 'sqrt', 'min...   \n",
       "138         RF  {'max_depth': 50, 'max_features': 'sqrt', 'min...   \n",
       "142         RF  {'max_depth': 50, 'max_features': 'log2', 'min...   \n",
       "144         RF  {'max_depth': 100, 'max_features': 'sqrt', 'mi...   \n",
       "146         RF  {'max_depth': 100, 'max_features': 'sqrt', 'mi...   \n",
       "150         RF  {'max_depth': 100, 'max_features': 'log2', 'mi...   \n",
       "278         GB  {'learning_rate': 0.001, 'n_estimators': 10, '...   \n",
       "280         GB  {'learning_rate': 0.001, 'n_estimators': 100, ...   \n",
       "282         GB  {'learning_rate': 0.1, 'n_estimators': 10, 'su...   \n",
       "305         DT  {'criterion': 'gini', 'max_depth': 2, 'min_sam...   \n",
       "306         DT  {'criterion': 'gini', 'max_depth': 2, 'min_sam...   \n",
       "315         DT  {'criterion': 'entropy', 'max_depth': 2, 'min_...   \n",
       "316         DT  {'criterion': 'entropy', 'max_depth': 2, 'min_...   \n",
       "434         RF  {'max_depth': 50, 'max_features': 'sqrt', 'min...   \n",
       "442         RF  {'max_depth': 100, 'max_features': 'sqrt', 'mi...   \n",
       "535         RF  {'max_depth': 50, 'max_features': 'log2', 'min...   \n",
       "543         RF  {'max_depth': 100, 'max_features': 'log2', 'mi...   \n",
       "629         RF  {'max_depth': 5, 'max_features': 'log2', 'min_...   \n",
       "675         GB  {'learning_rate': 0.001, 'n_estimators': 100, ...   \n",
       "697         LR                          {'C': 1, 'penalty': 'l1'}   \n",
       "721         RF  {'max_depth': 5, 'max_features': 'sqrt', 'min_...   \n",
       "723         RF  {'max_depth': 5, 'max_features': 'sqrt', 'min_...   \n",
       "725         RF  {'max_depth': 5, 'max_features': 'log2', 'min_...   \n",
       "726         RF  {'max_depth': 5, 'max_features': 'log2', 'min_...   \n",
       "727         RF  {'max_depth': 5, 'max_features': 'log2', 'min_...   \n",
       "826         RF  {'max_depth': 5, 'max_features': 'log2', 'min_...   \n",
       "893         LR                        {'C': 0.1, 'penalty': 'l1'}   \n",
       "895         LR                          {'C': 1, 'penalty': 'l1'}   \n",
       "897         LR                         {'C': 10, 'penalty': 'l1'}   \n",
       "920         RF  {'max_depth': 5, 'max_features': 'sqrt', 'min_...   \n",
       "922         RF  {'max_depth': 5, 'max_features': 'sqrt', 'min_...   \n",
       "924         RF  {'max_depth': 5, 'max_features': 'log2', 'min_...   \n",
       "925         RF  {'max_depth': 5, 'max_features': 'log2', 'min_...   \n",
       "926         RF  {'max_depth': 5, 'max_features': 'log2', 'min_...   \n",
       "\n",
       "    test_set_start_date  baseline    p_at_5    r_at_5   f1_at_5  \n",
       "7            2004-01-01  0.139671  0.968085  0.346008  0.509804  \n",
       "128          2005-01-01  0.140202  0.968085  0.344697  0.508380  \n",
       "130          2005-01-01  0.140202  0.968085  0.344697  0.508380  \n",
       "134          2005-01-01  0.140202  0.968085  0.344697  0.508380  \n",
       "136          2005-01-01  0.140202  0.968085  0.344697  0.508380  \n",
       "138          2005-01-01  0.140202  0.968085  0.344697  0.508380  \n",
       "142          2005-01-01  0.140202  0.968085  0.344697  0.508380  \n",
       "144          2005-01-01  0.140202  0.968085  0.344697  0.508380  \n",
       "146          2005-01-01  0.140202  0.968085  0.344697  0.508380  \n",
       "150          2005-01-01  0.140202  0.968085  0.344697  0.508380  \n",
       "278          2006-01-01  0.111524  0.648936  0.290476  0.401316  \n",
       "280          2006-01-01  0.111524  0.648936  0.290476  0.401316  \n",
       "282          2006-01-01  0.111524  0.648936  0.290476  0.401316  \n",
       "305          2007-01-01  0.154198  0.953846  0.306931  0.464419  \n",
       "306          2007-01-01  0.154198  0.953846  0.306931  0.464419  \n",
       "315          2007-01-01  0.154198  0.953846  0.306931  0.464419  \n",
       "316          2007-01-01  0.154198  0.953846  0.306931  0.464419  \n",
       "434          2008-01-01  0.145802  0.953846  0.324607  0.484375  \n",
       "442          2008-01-01  0.145802  0.953846  0.324607  0.484375  \n",
       "535          2009-01-01  0.146154  1.000000  0.342105  0.509804  \n",
       "543          2009-01-01  0.146154  1.000000  0.342105  0.509804  \n",
       "629          2010-01-01  0.170803  0.985294  0.286325  0.443709  \n",
       "675          2010-01-01  0.170803  0.985294  0.286325  0.443709  \n",
       "697          2011-01-01  0.148040  0.964706  0.324111  0.485207  \n",
       "721          2011-01-01  0.148040  0.964706  0.324111  0.485207  \n",
       "723          2011-01-01  0.148040  0.964706  0.324111  0.485207  \n",
       "725          2011-01-01  0.148040  0.964706  0.324111  0.485207  \n",
       "726          2011-01-01  0.148040  0.964706  0.324111  0.485207  \n",
       "727          2011-01-01  0.148040  0.964706  0.324111  0.485207  \n",
       "826          2012-01-01  0.149533  1.000000  0.332031  0.498534  \n",
       "893          2013-01-01  0.146552  0.988506  0.337255  0.502924  \n",
       "895          2013-01-01  0.146552  0.988506  0.337255  0.502924  \n",
       "897          2013-01-01  0.146552  0.988506  0.337255  0.502924  \n",
       "920          2013-01-01  0.146552  0.988506  0.337255  0.502924  \n",
       "922          2013-01-01  0.146552  0.988506  0.337255  0.502924  \n",
       "924          2013-01-01  0.146552  0.988506  0.337255  0.502924  \n",
       "925          2013-01-01  0.146552  0.988506  0.337255  0.502924  \n",
       "926          2013-01-01  0.146552  0.988506  0.337255  0.502924  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_models_per_metric['p_at_5'].iloc[:, [0,2,3,4,11,12,13]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best models for Precision at 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>parameters</th>\n",
       "      <th>test_set_start_date</th>\n",
       "      <th>baseline</th>\n",
       "      <th>p_at_10</th>\n",
       "      <th>r_at_10</th>\n",
       "      <th>f1_at_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LR</td>\n",
       "      <td>{'C': 1, 'penalty': 'l2'}</td>\n",
       "      <td>2004-01-01</td>\n",
       "      <td>0.139671</td>\n",
       "      <td>0.872340</td>\n",
       "      <td>0.623574</td>\n",
       "      <td>0.727273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>RF</td>\n",
       "      <td>{'max_depth': 50, 'max_features': 'sqrt', 'min...</td>\n",
       "      <td>2005-01-01</td>\n",
       "      <td>0.140202</td>\n",
       "      <td>0.824468</td>\n",
       "      <td>0.587121</td>\n",
       "      <td>0.685841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>RF</td>\n",
       "      <td>{'max_depth': 100, 'max_features': 'sqrt', 'mi...</td>\n",
       "      <td>2005-01-01</td>\n",
       "      <td>0.140202</td>\n",
       "      <td>0.824468</td>\n",
       "      <td>0.587121</td>\n",
       "      <td>0.685841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>RF</td>\n",
       "      <td>{'max_depth': 50, 'max_features': 'log2', 'min...</td>\n",
       "      <td>2006-01-01</td>\n",
       "      <td>0.111524</td>\n",
       "      <td>0.563830</td>\n",
       "      <td>0.504762</td>\n",
       "      <td>0.532663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>RF</td>\n",
       "      <td>{'max_depth': 100, 'max_features': 'log2', 'mi...</td>\n",
       "      <td>2006-01-01</td>\n",
       "      <td>0.111524</td>\n",
       "      <td>0.563830</td>\n",
       "      <td>0.504762</td>\n",
       "      <td>0.532663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>GB</td>\n",
       "      <td>{'learning_rate': 0.001, 'n_estimators': 100, ...</td>\n",
       "      <td>2007-01-01</td>\n",
       "      <td>0.154198</td>\n",
       "      <td>0.854962</td>\n",
       "      <td>0.554455</td>\n",
       "      <td>0.672673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>RF</td>\n",
       "      <td>{'max_depth': 50, 'max_features': 'sqrt', 'min...</td>\n",
       "      <td>2008-01-01</td>\n",
       "      <td>0.145802</td>\n",
       "      <td>0.801527</td>\n",
       "      <td>0.549738</td>\n",
       "      <td>0.652174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>RF</td>\n",
       "      <td>{'max_depth': 100, 'max_features': 'sqrt', 'mi...</td>\n",
       "      <td>2008-01-01</td>\n",
       "      <td>0.145802</td>\n",
       "      <td>0.801527</td>\n",
       "      <td>0.549738</td>\n",
       "      <td>0.652174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576</th>\n",
       "      <td>GB</td>\n",
       "      <td>{'learning_rate': 0.001, 'n_estimators': 100, ...</td>\n",
       "      <td>2009-01-01</td>\n",
       "      <td>0.146154</td>\n",
       "      <td>0.853846</td>\n",
       "      <td>0.584211</td>\n",
       "      <td>0.693750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>LR</td>\n",
       "      <td>{'C': 0.001, 'penalty': 'l2'}</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>0.170803</td>\n",
       "      <td>0.941606</td>\n",
       "      <td>0.551282</td>\n",
       "      <td>0.695418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>601</th>\n",
       "      <td>LR</td>\n",
       "      <td>{'C': 10, 'penalty': 'l2'}</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>0.170803</td>\n",
       "      <td>0.941606</td>\n",
       "      <td>0.551282</td>\n",
       "      <td>0.695418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>735</th>\n",
       "      <td>RF</td>\n",
       "      <td>{'max_depth': 50, 'max_features': 'log2', 'min...</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>0.148040</td>\n",
       "      <td>0.852941</td>\n",
       "      <td>0.573123</td>\n",
       "      <td>0.685579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>736</th>\n",
       "      <td>RF</td>\n",
       "      <td>{'max_depth': 50, 'max_features': 'log2', 'min...</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>0.148040</td>\n",
       "      <td>0.852941</td>\n",
       "      <td>0.573123</td>\n",
       "      <td>0.685579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>743</th>\n",
       "      <td>RF</td>\n",
       "      <td>{'max_depth': 100, 'max_features': 'log2', 'mi...</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>0.148040</td>\n",
       "      <td>0.852941</td>\n",
       "      <td>0.573123</td>\n",
       "      <td>0.685579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744</th>\n",
       "      <td>RF</td>\n",
       "      <td>{'max_depth': 100, 'max_features': 'log2', 'mi...</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>0.148040</td>\n",
       "      <td>0.852941</td>\n",
       "      <td>0.573123</td>\n",
       "      <td>0.685579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>772</th>\n",
       "      <td>GB</td>\n",
       "      <td>{'learning_rate': 0.001, 'n_estimators': 10, '...</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>0.148040</td>\n",
       "      <td>0.852941</td>\n",
       "      <td>0.573123</td>\n",
       "      <td>0.685579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>LR</td>\n",
       "      <td>{'C': 0.1, 'penalty': 'l2'}</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>0.149533</td>\n",
       "      <td>0.912281</td>\n",
       "      <td>0.609375</td>\n",
       "      <td>0.730679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>929</th>\n",
       "      <td>RF</td>\n",
       "      <td>{'max_depth': 50, 'max_features': 'sqrt', 'min...</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>0.146552</td>\n",
       "      <td>0.896552</td>\n",
       "      <td>0.611765</td>\n",
       "      <td>0.727273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>937</th>\n",
       "      <td>RF</td>\n",
       "      <td>{'max_depth': 100, 'max_features': 'sqrt', 'mi...</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>0.146552</td>\n",
       "      <td>0.896552</td>\n",
       "      <td>0.611765</td>\n",
       "      <td>0.727273</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    model_name                                         parameters  \\\n",
       "5           LR                          {'C': 1, 'penalty': 'l2'}   \n",
       "135         RF  {'max_depth': 50, 'max_features': 'sqrt', 'min...   \n",
       "143         RF  {'max_depth': 100, 'max_features': 'sqrt', 'mi...   \n",
       "238         RF  {'max_depth': 50, 'max_features': 'log2', 'min...   \n",
       "246         RF  {'max_depth': 100, 'max_features': 'log2', 'mi...   \n",
       "378         GB  {'learning_rate': 0.001, 'n_estimators': 100, ...   \n",
       "433         RF  {'max_depth': 50, 'max_features': 'sqrt', 'min...   \n",
       "441         RF  {'max_depth': 100, 'max_features': 'sqrt', 'mi...   \n",
       "576         GB  {'learning_rate': 0.001, 'n_estimators': 100, ...   \n",
       "595         LR                      {'C': 0.001, 'penalty': 'l2'}   \n",
       "601         LR                         {'C': 10, 'penalty': 'l2'}   \n",
       "735         RF  {'max_depth': 50, 'max_features': 'log2', 'min...   \n",
       "736         RF  {'max_depth': 50, 'max_features': 'log2', 'min...   \n",
       "743         RF  {'max_depth': 100, 'max_features': 'log2', 'mi...   \n",
       "744         RF  {'max_depth': 100, 'max_features': 'log2', 'mi...   \n",
       "772         GB  {'learning_rate': 0.001, 'n_estimators': 10, '...   \n",
       "795         LR                        {'C': 0.1, 'penalty': 'l2'}   \n",
       "929         RF  {'max_depth': 50, 'max_features': 'sqrt', 'min...   \n",
       "937         RF  {'max_depth': 100, 'max_features': 'sqrt', 'mi...   \n",
       "\n",
       "    test_set_start_date  baseline   p_at_10   r_at_10  f1_at_10  \n",
       "5            2004-01-01  0.139671  0.872340  0.623574  0.727273  \n",
       "135          2005-01-01  0.140202  0.824468  0.587121  0.685841  \n",
       "143          2005-01-01  0.140202  0.824468  0.587121  0.685841  \n",
       "238          2006-01-01  0.111524  0.563830  0.504762  0.532663  \n",
       "246          2006-01-01  0.111524  0.563830  0.504762  0.532663  \n",
       "378          2007-01-01  0.154198  0.854962  0.554455  0.672673  \n",
       "433          2008-01-01  0.145802  0.801527  0.549738  0.652174  \n",
       "441          2008-01-01  0.145802  0.801527  0.549738  0.652174  \n",
       "576          2009-01-01  0.146154  0.853846  0.584211  0.693750  \n",
       "595          2010-01-01  0.170803  0.941606  0.551282  0.695418  \n",
       "601          2010-01-01  0.170803  0.941606  0.551282  0.695418  \n",
       "735          2011-01-01  0.148040  0.852941  0.573123  0.685579  \n",
       "736          2011-01-01  0.148040  0.852941  0.573123  0.685579  \n",
       "743          2011-01-01  0.148040  0.852941  0.573123  0.685579  \n",
       "744          2011-01-01  0.148040  0.852941  0.573123  0.685579  \n",
       "772          2011-01-01  0.148040  0.852941  0.573123  0.685579  \n",
       "795          2012-01-01  0.149533  0.912281  0.609375  0.730679  \n",
       "929          2013-01-01  0.146552  0.896552  0.611765  0.727273  \n",
       "937          2013-01-01  0.146552  0.896552  0.611765  0.727273  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_models_per_metric['p_at_10'].iloc[:, [0,2,3,4,14,15,16]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best models for AUC-ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>parameters</th>\n",
       "      <th>test_set_start_date</th>\n",
       "      <th>baseline</th>\n",
       "      <th>auc-roc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LR</td>\n",
       "      <td>{'C': 10, 'penalty': 'l2'}</td>\n",
       "      <td>2004-01-01</td>\n",
       "      <td>0.139671</td>\n",
       "      <td>0.958478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>RF</td>\n",
       "      <td>{'max_depth': 50, 'max_features': 'sqrt', 'min...</td>\n",
       "      <td>2005-01-01</td>\n",
       "      <td>0.140202</td>\n",
       "      <td>0.925646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>RF</td>\n",
       "      <td>{'max_depth': 100, 'max_features': 'sqrt', 'mi...</td>\n",
       "      <td>2005-01-01</td>\n",
       "      <td>0.140202</td>\n",
       "      <td>0.925646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>RF</td>\n",
       "      <td>{'max_depth': 50, 'max_features': 'sqrt', 'min...</td>\n",
       "      <td>2006-01-01</td>\n",
       "      <td>0.111524</td>\n",
       "      <td>0.882219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>RF</td>\n",
       "      <td>{'max_depth': 100, 'max_features': 'sqrt', 'mi...</td>\n",
       "      <td>2006-01-01</td>\n",
       "      <td>0.111524</td>\n",
       "      <td>0.882219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>GB</td>\n",
       "      <td>{'learning_rate': 0.1, 'n_estimators': 10, 'su...</td>\n",
       "      <td>2007-01-01</td>\n",
       "      <td>0.154198</td>\n",
       "      <td>0.924869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>RF</td>\n",
       "      <td>{'max_depth': 50, 'max_features': 'sqrt', 'min...</td>\n",
       "      <td>2008-01-01</td>\n",
       "      <td>0.145802</td>\n",
       "      <td>0.927773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>RF</td>\n",
       "      <td>{'max_depth': 100, 'max_features': 'sqrt', 'mi...</td>\n",
       "      <td>2008-01-01</td>\n",
       "      <td>0.145802</td>\n",
       "      <td>0.927773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>GB</td>\n",
       "      <td>{'learning_rate': 0.1, 'n_estimators': 10, 'su...</td>\n",
       "      <td>2009-01-01</td>\n",
       "      <td>0.146154</td>\n",
       "      <td>0.937771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>LR</td>\n",
       "      <td>{'C': 0.001, 'penalty': 'l2'}</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>0.170803</td>\n",
       "      <td>0.943511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>LR</td>\n",
       "      <td>{'C': 0.1, 'penalty': 'l1'}</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>0.148040</td>\n",
       "      <td>0.940994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>LR</td>\n",
       "      <td>{'C': 1, 'penalty': 'l2'}</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>0.149533</td>\n",
       "      <td>0.951140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892</th>\n",
       "      <td>LR</td>\n",
       "      <td>{'C': 0.001, 'penalty': 'l2'}</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>0.146552</td>\n",
       "      <td>0.961948</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    model_name                                         parameters  \\\n",
       "7           LR                         {'C': 10, 'penalty': 'l2'}   \n",
       "135         RF  {'max_depth': 50, 'max_features': 'sqrt', 'min...   \n",
       "143         RF  {'max_depth': 100, 'max_features': 'sqrt', 'mi...   \n",
       "236         RF  {'max_depth': 50, 'max_features': 'sqrt', 'min...   \n",
       "244         RF  {'max_depth': 100, 'max_features': 'sqrt', 'mi...   \n",
       "381         GB  {'learning_rate': 0.1, 'n_estimators': 10, 'su...   \n",
       "435         RF  {'max_depth': 50, 'max_features': 'sqrt', 'min...   \n",
       "443         RF  {'max_depth': 100, 'max_features': 'sqrt', 'mi...   \n",
       "579         GB  {'learning_rate': 0.1, 'n_estimators': 10, 'su...   \n",
       "595         LR                      {'C': 0.001, 'penalty': 'l2'}   \n",
       "695         LR                        {'C': 0.1, 'penalty': 'l1'}   \n",
       "797         LR                          {'C': 1, 'penalty': 'l2'}   \n",
       "892         LR                      {'C': 0.001, 'penalty': 'l2'}   \n",
       "\n",
       "    test_set_start_date  baseline   auc-roc  \n",
       "7            2004-01-01  0.139671  0.958478  \n",
       "135          2005-01-01  0.140202  0.925646  \n",
       "143          2005-01-01  0.140202  0.925646  \n",
       "236          2006-01-01  0.111524  0.882219  \n",
       "244          2006-01-01  0.111524  0.882219  \n",
       "381          2007-01-01  0.154198  0.924869  \n",
       "435          2008-01-01  0.145802  0.927773  \n",
       "443          2008-01-01  0.145802  0.927773  \n",
       "579          2009-01-01  0.146154  0.937771  \n",
       "595          2010-01-01  0.170803  0.943511  \n",
       "695          2011-01-01  0.148040  0.940994  \n",
       "797          2012-01-01  0.149533  0.951140  \n",
       "892          2013-01-01  0.146552  0.961948  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_models_per_metric['auc-roc'].iloc[:, [0,2,3,4,26]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot of all model types performance at different train/test sets, for the different metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "importlib.reload(pipeline)\n",
    "\n",
    "best_models_per_metric = {}\n",
    "\n",
    "for metric in metrics_to_display:\n",
    "    #For each model, find the set of parameters that work the best in each train/test set\n",
    "    best_models = pipeline.get_best_models_of_each_type_for_each_train_test_set(models_to_run,results,'test_set_start_date', metric)\n",
    "    pipeline.plot_models_in_time(models_to_run, best_models, metric)\n",
    "    best_models_per_metric[metric]=best_models\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
